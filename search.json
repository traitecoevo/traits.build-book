[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The {traits.build} data model, R package, and workflow",
    "section": "",
    "text": "1 About",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>About</span>"
    ]
  },
  {
    "objectID": "index.html#brief-overview",
    "href": "index.html#brief-overview",
    "title": "The {traits.build} data model, R package, and workflow",
    "section": "1.1 Brief overview",
    "text": "1.1 Brief overview\nImagine you wanted to build a database of traits. You might start by compiling data from existing datasets, but you’d quickly find that there are many different ways to name and measure the same trait, that different studies use different units, or use an outdated name for a species or taxon.\ntraits.build is a data standard, R package, and workflow that is desgined to help you build a harmonised, relational database from disparate datasets. The package was first developed to create austraits.build an, open-source database of Australian plant traits. The code has been transformed into a standalone package allowing anyone to build a relational, tabular database for any taxonomic group and any collection of traits.\nA description of this package is available at: Wenk, E., Bal, P., Coleman, D., Gallagher, R., Yang, S., Falster, D., 2024. Traits.build: A data model, workflow and R package for building harmonised ecological trait databases. Ecological Informatics 83, 102773. DOI: j.ecoinf.2024.102773",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>About</span>"
    ]
  },
  {
    "objectID": "index.html#about-this-manual",
    "href": "index.html#about-this-manual",
    "title": "The {traits.build} data model, R package, and workflow",
    "section": "1.2 About this manual",
    "text": "1.2 About this manual\nThis manual is a step-by-step user guide to the traits.build standard, R package and workflow manual. Alongside this manual, you may find the following resources useful:\n\ninstallation instructions for the traits.build package\na reference page with all user-side functions for the traits.build package.\nlinks to example projects",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>About</span>"
    ]
  },
  {
    "objectID": "index.html#a-simple-example",
    "href": "index.html#a-simple-example",
    "title": "The {traits.build} data model, R package, and workflow",
    "section": "1.3 A simple example",
    "text": "1.3 A simple example\nTo get you started, we’ve provided a template example compilation which you can clone and modify. This provides the basic steps for building a traits.build compilation. Follow the instructions in Tutorials chapter for a step-by-step guide to building a database from scratch.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>About</span>"
    ]
  },
  {
    "objectID": "index.html#getting-help",
    "href": "index.html#getting-help",
    "title": "The {traits.build} data model, R package, and workflow",
    "section": "1.4 Getting help",
    "text": "1.4 Getting help\nAlong the way, users may encounter a number of errors and warnings. Some of these are designed to help you build a robust database, others may constitue an error in your data, file structure, or the package. If you encounter an error or warning, please read the message carefully and follow the instructions for getting help.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>About</span>"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "The {traits.build} data model, R package, and workflow",
    "section": "1.5 Acknowledgements",
    "text": "1.5 Acknowledgements\nThis manual arose from code within the AusTraits project at https://github.com/traitecoevo/austraits.build. The AusTraits project received investment (https://doi.org/10.47486/DP720) from the Australian Research Data Commons (ARDC). The ARDC is funded by the National Collaborative Research Infrastructure Strategy (NCRIS).",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>About</span>"
    ]
  },
  {
    "objectID": "motivation.html",
    "href": "motivation.html",
    "title": "2  Motivation",
    "section": "",
    "text": "2.1 The problem\nEcological data are often collected in disparate formats, making it difficult to combine datasets for analysis. This is particularly true for trait data, which are often collected in a variety of formats and are rarely stored in a relational database. This makes it difficult to combine trait data with other ecological data, such as abundance or biomass, for analysis.\nMoreover, trait data are often collected in fragments, corrpesonding to scientific papers. Different traits may be collected for different species, or different traits are collected for the same species at different times or at different locations.\nTo create a large harmonised dataset, we need to combine these different datasets into a unfied whole, with common names, units, values for categorical traits, and so on. This is a time-consuming process.\nWe are not the first group to tackle this problem. Our field (plant ecology) has many trait datasets, most compiled from diverse sources. Most start small, with a few soruces that can be handled within a spreadhseet. But as thery grow, they ecnouter issues. The largest is TRY, with &gt; 15 million records from over 300,000 plant taxa. However, each group has had to tackle the compilation challenge anew, as there are no common pathways for creating a harmonised dataset.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Motivation</span>"
    ]
  },
  {
    "objectID": "motivation.html#the-solution",
    "href": "motivation.html#the-solution",
    "title": "2  Motivation",
    "section": "2.2 The solution",
    "text": "2.2 The solution\nThe traits.build data standard, R package, and workflow offer a solution to this problem, with a set of open-source tools that enable users to create open-source, harmonised, reproducible databases from disparate datasets, underpinned by a sophisticated ontology able to handle the complexities inherent to ecological data.\nWe developed these tools for the to create AusTraits, an, open-source database of Australian plant traits. We figured others may want to replicate these efforts, so we the code and workflow was transformed into a standalone package allowing anyone to build a trait database for their own region or taxa.\nAlong the way, we hdeveloped a suite of tools:\n\ntraits.build data standard: a relational database structure that fully documents the contextual data essential to interpreting ecological data.\ntraits.build R package: a set of functions that enable users to create a harmonised database from disparate datasets.\nAPD: The AusTraits Plant Dictionary, with detailed descriptions for more than 500 plant trait concepts.\n\nAPCalign: an R package to align and update Australian plant taxon name strings with the Australian Plant Census.\n\nThe tools are open-source, so that users can apply them to suit their needs and without cost.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Motivation</span>"
    ]
  },
  {
    "objectID": "workflow.html",
    "href": "workflow.html",
    "title": "3  Workflow",
    "section": "",
    "text": "3.1 Core principles\nThis chapter provides an overview of our workflow, to demonstrate our commitment to creating a reliable, reproducible resource for anyone interested in plant traits.\nThe project’s guiding principles are to:",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Workflow</span>"
    ]
  },
  {
    "objectID": "workflow.html#core-principles",
    "href": "workflow.html#core-principles",
    "title": "3  Workflow",
    "section": "",
    "text": "Wherever possible solve problems in a general way, that enables others to leverage our efforts to solve their own problems.\nEnable users to create open-source, harmonised, reproducible databases from disparate datasets.\nProvide a fully transparent workflow, where all decisions on how to handle the data are exposed and can be.\nOffer a relational database structure that fully documents the contextual data essential to interpreting ecological data.\nOffer a straightforward, robust template for building a trait dictionary.\nOffer a database structure that is flexible enough to accommodate the complexities inherent to ecological data.\nOffer a database structure that is underlain by a documented ontology, ensuring each database field is interpretable and interoperable with other databases and data structures.\nHave no dependencies on proprietary software or costs to setup and maintain (beyond person time).",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Workflow</span>"
    ]
  },
  {
    "objectID": "workflow.html#approach",
    "href": "workflow.html#approach",
    "title": "3  Workflow",
    "section": "3.2 Approach",
    "text": "3.2 Approach\ntraits.build can be viewed through two lenses, its output structure and its underlying conceptual framework.\n\nOutput structure\ntraits.build is a relational database. There is a core traits table, supported by ancillary tables that document location properties (include latitude & longitude), context properties, dataset and measurement methods, taxon concepts, contributor details, and sources. All tables are stored in long format, such that there is a single column that includes all trait names (or location properties, or context properties) and column for trait values.\nA series of identifiers, including both textual fields (i.e. taxon_name, trait_name, dataset_id) and numeric identifiers link the ancillary tables to the traits table. The many numeric identifiers are overwhelming until you consider the conceptual framework, or mindmap, that underpins traits.build. They include: observation_id, population_id, individual_id, temporal_id, location_id, entity_context_id, plot_id, and source_id.\nStoring the resource as a relational table greatly reduces file sizes and facilitates searching for a particular metadata field\n\n\nConceptual framework\ntraits.build’s database structure effectively captures the complexities inherent to ecological data. Each dataset is unique, with measurements recorded on different entities (individuals, populations, species), in specific locations, and under countless environmental and experimental conditions, the so-called context of a measurement. The context offers essential meaning to each trait value. An ecological database must effectively capture all relevant contexts or the accompanying trait measurements lose much of their value.\ntraits.build is designed around the concept of an observation, a collection of measurements of different traits made at a specific point in time on a specific entity. OBOE, the Extensible Observation Ontology, first developed this conceptual framework, explicitly for complex ecological datasets. An observation_id links the measurements made on different traits that comprise a single observation. Measurements made at different points in time, on different entities, at different locations, or under different contextual conditions require unique observation_id values. The additional identifiers in the traits table (and the ancillary tables) were developed to ensure that unique observation_ids were generated for distinct observations, per this framework.\nWithin a dataset, observation_id’s are generated for unique combinations of the fields: taxon_name, population_id, individual_id, temporal_id, entity_type, and source_id. For instance, if measurements are made on the same individual during the wet versus dry season, the two observations will share an individual_id but have distinct temporal_id values, and therefore have distinct observation_id’s. See traits.build schema for definitions of identifiers",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Workflow</span>"
    ]
  },
  {
    "objectID": "workflow.html#concepts",
    "href": "workflow.html#concepts",
    "title": "3  Workflow",
    "section": "3.3 Concepts",
    "text": "3.3 Concepts\nOur workflow is structured with the following concepts.\n\nData sources\nThe data in a traits.build compilation is derived from distinct sources, each contributed by an individual researcher, government entity (e.g. herbaria), or NGO. Each reflects the research agenda of the individual/organisation who contributed the data - the species selected, traits measured, manipulative treatments performed, and locations sampled encompass the diversity of research interests present in Australia throughout past decades. These datasets use different variable trait names, units and methods and have different data structures.\n\n\nStandardising and harmonising data\nTo create a single database for distribution to the research community, we developed a reproducible and transparent workflow in R for merging each dataset into AusTraits. The pipeline ensures the following information is standardised across all datasets in AusTraits. A metadata file for each study documents how the data tables submitted by an individual contributor are translated into the standardised terms used in the AusTraits database.\n\ntaxonomic nomenclature follows the Australian Plant Census (APC), with a pipeline to update outdated taxonomy, correct minor spelling mistakes, and align with a known genus when a full species names isn’t provided.\n\ntrait names are defined in our traits.yml file and only data for traits included in this file can be merged into AusTraits. The trait names used in the incoming dataset are mapped onto the appropriate AusTraits trait name.\nFor numeric traits the traits.yml file includes units and the allowable range of values. All incoming data are converted to the appropriate units and data outside the range of allowable values are removed from the main AusTraits data table.\nFor categorical traits the traits.yml file includes a list of allowable values, allowed terms for the trait. Each categorical trait value is defined in the traits.yml file. Lists of substitutions translate the exact syntax and terms in a submitted dataset into the values allowed by AusTraits. This ensures that for a certain trait the same value has an identical meaning throughout the AusTraits database.\nSite locations are recorded in decimal degrees.\n\n\n\nReferencing sources and recording methods\nThe metadata file also includes all metadata associated with the study:\n\nThe source information for each dataset is recorded. Most frequently, these are the primary publications derived from the dataset.\nPeople associated with the collection of the data are listed, including their role in the project.\nCollection methods are included.\nFields capture value type (mean, min, max, mode, range, bin) and associated replicate numbers, basis of value (measurement, expert_score, model_derived), entity type (species, population, individual), life stage (adult, juvenile,sapling, seedling), basis of record (field, field_experiment, preserved_specimen, captive_cultivated, lab, literature), and any additional measurement remarks.\nAvailable data on location properties are recorded.\nAvailable data on plot and treatment contextual properties are recorded.\nA context field, temporal_context_id, indicates if repeat measures were made on the same individual over time.\nA context field, method_context_id, indicates if the same trait was measured using multiple methods.\nCollection date is recorded.\n\n\n\nError checking\nWe consider deatiled error checking to be an inmporant and ongoing part of our workflow. The following steps are taken to ensure data quality.\n\nThe data curator can rus a series of tests on each data set, detailed in the adding data vignette\nThese tests identify misaligned units, unrecognised taxon names, and unsupported categorical trait values\nThese tests also identify and eliminate most duplicate data - instances where the same numeric trait data is submitted by multiple people\nEach dataset is then compiled into a report which summarises metadata and plots/charts trait values in comparison to other measurements of that trait in AusTraits. The report is reviewed by the data contributor to ensure metadata is complete and data values are as expected.\nA second member of the AusTraits team double checks each dataset before it is merged into the main repository.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Workflow</span>"
    ]
  },
  {
    "objectID": "usage_examples.html",
    "href": "usage_examples.html",
    "title": "4  Usage examples",
    "section": "",
    "text": "4.1 AusTraits\nThe workflow described here evolved out of the AusTraits project. AusTraits is an open-source, harmonized database of Australian plant trait data. It synthesises data on nearly 500 traits across more than 30,000 taxa from over 300 sources. Begun in 2016 as an initiative between three lab groups, it has grown to be the largest collation of plant trait data for Australian plants.\nThe traits.build workflow is now used to build the AusTraits database. Indeed, the GitHub repository traitecoevo/austraits.build now includes only the trait datasets (& metadata) and the configuration files required to compile AusTraits. The R workflow to build the database is now sourced from the {traits.build} package",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Usage examples</span>"
    ]
  },
  {
    "objectID": "usage_examples.html#other-examples",
    "href": "usage_examples.html#other-examples",
    "title": "4  Usage examples",
    "section": "4.2 Other examples",
    "text": "4.2 Other examples\nThere are now multiple new porjects using the traits.build workflow and package. At this stage, most are in private repositories, but we envisage that they will be made public in the near future.\n\nAusTraits: A compilation of traits data for Australian plants\nAusInverTraits: A compilation of traits data for invertebrates, led by Inverterbates Australia\nAusFizz: A compilation of physiological response curves for plants",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Usage examples</span>"
    ]
  },
  {
    "objectID": "long_wide.html",
    "href": "long_wide.html",
    "title": "5  Long vs Wide data",
    "section": "",
    "text": "5.1 Background\nConcepts\nThere are two distinct formats for storing data, wide and long. With wide format, each row is a separate set of measurements on an entity (individual, taxon), and data for each trait are recorded in successive columns. With long format data, each row includes only a single trait measurement, with a column for the trait name and a column that indicates which rows of data belong to the same entity. Most ecological datasets are in wide format, as the same trait measurements are made on each entity. However, when merging together datasets that measure different traits, it becomes more efficient to store data in long format. Otherwise, you end up with a very “holey” table, as each trait may only be measured on a small proportion of entities.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Long vs Wide data</span>"
    ]
  },
  {
    "objectID": "long_wide.html#our-approach",
    "href": "long_wide.html#our-approach",
    "title": "5  Long vs Wide data",
    "section": "5.2 Our approach",
    "text": "5.2 Our approach\nThe traits.build output tables (traits, locations, contexts, etc.) are each in long format. Within a traits.build database different traits, location properties, and context properties are always likely to be collected by different datasets, leading to a database with many, many columns with low completeness. Under this scenario, long format significantly reduces the size of the data object, reducing storage costs and increasing the speed of loading. However, most users will prefer a wide format for analysis as multiple trait measurements for the same entity will be collapsed to a single row. This becomes practical once the full database is subsetted to just include specific traits.\n\nPivotting between long and wide\nTwo {tidyr} functions, pivot_longer and pivot_wider make it quick to convert data from long to wide format in R. The AusTraits tutorial offers multiple examples for how these functions can be used to pivot the various relational tables in a traits.build database, inuding the core traits table.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Long vs Wide data</span>"
    ]
  },
  {
    "objectID": "database_standard.html",
    "href": "database_standard.html",
    "title": "6  Data standard",
    "section": "",
    "text": "6.1 Overview\nA single universally accepted trait database standard does not currently exist among plant ecologists, limiting our ability to merge together distinct databases.\nA broadly accepted standard must achieve two goals:\nThe AusTraits Project aims to offer a trait database standard that achieves both these goals.\nOur database standard has not been invented from scratch. We have built upon ideas and standards described in previous publications and ontologies. In particular:",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data standard</span>"
    ]
  },
  {
    "objectID": "database_standard.html#overview",
    "href": "database_standard.html#overview",
    "title": "6  Data standard",
    "section": "",
    "text": "Be able to fully document the metadata and, in particular, the contextual information, essential to interpreting ecological data.\nBe fully described in an ontology (or through figures) that clearly capture the meaning of each database field (column) and the relationships between database fields.\n\n\n\n\nOBOE, the Extensible Observation Ontology (Madin, Joshua, et al. (2007) “An ontology for describing and synthesizing ecological observation data.” Ecological informatics) doi: 10.1016/j.ecoinf.2007.05.004\nETS, the Ecological Trait-data Standard (Schneider, Florian D., et al. (2019) “Towards an ecological trait‐data standard.” Methods in Ecology and Evolution.) doi: 10.1111/2041-210X.13288\nDarwinCore dwc.tdwg.org",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data standard</span>"
    ]
  },
  {
    "objectID": "database_standard.html#database-that-fully-documents-ecological-metadata",
    "href": "database_standard.html#database-that-fully-documents-ecological-metadata",
    "title": "6  Data standard",
    "section": "6.2 Database that fully documents ecological metadata",
    "text": "6.2 Database that fully documents ecological metadata\nTo date, AusTraits, Australia’s Plant Trait Database, has incorporated more than 370 unique datasets, spanning the breadth of plant trait data collected across Australia. It has been more than 6 months (and ~50 datasets) since we have identified a class of metadata or contextual information that could not be mapped into the traits.build structure.\nThe database structure can capture:\n\nlocation information, including coordinates and location properties\nthe entity associated with each trait measurement (e.g. species, population, individual)\ntemporal contexts, reflecting repeat measurements of an entity across time\ntreatment contexts, indicating distinct treatments applied to different entities\nentity contexts, documenting defining features of individual entities (e.g. sex or age of an individual)\nmethod contexts, documenting slight variations in sampling protocols\nresponse curve measurements are grouped into a single observation and assigned sequential identifiers\n\nThe database standard will continue to evolve as traits.build is used to build a greater diversity of trait databases, but, already offers a flexible, detailed structure for capturing and harmonising ecological data.\nSee relationships between database variables for more details.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data standard</span>"
    ]
  },
  {
    "objectID": "database_standard.html#database-standard-described-by-an-ontology",
    "href": "database_standard.html#database-standard-described-by-an-ontology",
    "title": "6  Data standard",
    "section": "6.3 Database standard described by an ontology",
    "text": "6.3 Database standard described by an ontology\nA database standard is only useful if:\n\nEach database field has a clear and consistent meaning\nThe relationships between database fields are explicit and meaningful\nThis information can readily be interpreted by both trait database custodians and database users\n\nBuilding both a formal ontology and visualisations of the ontology has been essential toward reaching these goals. To quote a seminal paper, “Ontological analysis clarifies the structure of knowledge” (Chandrasekaran et al., 1999).\nIndeed, the construction of knowledge graphs and ontological analysis has undercovered locations where a lack of semantic clarity in database structure reduced the interpretation of the output data. This iterative process leads to the continual refinement of the database structure and mapped links across database fields.\nOur ontology remains a work-in-progress, but an outdated version is available at traits.build ontology.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data standard</span>"
    ]
  },
  {
    "objectID": "database_structure.html",
    "href": "database_structure.html",
    "title": "7  Data structure",
    "section": "",
    "text": "7.1 Components\nThis chapter describes the structure of the output of a traits.build compilation.\nNote that the information below is based on the information provided within the file traits.build_schema.yml, which can be accessed by running get_schema or system.file(\"support\", \"traits.build_schema.yml\", package = \"traits.build\").\nA traits.build compilation results in a series of linked components, which cross link against each other:\nThese include all the data and contextual information submitted with each contributed dataset.\nThe core components are defined as follows.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data structure</span>"
    ]
  },
  {
    "objectID": "database_structure.html#traits",
    "href": "database_structure.html#traits",
    "title": "7  Data structure",
    "section": "7.2 Traits",
    "text": "7.2 Traits\nDescription: A table containing measurements of traits.\nContent:\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\ndataset_id\n\n\nPrimary identifier for each study contributed to AusTraits; most often these are scientific papers, books, or online resources. By default this should be the name of the first author and year of publication, e.g. Falster_2005.\n\n\n\n\ntaxon_name\n\n\nScientific name of the taxon on which traits were sampled, without authorship. When possible, this is the currently accepted (botanical) or valid (zoological) scientific name, but might also be a higher taxonomic level.\n\n\n\n\nobservation_id\n\n\nA unique integral identifier for the observation, where an observation is all measurements made on an individual at a single point in time. It is important for joining traits coming from the same observation_id. Within each dataset, observation_id’s are unique combinations of taxon_name, population_id, individual_id, and temporal_context_id.\n\n\n\n\ntrait_name\n\n\nName of the trait sampled. Allowable values specified in the table definitions.\n\n\n\n\nvalue\n\n\nThe measured value of a trait, location property or context property.\n\n\n\n\nunit\n\n\nUnits of the sampled trait value after aligning with AusTraits standards.\n\n\n\n\nentity_type\n\n\nA categorical variable specifying the entity corresponding to the trait values recorded.\n\n\n\n\nvalue_type\n\n\nA categorical variable describing the statistical nature of the trait value recorded.\n\n\n\n\nbasis_of_value\n\n\nA categorical variable describing how the trait value was obtained.\n\n\n\n\nreplicates\n\n\nNumber of replicate measurements that comprise a recorded trait measurement. A numeric value (or range) is ideal and appropriate if the value type is a mean, median, min or max. For these value types, if replication is unknown the entry should be unknown. If the value type is raw_value the replicate value should be 1. If the trait is categorical or the value indicates a measurement for an entire species (or other taxon) replicate value should be .na.\n\n\n\n\nbasis_of_record\n\n\nA categorical variable specifying from which kind of specimen traits were recorded.\n\n\n\n\nlife_stage\n\n\nA field to indicate the life stage or age class of the entity measured. Standard values are adult, sapling, seedling and juvenile.\n\n\n\n\npopulation_id\n\n\nA unique integer identifier for a population, where a population is defined as individuals growing in the same location (location_id /location_name) and plot (plot_context_id, a context category) and being subjected to the same treatment (treatment_context_id, a context category).\n\n\n\n\nindividual_id\n\n\nA unique integer identifier for an individual, with individuals numbered sequentially within each dataset by taxon by population grouping. Most often each row of data represents an individual, but in some datasets trait data collected on a single individual is presented across multiple rows of data, such as if the same trait is measured using different methods or the same individual is measured repeatedly across time.\n\n\n\n\nrepeat_measurements_id\n\n\nA unique integer identifier for repeat measurements of a trait that comprise a single observation, such as a response curve.\n\n\n\n\ntemporal_context_id\n\n\nA unique integer identifier assigned where repeat observations are made on the same individual (or population, or taxon) across time. The identifier links to specific information in the context table.\n\n\n\n\nsource_id\n\n\nFor datasets that are compilations, an identifier for the original data source.\n\n\n\n\nlocation_id\n\n\nA unique integer identifier for a location, with locations numbered sequentially within a dataset. The identifier links to specific information in the location table.\n\n\n\n\nentity_context_id\n\n\nA unique integer identifier indicating specific contextual properties of an individual, possibly including the individual’s sex or caste (for social insects).\n\n\n\n\nplot_context_id\n\n\nA unique integer identifier for a plot, where a plot is a distinct collection of organisms within a single geographic location, such as plants growing on different aspects or blocks in an experiment. The identifier links to specific information in the context table.\n\n\n\n\ntreatment_context_id\n\n\nA unique integer identifier for a treatment, where a treatment is any experimental manipulation to an organism’s growing/living conditions. The identifier links to specific information in the context table.\n\n\n\n\ncollection_date\n\n\nDate sample was taken, in the format yyyy-mm-dd, yyyy-mm or yyyy, depending on the resoluton specified. Alternatively an overall range for the study can be indicating, with the starting and ending sample date sepatated by a /, as in 2010-10/2011-03.\n\n\n\n\nmeasurement_remarks\n\n\nBrief comments or notes accompanying the trait measurement.\n\n\n\n\nmethod_id\n\n\nA unique integer identifier to distinguish between multiple sets of methods used to measure a single trait within the same dataset. The identifier links to specific information in the methods table.\n\n\n\n\nmethod_context_id\n\n\nA unique integer identifier indicating a trait is measured multiple times on the same entity, with different methods used for each entry. This field is only used if a single trait is measured using multiple methods within the same dataset. The identifier links to specific information in the context table.\n\n\n\n\noriginal_name\n\n\nName given to taxon in the original data supplied by the authors.\n\n\n\n\n\nEntity type\nAn entity is the feature of interest, indicating what a trait value applies to. While an entity can be just a component of an organism, within the scope of AusTraits, an individual is the finest scale entity that can be documented. The same study might measure some traits at a population-level (entity = population) and others at an individual-level (entity = individual).\nIn detail:\n\nentity_type is a categorical variable specifying the entity corresponding to the trait values recorded. Possible values are:\n\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\nindividual\n\n\nValue comes from a single individual.\n\n\n\n\npopulation\n\n\nValue represents a summary statistic from multiple individuals at a single location.\n\n\n\n\nmetapopulation\n\n\nValue represents a summary statistic from individuals of the taxon across multiple locations.\n\n\n\n\nspecies\n\n\nValue represents a summary statistic for a species or infraspecific taxon across its range or as estimated by an expert based on their knowledge of the taxon. Data fitting this category include estimates from reference books that represent a taxon’s entire range and values for categorical variables obtained from a reference book or identified by an expert.\n\n\n\n\ngenus\n\n\nValue represents a summary statistic or expert score for an entire genus.\n\n\n\n\nfamily\n\n\nValue represents a summary statistic or expert score for an entire family.\n\n\n\n\norder\n\n\nValue represents a summary statistic or expert score for an entire order.\n\n\n\n\n\n\nIdentifiers\nThe traits table includes 12 identifiers, dataset_id, observation_id, taxon_name, population_id, individual_id, temporal_context_id, source_id, location_id, entity_context_id, plot_context_id, treatment_context_id, and method_context_id.\ndataset_id, source_id and taxon_name have easy-to-interpret values. The others are simply integral identifiers that link groups of measurements and are automatically generated through the AusTraits workflow (individual_id can be assigned in the metadata file or automatically generated.)\nTo expand on the definitions provided above,\n\nobservation_id links measurements made on the same entity (individual, population, or species) at a single point in time.\npopulation_id indicates entities that share a common location_id, plot_context_id, and treatment_context_id. It is used to align measurements and observation_id’s for individuals versus populations (i.e. distinct entity_types) that share a common population_id. It is numbered sequentially within a dataset.\nindividual_id indicates a unique organism. It is numbered sequentially within a dataset by population. Multiple observations on the same organism across time (with distinct observation_id values), share a common individual_id.\ntemporal_context_id indicates a distinct point in time and is used only if there are repeat measurements on a population or individual across time. The identifier links to context properties (and their associated information) in the contexts table for context properties of type temporal.\nsource_id is applied if not all data within a single dataset (dataset_id) is from the same source, such as when a dataset represents a compilation for a meta-analysis.\nlocation_id links to a distinct location_name and associated location_properties in the location table.\nentity_context_id links to information in the contexts table for context properties (& associated values/descriptions) with category entity_context. Entity_contexts include organism sex, organism caste and any other features of an entity that need to be documented.\nplot_context_id links to information in the contexts table for context properties (& associated values/descriptions) with category plot. Plot contexts include both blocks/plots within an experimental design as well as any stratified variation within a location that needs to be documented (e.g. slope position).\ntreatment_context_idlinks to information in the contexts table for context properties (& associated values/descriptions) with category treatment. Treatment contexts are experimental manipulations applied to groups of individuals.\nmethod_context_idlinks to information in the contexts table for context properties (& associated values/descriptions) with category method. A method context indicates that the same trait was measured on or across individuals using different methods.\n\nAdditionally, measurement_remarks is used to document brief comments or notes accompanying the trait measurement.\n\n\nLife stage, basis of record\n\nlife_stage: a field to indicate the life stage or age class of the entity measured. Standard values are adult, sapling, seedling and juvenile.\nbasis_of_record: a categorical variable specifying from which kind of specimen traits were recorded.\n\nPossible values are:\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\nfield\n\n\nTraits were recorded on entities living naturally in the field.\n\n\n\n\nfield_experiment\n\n\nTraits were recorded on entities living under experimentally manipulated conditions in the field.\n\n\n\n\ncaptive_cultivated\n\n\nTraits were recorded on entities living in a common garden, arboretum, or botanical or zoological garden.\n\n\n\n\nlab\n\n\nTraits were recorded on entities growing in a lab, glasshouse or growth chamber.\n\n\n\n\npreserved_specimen\n\n\nTraits were recorded from specimens preserved in a collection, eg. herbarium or museum.\n\n\n\n\nliterature\n\n\nTraits were sourced from values reported in the literature, and where the basis of record is not otherwise known.\n\n\n\n\n\n\nValues, value types, basis of value\nEach record in the table of trait data has an associated value, value_type, and basis_of_value.\nValues: A trait’s values are either numeric or categorical. For traits with numerical values, the recorded value has been converted into standardised units and the AusTraits workflow has confirmed the value can be converted into a number and lies within the allowable range. For categorical variables, records have been aligned through substitutions to values listed as allowable values (terms) in a trait’s definition.\n- we use _ for multi-word terms, e.g. semi_deciduous\n- we use a space for situations where two values co-occur for the same entity. For instance, a flora might indicate that a plant species can be either annual or biennial, in which case the trait is scored as annual biennial.\nValue types: Each trait measurement has an associated value_type, which is a categorical variable describing the statistical nature of the trait value recorded.\nPossible value types are:\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\nraw\n\n\nValue recorded for an entity.\n\n\n\n\nminimum\n\n\nValue is the minimum of values recorded for an entity.\n\n\n\n\nmean\n\n\nValue is the mean of values recorded for an entity.\n\n\n\n\nmedian\n\n\nValue is the median of values recorded for an entity.\n\n\n\n\nmaximum\n\n\nValue is the maximum of values recorded for an entity.\n\n\n\n\nmode\n\n\nValue is the mode of values recorded for an entity. This is the appropriate value type for a categorical trait value.\n\n\n\n\nrange\n\n\nValue is a range of values recorded for an entity.\n\n\n\n\nbin\n\n\nValue for an entity falls within specified limits.\n\n\n\n\nstandard_error\n\n\nValue is the standard error of a mean of values recorded for an entity.\n\n\n\n\nunknown\n\n\nNot currently known.\n\n\n\n\nEach trait measurement also has an associated basis_of_value, which is a categorical variable describing how the trait value was obtained.\nPossible values are:\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\nmeasurement\n\n\nValue is the result of a measurement(s) made on a specimen(s).\n\n\n\n\nexpert_score\n\n\nValue has been estimated by an expert based on their knowledge of the entity.\n\n\n\n\nmodel_derived\n\n\nValue is derived from a statistical model, for example via gap-filling.\n\n\n\n\nunknown\n\n\nNot currently known.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data structure</span>"
    ]
  },
  {
    "objectID": "database_structure.html#locations",
    "href": "database_structure.html#locations",
    "title": "7  Data structure",
    "section": "7.3 Locations",
    "text": "7.3 Locations\nDescription: A table containing observations of location/site characteristics associated with information in traits. Cross referencing between the two dataframes is possible using combinations of the variables dataset_id, location_name.\nContent:\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\ndataset_id\n\n\nPrimary identifier for each study contributed to AusTraits; most often these are scientific papers, books, or online resources. By default this should be the name of the first author and year of publication, e.g. Falster_2005.\n\n\n\n\nlocation_id\n\n\nA unique integer identifier for a location, with locations numbered sequentially within a dataset. The identifier links to specific information in the location table.\n\n\n\n\nlocation_name\n\n\nThe location name.\n\n\n\n\nlocation_property\n\n\nThe location characteristic being recorded. The name should include units of measurement, e.g. MAT (C). Ideally we have at least the following variables for each location, longitude (deg), latitude (deg), description.\n\n\n\n\nvalue\n\n\nThe measured value of a location property.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data structure</span>"
    ]
  },
  {
    "objectID": "database_structure.html#contexts",
    "href": "database_structure.html#contexts",
    "title": "7  Data structure",
    "section": "7.4 Contexts",
    "text": "7.4 Contexts\nDescription: A table containing observations of contextual characteristics associated with information in traits. Cross referencing between the two dataframes is possible using combinations of the variables dataset_id, link_id, and link_vals.\nContent:\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\ndataset_id\n\n\nPrimary identifier for each study contributed to AusTraits; most often these are scientific papers, books, or online resources. By default this should be the name of the first author and year of publication, e.g. Falster_2005.\n\n\n\n\ncontext_property\n\n\nThe contextual characteristic being recorded. If applicable, name should include units of measurement, e.g. CO2 concentration (ppm).\n\n\n\n\ncategory\n\n\nThe category of context property, with options being plot, treatment, individual_context, temporal and method.\n\n\n\n\nvalue\n\n\nThe measured value of a context property.\n\n\n\n\ndescription\n\n\nDescription of a specific context property value.\n\n\n\n\nlink_id\n\n\nVariable indicating which identifier column in the traits table contains the specified link_vals.\n\n\n\n\nlink_vals\n\n\nUnique integer identifiers that link between identifier columns in the traits table and the contextual properties/values in the contexts table.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data structure</span>"
    ]
  },
  {
    "objectID": "database_structure.html#methods",
    "href": "database_structure.html#methods",
    "title": "7  Data structure",
    "section": "7.5 Methods",
    "text": "7.5 Methods\nDescription: A table containing details on methods with which data were collected, including time frame and source. Cross referencing with the traits table is possible using combinations of the variables dataset_id, trait_name.\nContent:\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\ndataset_id\n\n\nPrimary identifier for each study contributed to AusTraits; most often these are scientific papers, books, or online resources. By default this should be the name of the first author and year of publication, e.g. Falster_2005.\n\n\n\n\ntrait_name\n\n\nName of the trait sampled. Allowable values specified in the table definitions.\n\n\n\n\nmethods\n\n\nA textual description of the methods used to collect the trait data. Whenever available, methods are taken near-verbatim from the referenced source. Methods can include descriptions such as ‘measured on botanical collections’, ‘data from the literature’, or a detailed description of the field or lab methods used to collect the data.\n\n\n\n\nmethod_id\n\n\nA unique integer identifier to distinguish between multiple sets of methods used to measure a single trait within the same dataset. The identifier links to specific information in the methods table.\n\n\n\n\ndescription\n\n\nA 1-2 sentence description of the purpose of the study.\n\n\n\n\nsampling_strategy\n\n\nA written description of how study locations were selected and how study individuals were selected. When available, this information is lifted verbatim from a published manuscript. For preserved specimens, this field ideally indicates which records were ‘sampled’ to measure a specific trait.\n\n\n\n\nsource_primary_key\n\n\nCitation key for the primary source in sources. The key is typically formatted as Surname_year.\n\n\n\n\nsource_primary_citation\n\n\nCitation for the primary source. This detail is generated from the primary source in the metadata.\n\n\n\n\nsource_secondary_key\n\n\nCitation key for the secondary source in sources. The key is typically formatted as Surname_year.\n\n\n\n\nsource_secondary_citation\n\n\nCitations for the secondary source. This detail is generated from the secondary source in the metadata.\n\n\n\n\nsource_original_dataset_key\n\n\nCitation key for the original dataset_id in sources; for compilations. The key is typically formatted as Surname_year.\n\n\n\n\nsource_original_dataset_citation\n\n\nCitations for the original dataset_id in sources; for compilationse. This detail is generated from the original source in the metadata.\n\n\n\n\ndata_collectors\n\n\nThe person (people) leading data collection for this study.\n\n\n\n\nassistants\n\n\nNames of people who played a more minor role in data collection for the study.\n\n\n\n\ndataset_curators\n\n\nNames of database team member(s) who contacted the data collectors and added the study to the database repository.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data structure</span>"
    ]
  },
  {
    "objectID": "database_structure.html#excluded_data",
    "href": "database_structure.html#excluded_data",
    "title": "7  Data structure",
    "section": "7.6 Excluded_data",
    "text": "7.6 Excluded_data\nDescription: A table of data that did not pass quality tests and so were excluded from the master dataset. The structure is identical to that presented in the traits table, only with an extra column called error indicating why the record was excluded. Common reasons are missing_unit_conversions, missing_value, and unsupported_trait_value.\nContent:\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\nerror\n\n\nIndicating why the record was excluded. Common reasons are missing_unit_conversions, missing_value, and unsupported_trait_value.\n\n\n\n\ndataset_id\n\n\nPrimary identifier for each study contributed to AusTraits; most often these are scientific papers, books, or online resources. By default this should be the name of the first author and year of publication, e.g. Falster_2005.\n\n\n\n\ntaxon_name\n\n\nScientific name of the taxon on which traits were sampled, without authorship. When possible, this is the currently accepted (botanical) or valid (zoological) scientific name, but might also be a higher taxonomic level.\n\n\n\n\nobservation_id\n\n\nA unique integral identifier for the observation, where an observation is all measurements made on an individual at a single point in time. It is important for joining traits coming from the same observation_id. Within each dataset, observation_id’s are unique combinations of taxon_name, population_id, individual_id, and temporal_context_id.\n\n\n\n\ntrait_name\n\n\nName of the trait sampled. Allowable values specified in the table definitions.\n\n\n\n\nvalue\n\n\nThe measured value of a trait.\n\n\n\n\nunit\n\n\nUnits of the sampled trait value after aligning with AusTraits standards.\n\n\n\n\nentity_type\n\n\nA categorical variable specifying the entity corresponding to the trait values recorded.\n\n\n\n\nvalue_type\n\n\nA categorical variable describing the statistical nature of the trait value recorded.\n\n\n\n\nbasis_of_value\n\n\nA categorical variable describing how the trait value was obtained.\n\n\n\n\nreplicates\n\n\nNumber of replicate measurements that comprise a recorded trait measurement. A numeric value (or range) is ideal and appropriate if the value type is a mean, median, min or max. For these value types, if replication is unknown the entry should be unknown. If the value type is raw_value the replicate value should be 1. If the trait is categorical or the value indicates a measurement for an entire species (or other taxon) replicate value should be .na.\n\n\n\n\nbasis_of_record\n\n\nA categorical variable specifying from which kind of specimen traits were recorded.\n\n\n\n\nlife_stage\n\n\nA field to indicate the life stage or age class of the entity measured. Standard values are adult, sapling, seedling and juvenile.\n\n\n\n\npopulation_id\n\n\nA unique integer identifier for a population, where a population is defined as individuals growing in the same location (location_id /location_name) and plot (plot_context_id, a context category) and being subjected to the same treatment (treatment_context_id, a context category).\n\n\n\n\nindividual_id\n\n\nA unique integer identifier for an individual, with individuals numbered sequentially within each dataset by taxon by population grouping. Most often each row of data represents an individual, but in some datasets trait data collected on a single individual is presented across multiple rows of data, such as if the same trait is measured using different methods or the same individual is measured repeatedly across time.\n\n\n\n\nrepeat_measurements_id\n\n\nA unique integer identifier for repeat measurements of a trait that comprise a single observation, such as a response curve.\n\n\n\n\ntemporal_context_id\n\n\nA unique integer identifier assigned where repeat observations are made on the same individual (or population, or taxon) across time. The identifier links to specific information in the context table.\n\n\n\n\nsource_id\n\n\nFor datasets that are compilations, an identifier for the original data source.\n\n\n\n\nlocation_id\n\n\nA unique integer identifier for a location, with locations numbered sequentially within a dataset. The identifier links to specific information in the location table.\n\n\n\n\nentity_context_id\n\n\nA unique integer identifier indicating specific contextual properties of an individual, possibly including the individual’s sex or caste (for social insects).\n\n\n\n\nplot_context_id\n\n\nA unique integer identifier for a plot, where a plot is a distinct collection of organisms within a single geographic location, such as plants growing on different aspects or blocks in an experiment. The identifier links to specific information in the context table.\n\n\n\n\ntreatment_context_id\n\n\nA unique integer identifier for a treatment, where a treatment is any experimental manipulation to an organism’s growing/living conditions. The identifier links to specific information in the context table.\n\n\n\n\ncollection_date\n\n\nDate sample was taken, in the format yyyy-mm-dd, yyyy-mm or yyyy, depending on the resoluton specified. Alternatively an overall range for the study can be indicating, with the starting and ending sample date sepatated by a /, as in 2010-10/2011-03.\n\n\n\n\nmeasurement_remarks\n\n\nBrief comments or notes accompanying the trait measurement.\n\n\n\n\nmethod_id\n\n\nA unique integer identifier to distinguish between multiple sets of methods used to measure a single trait within the same dataset. The identifier links to specific information in the methods table.\n\n\n\n\nmethod_context_id\n\n\nA unique integer identifier indicating a trait is measured multiple times on the same entity, with different methods used for each entry. This field is only used if a single trait is measured using multiple methods within the same dataset. The identifier links to specific information in the context table.\n\n\n\n\noriginal_name\n\n\nName given to taxon in the original data supplied by the authors.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data structure</span>"
    ]
  },
  {
    "objectID": "database_structure.html#taxa",
    "href": "database_structure.html#taxa",
    "title": "7  Data structure",
    "section": "7.7 Taxa",
    "text": "7.7 Taxa\nDescription: A table containing details on taxa that are included in the table traits. We have attempted to align species names with known taxonomic units in the Australian Plant Census (APC) and/or the Australian Plant Names Index (APNI); the sourced information is released under a CC-BY3 license.\nVersion 0.1.0 of AusTraits contains records for 7324 different taxa.\nContent:\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\ntaxon_name\n\n\nScientific name of the taxon on which traits were sampled, without authorship. When possible, this is the currently accepted (botanical) or valid (zoological) scientific name, but might also be a higher taxonomic level.\n\n\n\n\ntaxonomic_dataset\n\n\nName of the taxonomy (tree) that contains this concept. ie. APC, AusMoss etc.\n\n\n\n\ntaxon_rank\n\n\nThe taxonomic rank of the most specific name in the scientific name.\n\n\n\n\ntrinomial\n\n\nThe infraspecific taxon name match for an original name. This column is assigned na for taxon name that are at a broader taxonomic_resolution.\n\n\n\n\nbinomial\n\n\nThe species-level taxon name match for an original name. This column is assigned na for taxon name that are at a broader taxonomic_resolution.\n\n\n\n\ngenus\n\n\nGenus of the taxon without authorship.\n\n\n\n\nfamily\n\n\nFamily of the taxon.\n\n\n\n\ntaxon_distribution\n\n\nKnown distribution of the taxon, by Australian state.\n\n\n\n\nestablishment_means\n\n\nStatement about whether an organism or organisms have been introduced to a given place and time through the direct or indirect activity of modern humans.\n\n\n\n\ntaxonomic_status\n\n\nThe status of the use of the scientificName as a label for the taxon in regard to the ‘accepted (or valid) taxonomy’. The assigned taxonomic status must be linked to a specific taxonomic reference that defines the concept.\n\n\n\n\ntaxon_id\n\n\nAn identifier for the set of taxon information (data associated with the taxon class). May be a global unique identifier or an identifier specific to the data set. Must be resolvable within this dataset.\n\n\n\n\ntaxon_id_genus\n\n\nAn identifier for the set of taxon information (data associated with the taxon class) for the genus associated with a taxon name. May be a global unique identifier or an identifier specific to the data set. Must be resolvable within this dataset.\n\n\n\n\ntaxon_id_family\n\n\nAn identifier for the set of taxon information (data associated with the taxon class) for the family associated with a taxon name. May be a global unique identifier or an identifier specific to the data set. Must be resolvable within this dataset.\n\n\n\n\nscientific_name\n\n\nThe full scientific name, with authorship and date information if known.\n\n\n\n\nscientific_name_id\n\n\nAn identifier for the set of taxon information (data associated with the taxon class). May be a global unique identifier or an identifier specific to the data set. Must be resolvable within this dataset.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data structure</span>"
    ]
  },
  {
    "objectID": "database_structure.html#taxonomic_updates",
    "href": "database_structure.html#taxonomic_updates",
    "title": "7  Data structure",
    "section": "7.8 Taxonomic_updates",
    "text": "7.8 Taxonomic_updates\nDescription: A table of all taxonomic changes implemented in the construction of AusTraits. Changes are determined by comparing the originally submitted taxon name against the taxonomic names listed in the taxonomic reference files, best placed in a subfolder in the config folder . Cross referencing with the traits table is possible using combinations of the variables dataset_id and taxon_name.\nContent:\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\ndataset_id\n\n\nPrimary identifier for each study contributed to AusTraits; most often these are scientific papers, books, or online resources. By default this should be the name of the first author and year of publication, e.g. Falster_2005.\n\n\n\n\noriginal_name\n\n\nName given to taxon in the original data supplied by the authors.\n\n\n\n\naligned_name\n\n\nThe taxon name without authorship after implementing automated syntax standardisation and spelling changes as well as manually encoded syntax alignments for this taxon in the metadata file for the corresponding dataset_id. This name has not yet been matched to the currently accepted (botanical) or valid (zoological) taxon name in cases where there are taxonomic synonyms, isonyms, orthographic variants, etc.\n\n\n\n\ntaxonomic_resolution\n\n\nThe rank of the most specific taxon name (or scientific name) to which a submitted orignal name resolves.\n\n\n\n\ntaxon_name\n\n\nScientific name of the taxon on which traits were sampled, without authorship. When possible, this is the currently accepted (botanical) or valid (zoological) scientific name, but might also be a higher taxonomic level.\n\n\n\n\naligned_name_taxon_id\n\n\nAn identifier for the aligned name before it is updated to the currently accepted name usage. This may be a global unique identifier or an identifier specific to the data set. Must be resolvable within this dataset.\n\n\n\n\naligned_name_taxonomic_status\n\n\nThe status of the use of the aligned_name as a label for a taxon. Requires taxonomic opinion to define the scope of a taxon. Rules of priority then are used to define the taxonomic status of the nomenclature contained in that scope, combined with the experts opinion. It must be linked to a specific taxonomic reference that defines the concept.\n\n\n\n\nBoth the original and the updated taxon names are included in the traits table.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data structure</span>"
    ]
  },
  {
    "objectID": "database_structure.html#definitions",
    "href": "database_structure.html#definitions",
    "title": "7  Data structure",
    "section": "7.9 Definitions",
    "text": "7.9 Definitions\nDescription: A copy of the definitions for all tables and terms. Information included here was used to process data and generate any documentation for the study.\nDetails on trait definitions: The allowable trait names and trait values are defined in the definitions file. Each trait is labelled as either numeric or categorical. An example of each type is as follows. For an example, see the the Trait definitions for AusTraits.\nleaf_mass_per_area\n\nnumber of records: 2261\nnumber of studies: 13\n\nwoodiness\n\nnumber of records: 0\nnumber of studies: 0",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data structure</span>"
    ]
  },
  {
    "objectID": "database_structure.html#contributors",
    "href": "database_structure.html#contributors",
    "title": "7  Data structure",
    "section": "7.10 Contributors",
    "text": "7.10 Contributors\nDescription: A table of people contributing to each study.\nContent:\n\n\n\n\nkey\n\n\nvalue\n\n\n\n\n\n\ndataset_id\n\n\nPrimary identifier for each study contributed to AusTraits; most often these are scientific papers, books, or online resources. By default this should be the name of the first author and year of publication, e.g. Falster_2005.\n\n\n\n\nlast_name\n\n\nLast name of the data collector.\n\n\n\n\ngiven_name\n\n\nGiven names of the data collector.\n\n\n\n\nORCID\n\n\nORCID of the data collector.\n\n\n\n\naffiliation\n\n\nLast known institution or affiliation.\n\n\n\n\nadditional_role\n\n\nAdditional roles of data collector, mostly contact person.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data structure</span>"
    ]
  },
  {
    "objectID": "database_structure.html#sources",
    "href": "database_structure.html#sources",
    "title": "7  Data structure",
    "section": "7.11 Sources",
    "text": "7.11 Sources\nFor each dataset in the compilation there is the option to list primary and secondary citations. The primary citation is defined as, The original study in which data were collected. The secondary citation is defined as, A subsequent study where data were compiled or re-analysed.\nThe element sources includes bibtex versions of all sources which can be imported into your reference library:\nOr individually viewed:\nA formatted version of the sources also exists within the table methods.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data structure</span>"
    ]
  },
  {
    "objectID": "database_structure.html#metadata",
    "href": "database_structure.html#metadata",
    "title": "7  Data structure",
    "section": "7.12 Metadata",
    "text": "7.12 Metadata\nDescription: Metadata associated with the dataset, including title, creators, license, subject, funding sources.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data structure</span>"
    ]
  },
  {
    "objectID": "database_structure.html#build_info",
    "href": "database_structure.html#build_info",
    "title": "7  Data structure",
    "section": "7.13 Build_info",
    "text": "7.13 Build_info\nDescription: A description of the computing environment used to create this version of the dataset, including version number, git commit and R session_info.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data structure</span>"
    ]
  },
  {
    "objectID": "database_metadata.html",
    "href": "database_metadata.html",
    "title": "8  Overview of traits.build ontology",
    "section": "",
    "text": "8.1 Using the OBOE structure\nThe traits.build ontology is built upon the Extensible Observation Ontology (OBOE). OBOE was developed explicitly to document the multitude of information associated with ecological observations.\nOBOE has 4 core classes:\nWithin the OBOE structure, observations can be grouped into a series of nested observation collections, representing broader groupings of measurements. This flexibility within the OBOE structure, means that the database structure can uniquely indicate which traits are measured at the",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Overview of traits.build ontology</span>"
    ]
  },
  {
    "objectID": "database_metadata.html#using-the-oboe-structure",
    "href": "database_metadata.html#using-the-oboe-structure",
    "title": "8  Overview of traits.build ontology",
    "section": "",
    "text": "the entity, the “thing” being measured. For instance, an entity might be an individual, population or species.\nan observation of the entity at a single point in time. An observation can be comprised of multiple measurements and therefore can be represented by multiple rows of data within a database.\nthe measurements that comprise an observation, where each measurement is of a single trait. A single measured value is associated with each measurement.\nthe trait being measured, which must be documented within the accompanying trait dictionary.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Overview of traits.build ontology</span>"
    ]
  },
  {
    "objectID": "database_metadata.html#metadata-for-each-trait-value",
    "href": "database_metadata.html#metadata-for-each-trait-value",
    "title": "8  Overview of traits.build ontology",
    "section": "8.2 Metadata for each trait value",
    "text": "8.2 Metadata for each trait value\nEcological data is only meaningful when each data value is linked to all necessary metadata. \nThe OBOE structure also accommodates this requirement, allowing various metadata and context types to be linked to each of the core classes.\nThe following metadata/context fields are linked to each measurement in traits.build:\n\nEntity metadata \n\nentity type (species, population, individual) \nlife stage (adult, seedling, sapling) \nbasis of record (field, glasshouse, field experiment) \n\nsex, size, etc.\n\n\n\nValue metadata \n\nvalue type (mean, minimum, maximum, mode, raw) \nbasis of value (measurement, expert observation, literature) \nreplicate count \nunits \n\n\n\n\nMeasurement metadata \n\ntrait collection methods \n\n\n\nLocation properties \n\nlatitude/longitude \nvegetation description \nlocation properties, such as \n\nsoil nutrients (soil N)\n\nclimate variables (MAT, MAP, aridity index)\n\nfire history (fire intensity, fire severity, years since fire)\n\n\n\n\nContext properties\nThat is, anything else recorded about a specific row of data that explains differences between trait values across rows of data, such as\n\nentity contexts (e.g. plant sex, plant age, leaf type measured, tree diameter)\ntreatment contexts (e.g. nutrient addition treatment, drought treatment)\nplot contexts (differences within a single “location”; e.g. slope position, fire history)\ntemporal contexts (e.g. sampling season, sampling time of day)\nmethod contexts (e.g. canopy position, branch length sampled).\n\n\n\n\nTaxonomic information \n\ngenus, family \nfull scientific name \ntaxon rank \ntaxon identifiers (from APC, APNI) \n\n\n\nDataset metadata \n\ncollection date \ndataset description \ndataset sampling strategy \ndataset citation \ndata collectors",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Overview of traits.build ontology</span>"
    ]
  },
  {
    "objectID": "database_metadata.html#documenting-the-relationships-between-variables",
    "href": "database_metadata.html#documenting-the-relationships-between-variables",
    "title": "8  Overview of traits.build ontology",
    "section": "8.3 Documenting the relationships between variables",
    "text": "8.3 Documenting the relationships between variables\nTo satisfy the OBOE structure, it is important that these many metadata fields are linked to the correct class, a measurement, specific observation or observation collection, entity, value, etc.\nThe many identifiers present within the traits.build data tables are required to accomplish this.\nFor instance:\n\na population is defined as a group of individuals of the same species, subjected to the same treatment and plot contexts and occurring in the same location. Populations are defined by having a common population_id.\na temporal_context indicates measurements on an entity have been stratified across time, such as occurs when the same individual is measured during two different growing seasons. The column temporal_context_id in the traits table offers an identifier that links to details about the temporal context in the context table.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Overview of traits.build ontology</span>"
    ]
  },
  {
    "objectID": "dictionary.html",
    "href": "dictionary.html",
    "title": "9  Trait dictionary",
    "section": "",
    "text": "9.1 Examples\nA core component of the traits.build database structure is a trait dictionary that clearly defines and describes each trait concept included within the trait database.\nA description of the trait dictionary is available at: Wenk, E.H., Sauquet, H., Gallagher, R.V., Brownlee, R., Boettiger, C., Coleman, D., Yang, S., Auld, T., Barrett, R., Brodribb, T., Choat, B., Dun, L., Ellsworth, D., Gosper, C., Guja, L., Jordan, G.J., Le Breton, T., Leigh, A., Lu-Irving, P., Medlyn, B., Nolan, R., Ooi, M., Sommerville, K.D., Vesk, P., White, M., Wright, I.J., Falster, D.S., 2024. The AusTraits plant dictionary. Sci Data 11, 537. DOI: 10.1038/s41597-024-03368-z.\nBuilding upon the standard outlined by the ETS Ecological Trait-data Standard, all numeric traits must have standard units and an allowable range. Categorical traits must have a list of allowable trait values.\nEach trait concept must have a complete, explicit definition to eliminate confusion between trait concepts.\nThe trait dictionary is compiled in a simple yml format, allowing trait definitions to be easily added and edited.\nA sample numeric trait definition:\nseed_dry_mass:\n    label: Seed dry mass\n    description: A seed morphology trait [TO:0000184] which is the dry [PATO:0001824]\n    mass [PATO:0000125] of a mature [PATO:0001701] seed [PO:0009010].;Dry mass\n    of a mature seed, including both oven dried and air-dried samples.\n    comments: Standard methods people will have used to dry seeds include, 'fresh'\n    (at dispersal, mature); 'air dried' (at local ambient conditions); 'seed bank\n    air dried' (to 15% relative humidity); and 'oven dried' (&gt;100 deg C for a\n    set number of hours; e.g. seed bank standard is 103 deg C for 17 hours). It\n    is expected that some observations in AusTraits mapped onto â€˜seed_dry_mass'\n    will actually include both the seed and some dispersal tissue, if the two\n    cannot easily be separated; these should be mapped to 'diaspore_dry_mass'.\n    type: numeric\n    units: mg\n    allowed_values_min: 1.0e-05\n    allowed_values_max: 1000000.0\nA sample categorical trait definition:\nleaf_compoundness:\n    label: Leaf compoundness\n    description: A leaf shape trait [TO:0000492] which is whether a leaf [PO:0025034]\n    is a simple leaf [PO:0020042] or is divided into leaflets [PO:0020049] making\n    it a compound leaf [PO:0020043].;A binary trait that indicates whether a leaf\n    lamina is simple or divided into discontinuous leaflets (compound).\n    comments: See also the trait 'leaf_division' for more detailed leaf compoundness\n    trait values. Note that there might be some species that grade from deeply\n    lobed simple leaves (see trait `leaf_lobation`)  to compound leaves.\n    type: categorical\n    allowed_values_levels:\n        compound: A leaf that is divided into multiple leaflets. [PO:0020043]\n        simple: A leaf with a single undivided blade. [PO:0020042]\nFor additional examples, see the complete dictionary used for the AusTraits database.",
    "crumbs": [
      "Data structure and standard",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Trait dictionary</span>"
    ]
  },
  {
    "objectID": "traits_build.html",
    "href": "traits_build.html",
    "title": "10  The package",
    "section": "",
    "text": "The traits.build package provides a workflow for harmonising data from disconnected primary sources and arises from the AusTraits project. In 2023 this package was spun out as a separate package from the autraits.build repository.\nThe traits.build package provides the functions needed to build a compilation from the primary sources ino a standardised database. specified\nThe core components of the {traits.build} package are:\n\n15 functions functions, supplemented by a detailed protocol to wrangle diverse datasets into input files with a common structure that captures both the trait data and all essential metadata and context properties. These are a table (data.csv) containing all trait data, taxon names, location names (if relevant), and any context properties (if relevant) and a structured metadata file (metadata.yml) that assigns the columns from the data.csv file to their specific variables and maps all additional dataset metadata in a structured format.\nAn R-based pipeline to combine the input files into a single harmonised database with aligned trait names, aligned units, aligned categorical trait values, and aligned taxon names. Four database-specific configuration files are required for the build process, 1) a trait dictionary; 2) a units conversion file; 3) a taxon list; and 4) a database metadata file.\n\nGuided by the information in the configuration files, the R-scripted workflow combines the data.csv and metadata.yml files for the individual datasets into a unified, harmonised database. There are three distinct steps to this process, processed by a trio of functions, dataset_configure, dataset_process, and dataset_taxonomic_updates. These functions cyclically build each dataset, only combining them into a single database at the end of the workflow.\nA combination of automated tests and other quality controls ensure each dataset has been appropriately merged in and the output data are reliable, accurate, and supported by detailed metadata.",
    "crumbs": [
      "Creating with `traits.build`",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The package</span>"
    ]
  },
  {
    "objectID": "tutorial_compilation.html",
    "href": "tutorial_compilation.html",
    "title": "11  Tutorial: Example compilation",
    "section": "",
    "text": "11.1 Clone traits.build-template\nThis tutorial walks you through an example of creating a traits.build database from scratch using the traits.build template. We then look at examples of how to add datasets to the database using the traits.build workflow.\ntraits.build-template is a GitHub repository that contains:\nTo clone the repository, either visit the GitHub repository and click on the green &lt;&gt; Code tab toward the upper right corner of the landing page, or clone the repository through GitHub desktop, R Studio, or your choice of Git client.",
    "crumbs": [
      "Creating with `traits.build`",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Tutorial: Example compilation</span>"
    ]
  },
  {
    "objectID": "tutorial_compilation.html#clone-traits.build-template",
    "href": "tutorial_compilation.html#clone-traits.build-template",
    "title": "11  Tutorial: Example compilation",
    "section": "",
    "text": "Core files required to build your own database:\n\na sample trait dictionary\na unit conversions file\na generic database metadata file\na placeholder taxon list\na script of useful R functions\n\nTwo pre-added datasets.\n\nSee how metadata is documented in fully propagated metadata files.\nBuild a skeletal database before adding your own datasets.\n\nDatasets with explicit tutorials for filling in the dataset metadata files.\n\nThe tutorials for these datasets introduce you to the traits.build functions.\nBy working through the dataset tutorials, you are progressively introduced to how the complexities of ecological datasets can be documented within the traits.build structure\nThe datasets offer explicit examples of the types of complexities summarised in the Adding Data vignette.\nAs of September 2023 there are 3 tutorials, but this will expand to 6 tutorials by October 2023.",
    "crumbs": [
      "Creating with `traits.build`",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Tutorial: Example compilation</span>"
    ]
  },
  {
    "objectID": "tutorial_compilation.html#build-the-example",
    "href": "tutorial_compilation.html#build-the-example",
    "title": "11  Tutorial: Example compilation",
    "section": "11.2 Build the example",
    "text": "11.2 Build the example\nOnce you have cloned the repository and installed the package, the next step is to build the simplistic sample database:\n\nbuild_setup_pipeline(method = \"base\", database_name = \"traits.build_database\")\nsource(\"build.R\")\n\nAs described in the chapter on data structure the database is comprised of a series of relational tables and additional lists with metadata.\nOnce you’ve explored and feel familiar with the basic structure of a traits.build database, continue onto the tutorials to learn how to add datasets using the traits.build workflow.",
    "crumbs": [
      "Creating with `traits.build`",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Tutorial: Example compilation</span>"
    ]
  },
  {
    "objectID": "file_organisation.html",
    "href": "file_organisation.html",
    "title": "12  File organisation",
    "section": "",
    "text": "12.1 Repository structure\nThis chapter describes the typical files you may encounter in a traits.build compilation. The description is based on the austraits.build compilation.\nWe strongly suggest you create a standalone folder for your repository, e.g. austraits.build. This folder should contain all files needed to build your compilation. We’re big fans of github as a platform for collaboration. If you’re not familiar with git or github, we suggest you check out the happy git with R book.\nThe main directory for the austraits.build repository contains the following files and folders, with purpose as indicated. Not all of these files are required for a compilation, some are used for extra features such as website. They are included here for completeness.\nFiles used for data compilation\nR project file\nFiles for maintaining a repo on github\nAdditional files describing the compendium and testing the database build process",
    "crumbs": [
      "Creating with `traits.build`",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>File organisation</span>"
    ]
  },
  {
    "objectID": "file_organisation.html#repository-structure",
    "href": "file_organisation.html#repository-structure",
    "title": "12  File organisation",
    "section": "",
    "text": "├── remake.yml/build.R    # instructions for build\n├── config                # configuration files\n├── data                  # raw data files\n├── R                     # folder with custom R functions\n├── export                # folder for output\n└── scripts               # R scripts for processing files before/after build\n\n├── austraits.build.Rproj     # Rstudio project\n\n├── README.md         # landing page\n├── .github           # folder containing github actions, issue templates, code of conduct\n├── LICENCE\n├── NEWS.md\n├── inst              # contains images that appear on github repo \n\n├── DESCRIPTION           # compendium description\n├── tests                 # tests for whether database builds",
    "crumbs": [
      "Creating with `traits.build`",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>File organisation</span>"
    ]
  },
  {
    "objectID": "file_organisation.html#config-folder",
    "href": "file_organisation.html#config-folder",
    "title": "12  File organisation",
    "section": "12.2 /config folder",
    "text": "12.2 /config folder\nThe folder config contains four files which govern the building of the dataset.\nconfig\n├── metadata.yml\n├── traits.yml\n├── taxon_list.csv\n└── unit_conversions.csv\n\nmetadata.yml\nThe file metadata.yml documents dataset-level metadata, including a database description, authors, and funders.\n\n\ntraits.yml\nThe file traits.yml provides the trait definitions used to compile the trait database, including allowable trait values. See creating a trait dictionary for more information on the process of creating this file. A .yml file is a structured data file where information is presented in a hierarchical format (see appendix for details).\n\n\ntaxon_list.csv\nThe file taxon_list.csv is our master list of taxa in the trait database.\nIt includes all unique taxon names after typos have been corrected (through taxonomic_updates). It includes both accepted/valid taxon concepts and outdated taxonomic names. It includes taxon names indicating a taxon that can be identified to species and names that can only be resolved to a lower taxon rank.\nThere are only three required columns within taxon_list.csv: aligned_name, taxon_name and taxon_rank. In the file, aligned_name refers to the taxon name after any typos have been corrected, while taxon_name is the taxon name following updates to the currently accepted/valid taxon name (when available). Taxon_rank indicates the resolution of the taxon_name.\nHowever, it is best practice to include additional columns when available, including taxon identifiers for species (& infraspecific taxon concepts) or genera that align with known taxon concepts.\nThe file taxon_list.csv should be added to if a study includes taxa not previously represented in the trait database. It must be compiled outside of the traits.build workflow, as each dataset will use different taxonomic datasets, with different columns of information.\nFor AusTraits, the taxonomic datasets referenced are the two vascular plant lists within the National Species Lists (NSL), the APC (Australian Plant Census) and the Australian Plant Name Index (APNI). The workflow used by AusTraits to rebuild the taxon list is available here.\n\n\n\n\n\n\ntaxon_name\naligned_name\nfamily\ntaxonomic_dataset\ntaxon_rank\naligned_name_taxonomic_status\ntaxon_id\nscientific_name\nscientific_name_id\n\n\n\n\nAbelia x grandiflora\nAbelia x grandiflora\nCaprifoliaceae\nAPC\nSpecies\naccepted\nhttps://id.biodiversity.org.au/taxon/apni/51432945\nAbelia x grandiflora (Rovelli ex AndrÃ©) Rehder\nhttps://id.biodiversity.org.au/name/apni/190758\n\n\nAbelmoschus ficulneus\nAbelmoschus ficulneus\nMalvaceae\nAPC\nSpecies\naccepted\nhttps://id.biodiversity.org.au/node/apni/2897916\nAbelmoschus ficulneus (L.) Wight\nhttps://id.biodiversity.org.au/name/apni/55929\n\n\nAbelmoschus manihot\nAbelmoschus manihot\nMalvaceae\nAPC\nSpecies\naccepted\nhttps://id.biodiversity.org.au/node/apni/2901085\nAbelmoschus manihot (L.) Medik.\nhttps://id.biodiversity.org.au/name/apni/55937\n\n\nAbelmoschus manihot subsp. manihot\nAbelmoschus manihot subsp. manihot\nMalvaceae\nAPC\nSubspecies\naccepted\nhttps://id.biodiversity.org.au/node/apni/2917035\nAbelmoschus manihot (L.) Medik. subsp. manihot\nhttps://id.biodiversity.org.au/name/apni/116920\n\n\nAbelmoschus manihot subsp. tetraphyllus\nAbelmoschus manihot subsp. tetraphyllus\nMalvaceae\nAPC\nSubspecies\naccepted\nhttps://id.biodiversity.org.au/node/apni/2892917\nAbelmoschus manihot subsp. tetraphyllus (Roxb. ex Hornem.) Borss.Waalk.\nhttps://id.biodiversity.org.au/name/apni/55945\n\n\nAbelmoschus moschatus\nAbelmoschus moschatus\nMalvaceae\nAPC\nSpecies\naccepted\nhttps://id.biodiversity.org.au/node/apni/2900572\nAbelmoschus moschatus Medik.\nhttps://id.biodiversity.org.au/name/apni/55953\n\n\nAbelmoschus moschatus subsp. biakensis\nAbelmoschus moschatus subsp. biakensis\nMalvaceae\nAPC\nSubspecies\naccepted\nhttps://id.biodiversity.org.au/node/apni/2907435\nAbelmoschus moschatus subsp. biakensis (Hochr.) Borss.Waalk.\nhttps://id.biodiversity.org.au/name/apni/116595\n\n\nAbelmoschus moschatus subsp. moschatus\nAbelmoschus moschatus subsp. moschatus\nMalvaceae\nAPC\nSubspecies\naccepted\nhttps://id.biodiversity.org.au/node/apni/2911283\nAbelmoschus moschatus Medik. subsp. moschatus\nhttps://id.biodiversity.org.au/name/apni/243806\n\n\nAbelmoschus moschatus subsp. tuberosus\nAbelmoschus moschatus subsp. tuberosus\nMalvaceae\nAPC\nSubspecies\naccepted\nhttps://id.biodiversity.org.au/node/apni/2919287\nAbelmoschus moschatus subsp. tuberosus (Span.) Borss.Waalk.\nhttps://id.biodiversity.org.au/name/apni/55961\n\n\nAbildgaardia ovata\nAbildgaardia ovata\nCyperaceae\nAPC\nSpecies\naccepted\nhttps://id.biodiversity.org.au/node/apni/2919627\nAbildgaardia ovata (Burm.f.) Kral\nhttps://id.biodiversity.org.au/name/apni/150737\n\n\n\n\n\n\n\n\n\n\nunit_conversions.csv\nThe file unit_conversions.csv defines the unit conversions that are used when converting contributed trait data to common units, e.g.\n\n\n\n\nunit_from\nunit_to\nfunction\n\n\n\n\n%\nmg/g\nx*10\n\n\n%\ng/g\nx*0.01\n\n\n%\nmg/mg\nx*0.01\n\n\n%\nmg/kg\nx*10000\n\n\n%\n{dimensionless}\nx*.01\n\n\n%\n{count}/{count}\nx*.01\n\n\n{dimensionless}\n{count}/{count}\nx*1\n\n\na\nmo\nx*12\n\n\n{count}/m2\n{count}/mm2\nx*1/1000000\n\n\ncm\nm\nx*0.01",
    "crumbs": [
      "Creating with `traits.build`",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>File organisation</span>"
    ]
  },
  {
    "objectID": "file_organisation.html#data-folder",
    "href": "file_organisation.html#data-folder",
    "title": "12  File organisation",
    "section": "12.3 /data folder",
    "text": "12.3 /data folder\nThe folder data contains the raw data from individual studies included in the trait database.\nRecords within the data folder are organised as coming from a particular study, defined by the dataset_id. Data from each study are organised into a separate folder, with two files:\n\ndata.csv: a table containing the actual trait data.\nmetadata.yml: a file that contains study metadata (source, methods, locations, and context), maps trait names and units onto standard types, and lists any substitutions applied to the data in processing.\n\nThe folder data thus contains a long list of folders, one for each study and each containing two files:\ndata\n├── Angevin_2010\n│   ├── data.csv\n│   └── metadata.yml\n├── Barlow_1981\n│   ├── data.csv\n│   └── metadata.yml\n├── Bean_1997\n│   ├── data.csv\n│   └── metadata.yml\n├── ....\n\nwhere Angevin_2010, Barlow_1981, & Bean_1997 are each a unique dataset_id in the final dataset.\nThis file can be added to within specific traits.build projects, as required for different dataset styles.",
    "crumbs": [
      "Creating with `traits.build`",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>File organisation</span>"
    ]
  },
  {
    "objectID": "create_dictionary.html",
    "href": "create_dictionary.html",
    "title": "13  Creating a dictionary",
    "section": "",
    "text": "All with data within a trait database must be including in an accompanying trait dictionary.\nFollowing the Ecological Trait-data Standard, ETS:\n\nall traits must have a label and definition\nall traits must be defined as being either type: numeric or type: categorical\nnumeric traits must have standard units and an allowable range\ncategorical traits must have a list of allowable trait values.\n\nExamples are available here, while the complete AusTraits dictionary is available here.\nThe trait dictionary is compiled in a simple yml format, allowing trait definitions to be easily added and edited.\nCreating a trait dictionary that allows a database to build is quick; it simply requires filling in a brief definition and the required units/range/trait value fields. However, drafting meaningful, reusable trait definitions and categorical trait values requires complete, explicit definitions to eliminate confusion between trait concepts. The definitions and trait values should be agreed upon by the broader research community to allow the database to be reused by other researchers and supported by the research community.\nFor instance, to achieve these broader goals, the trait dictionary used for the AusTraits database has been formalised into a standalone output, the AusTraits Plant Dictionary (APD), available in both machine-readable and humman-friendly outputs through the w3id.org/APD namespace. The traits included in the APD have undergone a rigorous internal and external review process to ensure the trait concepts and their definitions are complete and robust, as described in the The AusTraits Plant Dictionary paper.",
    "crumbs": [
      "Creating with `traits.build`",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Creating a dictionary</span>"
    ]
  },
  {
    "objectID": "adding_data_brief.html",
    "href": "adding_data_brief.html",
    "title": "14  Adding datasets, an introduction",
    "section": "",
    "text": "This section gives a brief overview of how to add datasets to the database. For a more detailed guide, see the Guide to adding data part of this book, starting with Tutorial: Adding datasets.\nAll steps must be followed for the automated workflow to proceed without problems.\n\nInstall the {traits.build} R-package from github\nClone the traits.build-template repository from github\nFor each dataset, create a new branch in the repo, named for the new dataset_id in author_year format, e.g. Gallagher_2014.\nCreate a new folder within the folder data with the name dataset_id, e.g. Gallagher_2014.\nPrepare the file data.csv and place it within the new folder.\nPrepare the file metadata.yml and place it within the new folder.\nRun tests on the newly added dataset and correct the data.csv and metadata.yml files as necessary.\nAdd the new study into the build framework and rebuild the trait database, by running build_setup_pipeline() and source(build.R).\n\nYou can then rebuild the database, including the new dataset.\n\nRun quality checks on the newly added dataset and correct the data.csv and metadata.yml files as necessary.\nGenerate and proofread a report on the data. In particular, check that numeric trait values fall within a logical range relative to other studies, and that individual trait observations are not unnecessarily excluded because their trait values are unsupported.\nReturn to step 6 if changes are made to the data.csv or metadata.yml files.\nPush the GitHub branch to your database repository.\n\nThe best place to get started learning how to add datasets is to work through a series of 7 tutorials. Each introduces you to specific traits.build functions designed to facilitate the addition of dataset metadata or the metadata formats for specific types of datasets.\nThe chapter Adding datasets, a lengthy guide then offers a comprehensive guide to generating the data.csv and metadata.yml files and error-checking your results. This document is likely overwhelming until you are familiar with the traits.build workflow and metadata format.\nIt may also help to download one of the two sample datasets to use as a template for your own files and a guide on required content. Or alteratively, to see a greater diversity of dataset styles, look at the austraits.build repository\nYou should look at the files in the config folder, particularly the definitions file for the list of traits in AusTraits and how trait definitions are formatted.",
    "crumbs": [
      "Creating with `traits.build`",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Adding datasets, an introduction</span>"
    ]
  },
  {
    "objectID": "publishing.html",
    "href": "publishing.html",
    "title": "15  Publishing",
    "section": "",
    "text": "traits.build is an R package that was first developed to build AusTraits, a harmonised, open-source database of Australian plant traits. The code has been transformed into a standalone package allowing anyone to build a relational, tabular database for any taxonomic group and any collection of traits.\nThe project’s guiding principles are to:\n\nCreate open-source, harmonised, reproducible databases from disparate datasets.\nProvide a fully transparent workflow.\nOffer a relational database structure that fully documents the contextual data essential to interpreting ecological data.\nOffer a straightforward, robust template for building a trait dictionary.\nOffer a database structure that is flexible enough to accommodate the complexities inherent to ecological data.\nOffer a database structure that is underlain by a documented ontology, ensuring each database field is interpretable and interoperable with other databases and data structures.",
    "crumbs": [
      "Creating with `traits.build`",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Publishing</span>"
    ]
  },
  {
    "objectID": "tutorial_datasets.html",
    "href": "tutorial_datasets.html",
    "title": "16  Tutorial: Adding datasets",
    "section": "",
    "text": "This part of the traits.build book contains a series of tutorials, teaching you for to add datasets to a traits.build database.\nPrior to beginning these tutorials, ensure you have:\n\nInstalled the {traits.build} R package\n\nremotes::install_github(\"traitecoevo/traits.build\")\n\nCloned the traitecoevo/traits.build-template repository.\n\n\nClick on the green &lt;&gt; Code tab toward the upper right corner of https://github.com/traitecoevo/traits.build-template.\n\n\nBuilt the example database.\n\nThe tutorial is divided into the following sections:\n\ntutorial 1: Adding a simple dataset.\n\ntutorial 2: Adding a more complex dataset.\n\ntutorial 3: Adding contexts and complex units.\n\ntutorial 4: Additional complexities for adding datasets.\n\ntutorial 5: Adding datasets with multiple columns for a trait.\n\ntutorial 6: Adding datasets with repeat measurements (response curves).\n\ntutorial 7: Adding a long format dataset and mapping in units from a column.\n\nOnce you’ve worked your way through the tutorials and begin adding your own datasets, you’ll also want to refer to:\n\nlengthy guide to adding datasets\n\nguide to common issues when adding data.\n\nIf you are building a {traits.build} compiled trait database and have specific problems that should be covered in additional tutorials or require better explanations, please post an issue.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Tutorial: Adding datasets</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_1.html",
    "href": "tutorial_dataset_1.html",
    "title": "17  Tutorial 1: Adding a simple dataset",
    "section": "",
    "text": "17.1 Overview\nThis is the first of five tutorials on adding datasets to your traits.build database. This introduces you to the basic functions, the user input required, and the manual manipulations required to complete the dataset’s metadata file. The next four tutorials introduce you to progressively more complex datasets, functions, and decisions.\nBefore you begin this tutorial, ensure you have installed traits.build, cloned the traits.build-template repository, and have successfully build a database from the datasets in traits.build-template . Instructions are available at Tutorial: Example compilation.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tutorial 1: Adding a simple dataset</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_1.html#overview",
    "href": "tutorial_dataset_1.html#overview",
    "title": "17  Tutorial 1: Adding a simple dataset",
    "section": "",
    "text": "Goals\n\nLearn how to build a metadata.yml file for a dataset.\nLearn how to merge a new dataset into a traits.build database.\n\n\n\nNew functions introduced\n\nmetadata_create_template\nmetadata_add_source_doi\nmetadata_add_locations\nmetadata_add_traits\ndataset_test\nbuild_setup_pipeline",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tutorial 1: Adding a simple dataset</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_1.html#adding-tutorial_dataset_1",
    "href": "tutorial_dataset_1.html#adding-tutorial_dataset_1",
    "title": "17  Tutorial 1: Adding a simple dataset",
    "section": "17.2 Adding tutorial_dataset_1",
    "text": "17.2 Adding tutorial_dataset_1\n\nEnsure the dataset folder contains the correct data files\nIn the traits.build-template repository, there is a folder titled tutorial_dataset_1 within the data folder. \n\nEnsure that this folder exists on your computer. \nThe file data.csv exists within the tutorial_dataset_1 folder. \nThere is a folder raw nested within the tutorial_dataset_1 folder, that contains one file, notes.txt. \n\n\n\nSource necessary functions\n\nSource the functions in the traits.build package:\n\n\nlibrary(traits.build)\n\n\n\nUse functions to create a metadata.yml file\n\nCreate a metadata template\nAll dataset metadata is documented within a .yml file that also resides within the dataset’s folder.\nA function quickly creates the skeletal metadata.yml file.\n\nmetadata_create_template(\"tutorial_dataset_1\")\n\nThis function cycles through a series of user-input menus, querying about both the data format (long versus wide) and which columns contain which variables (taxon name, location name, individual identifiers, collection date).\n\nThe menus are shown below, with the menu in blue and the appropriate user input in red.\nIs the data long or wide format?\n\n1: Long\n2: Wide\nSelection: 2\nThis dataset is considered wide, because the data for each trait is documented in its own column.\nSelect column for taxon_name\n\n1: Species\n2: site\n3: LMA (mg mm-2)\n4: Leaf nitrogen (mg mg-1)\n5: leaf size (mm2)\n6: latitude (deg)\n7: longitude (deg)\n8: description`\nSelection: 1\nSelect 1 since taxon names are documented in the column Species.\nSelect column for location_name\n1: NA\n2: Species\n3: site\n4: LMA (mg mm-2)\n5: Leaf nitrogen (mg mg-1)\n6: leaf size (mm2)\n7: latitude (deg)\n8: longitude (deg)\n9: description\nSelection: 3\nSelect 3 since location names are documented in the column site.\nSelect column for individual_id\n1: NA\n2: Species\n3: site\n4: LMA (mg mm-2)\n5: Leaf nitrogen (mg mg-1)\n6: leaf size (mm2)\n7: latitude (deg)\n8: longitude (deg)\n9: description\n\nSelection: 1\nThis dataset does not include a column for individual_id, so 1: NA is the appropriate input.\nSelect column for collection_date\n1: NA\n2: Species\n3: site\n4: LMA (mg mm-2)\n5: Leaf nitrogen (mg mg-1)\n6: leaf size (mm2)\n7: latitude (deg)\n8: longitude (deg)\n9: description\nSelection: 1\nThis dataset does not include a column for collection_date, so 1: NA is the appropriate input.\nA follow-up question then allows you to add a fixed collection_date as a range. The information can be manually updated later.\nEnter collection_date range in format ‘2007/2009’: 2002-11/2002-11\n\nA final user prompt asks if, for any traits, a sequence of rows represents repeat observations.\n\nDo all traits need repeat_measurements_id’s?\n1: Yes 2: No\nThis only occurs if the dataset documents response curve data (e.g. an A-ci or light response curve for plants; or a temperature response curve for animal or plant behaviour) and the answer is almost always no.\n\n2\n\nNavigate to the dataset’s folder to find the metadata.yml file.\n\nOpen this file in Visual Studio Code (or another text-based editor of choice; NOT Word!), so you can see how it is progressively filled in as you work through the next steps.\n\n\n\nPropagate source information into the metadata.yml file\nThis dataset is from a published source with a doi and therefore the source information can be added with a single line of code:\n\nmetadata_add_source_doi(\n  dataset_id = \"tutorial_dataset_1\", \n  doi = \"10.1111/j.0022-0477.2005.00992.x\"\n  )\n\nThe following information is automatically propagated into the source field:\n\nprimary:\n  key: Test_1\n  bibtype: Article\n  year: '2005'\n  author: Daniel S. Falster and Mark Westoby\n  journal: Journal of Ecology\n  title: Alternative height strategies among 45 dicot rain forest species from tropical Queensland, Australia\n  volume: '93'\n  number: '3'\n  pages: 521--535\n  doi: 10.1111/j.0022-0477.2005.00992.x\n\nOnce you’ve run this line of code, look at the metadata file to confirm:\n\nthe authors’ names are formatted as first name last name or first initial last name (Daniel S. Falster or D. S. Falster if first names weren’t available)\n\nsequential author’s names are separated by and \nthe article title is in sentence case\n\nthe page numbers are filled in as a range, separated by a double dash (521--535 is correct) \n\nNote, there is also a function metadata_add_source_bibtex if your source information is in this format.\n\n\n\nAdd location details\nLocation data can be automatically propagated into the metadata file if it is available in tabular format. For instance, for this study:\n\nlocations &lt;-\n  read_csv(\"data/tutorial_dataset_1/data.csv\") %&gt;%\n    select(site, description, `latitude (deg)`, `longitude (deg)`) %&gt;%\n    distinct()\n\nYou can then add this location information directly into the metadata file by running:\n\nmetadata_add_locations(dataset_id = \"tutorial_dataset_1\", location_data = locations)\n\nThis leads to the following user prompts:\nSelect column for location_name \n1: site\n2: description\n3: latitude (deg)\n4: longitude (deg)\n\nSelection: 1 \nSelect the same column that you indicated contained location names when you created the metadata template.\nIndicate all columns you wish to keep as distinct location_properties in tutorial_dataset_1 (by number separated by space; e.g. ‘1 2 4’):\n\n1: description\n2: latitude (deg)\n3: longitude (deg)\n\nSelection: 1 2 3\nSelect all columns that include location properties that should be documented within the metadata.yml file. In this case, it is all three columns.\nFollowing locations added to metadata for tutorial_dataset_1: ‘Atherton’, ‘Cape Tribulation’\nwith variables ‘description’, ‘latitude (deg)’, ‘longitude (deg)’\nPlease complete information in data/tutorial_dataset_1/metadata.yml\n\nAll available location data has now been automatically added to the metadata.yml file.\n\nlocations:\n  Atherton:\n    description: Tropical rain forest vegetation\n    latitude (deg): -17.117\n    longitude (deg): 145.65\n  Cape Tribulation:\n    description: Complex mesophyll vine forest in tropical rain forest\n    latitude (deg): -16.1\n    longitude (deg): 145.45\n\n\n\n\nAdd traits\nThe next step is to select which columns in the data.csv file have trait information you want to include in the database.\nThe function metadata_add_traits automatically adds the trait-scaffold to metadata.yml:\n\nmetadata_add_traits(dataset_id = \"tutorial_dataset_1\")\n\nThe user is prompted to select the columns with trait data.\nIndicate all columns you wish to keep as distinct traits in tutorial_dataset_1 (by number separated by space; e.g. ‘1 2 4’):\n\n1: Species\n2: site\n3: LMA (mg mm-2)\n4: Leaf nitrogen (mg mg-1)\n5: leaf size (mm2)\n6: latitude (deg)\n7: longitude (deg)\n8: description\n\nSelection: 3 4 5\n\nYou select columns 3, 4, 5, as these contain trait data.\nFollowing traits added to metadata for tutorial_dataset_1: ‘LMA (mg mm-2)’, ‘Leaf nitrogen (mg mg-1)’, ‘leaf size (mm2)’\nPlease complete information in data/tutorial_dataset_1/metadata.yml\n\nmetadata.yml now includes a framework in which to manually fill in details about each trait:\n\ntraits:\n- var_in: LMA (mg mm-2)\n  unit_in: unknown\n  trait_name: unknown\n  entity_type: unknown\n  value_type: unknown\n  basis_of_value: unknown\n  replicates: unknown\n  methods: unknown\n- var_in: Leaf nitrogen (mg mg-1)\n  unit_in: unknown\n  trait_name: unknown\n  entity_type: unknown\n  value_type: unknown\n  basis_of_value: unknown\n  replicates: unknown\n  methods: unknown\n- var_in: leaf size (mm2)\n  unit_in: unknown\n  trait_name: unknown\n  entity_type: unknown\n  value_type: unknown\n  basis_of_value: unknown\n  replicates: unknown\n  methods: unknown\n\n\n\n\n\nManual filling in of metadata\nThe remaining fields within the metadata.yml file must now be filled in manually.\nThese include:\n* the contributors section\n* the description, basis_of_record, life_stage, sampling_strategy, original_file, and notes under the dataset section\n* details for each trait, including unit_in, trait_name, entity_type, value_type, basis_of_record, replicates and methods\nThese are all fields that contain the word unknown.\n\nAdding contributors\n\n\n\nContributor field\nInformation to add\n\n\n\n\nlast_name, first_name\nThe contributors first and last names should be available from the source\n\n\nORCID\nContributors are identified by their ORCID, available for most active researches at orcid.org\n\n\naffiliation\nAvailable from the source or the orcid.org website. Use the same syntax for the same affiliation throughout your database.\n\n\nadditional_role\nFor the lead dataset contributor, add the field: additional_role: contact\n\n\n\n\nYou can add multiple data collectors by duplicating the relevant 4 lines of code; see the Adding dataset vignette for protocols on who to add as a data collector.\nThe line assistants: can be deleted if there aren’t any assistants’ names to add.\nAdd yourself as the dataset_curator.\n\n\n\n\nDataset fields\n\nThe file data/tutorial_dataset_1/raw/tutorial_dataset_1_notes.txt indicates how to fill in the unknown dataset fields for this study.\nIn general, the information to fill in these fields should be available from the source (article) or obtained directly from the dataset contributor.\n\n\n\n\n\nDataset field\nInformation to add\n\n\n\n\nbasis_of_record\nSee traits.build_schema for allowable terms.\n\n\nlife_stage\nSee traits.build_schema for allowable terms.\n\n\ndescription\nA 1-2 sentence summary of the dataset. This can generally be formulated by information in the abstract.\n\n\nsampling_stategy\nA description of how sites and sampling protocols were chosen. Can generally be taken verbatim from the methods section of a manuscript.\n\n\noriginal_file\nName of the file submitted by the data contributor and archived in the raw folder.\n\n\nnotes\nnone (or .na) for this study, but any notes added by the data curator about data quality, edits to the data during dataset curation.\n\n\n\n\n\nTrait details\n\ntrait_name\nThe trait_name must match a trait_name within the traits dictionary. For this example:\n\n\n\ncolumn in dataset\ntrait concept\n\n\n\n\nLMA (mg mm-2)\nleaf_mass_per_area\n\n\nLeaf nitrogen (mg mg-1)\nleaf_N_per_dry_mass\n\n\nleaf size (mm2)\nleaf_area\n\n\n\nA dataset curator must be familiar with the likely traits in their discipline to accurately match those in a contributed dataset to traits in the dictionary, and be able to determine if a new trait definition is warranted.\n\n\nunit_in\nUnits are formatted according to the UCUM convention:\n\nunits in the numerator are separated by a ‘.’/\nunits in the denominator are each preceded by a ‘/’./\n“extra” information that is commonly informally included as part of the units for clarity can be included in curly brackets, {}\n\nAs examples:\n\n\n\nunits\nUCUM format\n\n\n\n\nmilligram per square millimetre\nmg/mm2\n\n\nmicromole per square metre second\numol/m2/s\n\n\nmicromole carbon dioxide per square metre second\numol{CO2}/m2/s\n\n\n\nIf the units being read in for a specific trait differ from those defined for the trait in the traits dictionary the trait values are converted using the conversion rules specified in unit_conversions.csv.\n\n\nentity_type, value_type, basis_of_value, replicates, methods\n\n\n\nfield\nvalue for this dataset\ndescription\n\n\n\n\nentity_type\npopulation\nThe entity corresponding to the trait value. Uses a controlled vocabulary. See traits.build_schema for allowable terms.\n\n\nvalue_type\nmean\nThe statistical nature of the trait value. Uses a controlled vocabulary. See traits.build_schema for allowable terms.\n\n\nbasis_of_value\nmeasurement\nHow the trait value was obtained. See traits.build_schema for allowable terms.\n\n\nreplicates\n3\nThe number of replicate measurements that comprise the trait measurement recorded in the spreadsheet.\n\n\nmethods\nSee the study’s metadata_notes.txt file\nA verbatim (free-form) text field documenting the methods used to collect the trait measurements. This is generally available from the reference or directly from the author.\n\n\n\nThe values for entity_type, value_type, basis_of_value, and replicates can vary by trait – and indeed by measurement – but for this study are identical for all traits.\n\n\n\nFinal steps\n\nDouble check the metadata.yml file\nYou should now have a completed metadata.yml file, with no unknown fields.\nYou’ll notice five sections we haven’t used, contexts, substitutions, taxonomic_updates, exclude_observations, and questions.\nThese should each contain an .na (as in substitutions: .na). They will be explored in future lessons.\n\n\nRun tests on the metadata file\nConfirm there are no errors in the metadata.yml file:\n\ndataset_test(\"tutorial_dataset_1\")\n\nThis should result in the following output:\n[ FAIL 0 | WARN 0 | SKIP 0 | PASS 79 ]\n\n\n\nAdd dataset to the database\nNext add the dataset_id to the build file that builds the database and rebuild the database\n\nbuild_setup_pipeline(method = \"base\", database_name = \"traits.build_database\")\nsource(\"build.R\")\n\n\n\nBuild dataset report\nAs a final step, build a report for the study\n\ntraits.build_database$build_info$version &lt;- \"5.0.0\"  \n    # a fix because the function was built around specific AusTraits versions\ndataset_report(\"tutorial_dataset_1\", traits.build_database, overwrite = TRUE)\n\nHave a look at the report, but there reports become much more interesting once there are more datasets in the database.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tutorial 1: Adding a simple dataset</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_2.html",
    "href": "tutorial_dataset_2.html",
    "title": "18  Tutorial 2: Adding a more complex dataset",
    "section": "",
    "text": "18.1 Overview\nThis is the second of five tutorials on adding datasets to your traits.build database.\nBefore you begin this tutorial, ensure you have installed traits.build, cloned the traits.build-template repository, and have successfully build a database from the datasets in traits.build-template. Instructions are available at Tutorial: Example compilation.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tutorial 2: Adding a more complex dataset</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_2.html#overview",
    "href": "tutorial_dataset_2.html#overview",
    "title": "18  Tutorial 2: Adding a more complex dataset",
    "section": "",
    "text": "Goals\n\nLearn how to merge in location data from a standalone spreadsheet.\nLearn how to add substitutions for categorical trait values.\nLearn how to add custom R code to the metadata file.\nUnderstand the importance of attributing traits to the correct entity_type.\nUnderstand the importance of having the dataset pivot.\n\n\n\nNew functions introduced\n\nmetadata_add_substitution\nmetadata_add_substitutions_list\nmetadata_check_custom_R_code",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tutorial 2: Adding a more complex dataset</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_2.html#adding-tutorial_dataset_2",
    "href": "tutorial_dataset_2.html#adding-tutorial_dataset_2",
    "title": "18  Tutorial 2: Adding a more complex dataset",
    "section": "18.2 Adding tutorial_dataset_2",
    "text": "18.2 Adding tutorial_dataset_2\n\nEnsure the dataset folder contains the correct data files\nIn the traits.build-template repository, there is a folder titled tutorial_dataset_2 within the data folder. \n\nEnsure that this folder exists on your computer. \nThe file data.csv exists within the tutorial_dataset_2 folder. \nThere is a folder raw nested within the tutorial_dataset_2 folder, that contains two files, locations.csv and notes.txt. \n\n\n\nsource necessary functions\n\nYou’ll need to both source the traits.build functions and some ancillary functions that are in a file in the scripts folder:\n\n\nlibrary(traits.build)\nsource(\"R/custom_R_code.R\")\n\n\n\nUse functions to create a metadata.yml file\n\nCreate a metadata template\nTo create the metadata template, run:\n\nmetadata_create_template(\"tutorial_dataset_2\")\n\nAs with tutorial_dataset_1 this function leads you through a series of menus requiring user input. Ensure you select:\ndata format: wide\ntaxon_name column: name_original\nlocation_name column: site_TEXT\nindividual_id column: 1: NA\ncollection_date column: 1: NA\nEnter collection_date range in format ‘2007/2009’: 1996/1997  Do all traits need repeat_measurements_id’s? 2: No\n\nNavigate to the dataset’s folder and open the metadata.yml file in Visual Studio Code, to ensure information is added to the expected sections as you work through the tutorial.\n\n\n\nPropagate source information into the metadata.yml file\nThis dataset is from a published source and therefore the source information can be added with the function metadata_add_source_doi:\n\nmetadata_add_source_doi(dataset_id = \"tutorial_dataset_2\", \n                        doi = \"10.1046/j.1365-2745.2000.00506.x\")\n\nconfirm:\n\nthe authors’ names are formatted as first name last name or first initial last name\n\nthe article title is in sentence case\n\nthe page numbers are filled in as a range, separated by a double dash\n\n\n\n\n\nAdd location details\nFor this dataset, location data is provided as a standalone spreadsheet, located in the raw data folder: tutorial_dataset_2\\raw\\locations.csv\nFirst read the location data provided into R:\n\nlocations &lt;-\n  read_csv(\"data/tutorial_dataset_2/raw/location_data.csv\")\n\ntraits.build requires three fields to use a specific syntax:\n\nlatitude must be in decimal degrees and the field name (column header) must be latitude (deg)\nlongitude must be in decimal degrees and the field name (column header) must be longitude (deg)\nA general site description is document in the field description\n\ntraits.build does not require that the labels for other location properties align across datasets, but it is best practice to use a controlled vocabulary, so database users can easily search across all datasets for information on a specific climate variable or soil nutrient content. For new databases or new location properties, any naming/labeling convention can be established.\nTo confirm you are using the correct syntax, check the terms already in use:\n\nlocations_properties &lt;-\n  traits.build_database$locations %&gt;%\n  distinct(location_property) %&gt;%\n  View()\n\nThen rename your columns to match those in use:\n\nlocations &lt;-\n  locations %&gt;%\n    rename(\n      `longitude (deg)` = long,\n      `latitude (deg)` = lat,\n      `description` = vegetation,\n      `elevation (m)` = elevation,\n      `precipitation, MAP (mm)` = MAP,\n      `soil P, total (mg/kg)` = `soil P`,\n      `soil N, total (ppm)` = `soil N`,\n      `geology (parent material)` = `parent material`\n    )\n\nNow add the location information into the metadata file:\n\nmetadata_add_locations(dataset_id = \"tutorial_dataset_2\", location_data = locations)\n\nEnsure you select:\nlocation_name: location\nlocation_property columns: 1 2 3 4 5 6 7 8\n\nCheck the metadata.yml file to ensure the location information has been added as expected. If there is a problem, rerun the necessary code; this will overwrite what is present. You can also manually add additional properties if something is forgotten.\n\n\n\nAdd traits\nTo select columns in the data.csv file that include trait data, run:\n\nmetadata_add_traits(dataset_id = \"tutorial_dataset_2\")\n\nSelect columns 3 4 5 6, as these contain trait data.\n\n\n\n\nManual filling in of metadata\nAfter confirming that the skeletal traits section has been added to metadata.yml file, you must fill in all the unknown fields.\nFor this dataset, you will later use functions to add substitutions and exclude unwanted observations, but it is best to first fill in the information for contributors, the dataset, and the traits.\nThese are all fields that contain the word unknown and must be filled in manually: \n\nthe contributors section\n\ndescription, basis_of_record, life_stage, sampling_strategy, original_file, and notes under the dataset section\n\ndetails for each trait, including unit_in, trait_name, entity_type, value_type, basis_of_record, replicates and methods\n\n\n\nAdding contributors\nThe file data/tutorial_dataset_2/raw/tutorial_dataset_2_notes.txt indicates the main data_contributor for this study.\n\nFill in the remaining contributor information as described in the tutorial_dataset_1 tutorial.\n\n\n\nDataset fields\nThe file data/tutorial_dataset_2/raw/tutorial_dataset_2_notes.txt indicates how to fill in the unknown dataset fields for this study.\n\n\nTrait details\nThe file data/tutorial_dataset_2/raw/tutorial_dataset_2_notes.txt indicates how to fill in the unknown trait fields for this study, but see below as well.\n\n\n\n\n\n\n\n\n\n\n\n\ncolumn in dataset\ntrait concept\nunits_in\nentity_type\nvalue_type\nbasis_of_value\nreplicates\n\n\n\n\nTRAIT Growth Form CATEGORICAL EP epiphyte (mistletoe) F fern G grass H herb S shrub T tree V vine\nplant_ growth_ form\n.na\nspecies\nmode\nexpert_score\n.na\n\n\nTRAIT SLA UNITS mm2/g\nleaf_mass_ per_area\nmm2/g\npopulation\nmean\nmeasurement\n5\n\n\nTRAIT Leaf Size UNITS mm2\nleaf_area\nmm2\npopulation\nmean\nmeasurement\n5\n\n\nTRAIT Leaf Dry Mass UNITS g\nleaf_dry_ mass\ng\npopulation\nmean\nmeasurement\n5\n\n\n\nSome notes:\n\nThe trait_name must match a trait concept within the traits dictionary.\nThe second trait in this dataset is documented as specific leaf area, the inverse of the trait concept leaf mass per area. The unit conversions algorithm inverts data read in as specific leaf area, converting it to leaf mass per area.\nCategorical traits do not have units or replicates, so these fields become .na.\nThe traits.build convention for a categorical trait is value_type: mode, indicating the recorded value is the most commonly observed trait value. In some datasets there may be multiple space-delimited values within a single cell in the data.csv file, indicating there are multiple commonly observed categorical trait values.\nFor most observations of categorical traits, the traits.build convention is that the basis_of_value is determined by an expert examining an individual, population or species, and is therefore an expert_score.\n\n\n\nAdditional steps\nOnce you are well-versed in adding datasets to a traits.build database you will know that there is additional information required in metadata.yml.\nHowever, for this tutorial, let’s begin by assuming we’re finished adding dataset metadata and check for errors:\n\ndataset_test(\"tutorial_dataset_2\")\n\n*Users, please note, not all of these test failures or messages are currently in place. Adding test to document all failures is still a work in progress. \nThree items will fail: \n\nThere are unknown trait values for plant_growth_form (error doesn’t yet exist) \nThere are values out of range for leaf_dry_mass (error doesn’t yet exist) \nThe dataset cannot pivot between long and wide formats. (error doesn’t yet exist) \n\nAs indicated in the output messages, there is a [troubleshooting vignette](https://github…/vignettes/) to help solve these errors. \nFor this tutorial however, keep reading…\nThere are several ways to proceed, but for these errors, it is useful to next build the dataset:\n\nbuild_setup_pipeline(method = \"base\", database_name = \"traits.build_database\")\nsource(\"build.R\")\n\nIf you look at the excluded_data table, you’ll find any data for this dataset that could not be mapped to known traits, known trait values, or fell within allowable ranges.\n\ntraits.build_database$excluded_data %&gt;%\n  filter(dataset_id == \"tutorial_dataset_2\") %&gt;%\n  View()\n\nThis code displays a table with 190 rows of excluded data. \n\n187 instances of Unsupported trait value for the trait plant_growth_form \n3 instance of Value out of allowable range for the trait leaf_dry_mass \n\nLooking through the output you’ll notice that the Unsupported trait value error exists because the data.csv file used plant growth form values that are different to those in the trait dictionary.\nThe values that triggered the Value out of allowable range error are all 0’s, a disallowed leaf_dry_mass value; the trait dictionary specifies that leaf_dry_mass can range from 0.01 - 15000.0 mg.\n\nAdding trait value substitutions\nFor categorical traits, only trait values that are indicated in the trait dictionary are recognised. This is an important harmonisation step, as it ensures the same trait concept value is mapped to the same trait value throughout the database.\nHowever, researchers use countless synonyms, abbreviations and syntax to express an identical trait value. traits.build converts all input to lowercase, but all other substitutions must be specified in the dataset’s metadata.yml file.\nFor this example individual letters were used to express 7 plant growth forms: EP, F, G, H, S, T, V\nLooking at the definition for plant_growth_form in the trait dictionary and the helpful column header provided by the contributor, you can deduce that t is for tree; s is for shrub, etc.\nThere are two ways to add substitutions into the metadata.yml file.\n\nMap in individual trait value substitutions using metadata_add_substitution:\n\n\nmetadata_add_substitution(dataset_id = \"tutorial_dataset_2\", \n        trait_name = \"plant_growth_form\", find = \"t\", replace = \"tree\")\n\nLook at the metadata.yml file and you’ll note that a substitution has been added, to indicate the t’s are tree’s\nYou would repeat this step for the remaining unknown trait values.\n\nMap in a table of substitutions using metadata_add_substitutions_list:\n\n\nIf there are quite a few trait values that require replacements, it is easier to first create a table of the required substitutions, then add a column of substitutions in either R or Excel.\n\n\ntable &lt;-\n  traits.build_database$excluded_data %&gt;%\n  filter(\n    dataset_id == \"tutorial_dataset_2\" &\n      error == \"Unsupported trait value\"\n  ) %&gt;%\n  distinct(trait_name, value) %&gt;%\n  rename(find = value)\n\nNext view your table to check the order of trait values and check the allowed values and definitions in the trait dictionary to ensure you replace each abbreviation with an accepted value. Note that epiphyte is not an allowed value for plant_growth_form in the trait dictionary, as, AusTraits uses a narrow definition of plant_growth_form, and separately has a trait plant_growth_substrate which includes the trait value epiphyte. For now, we’ll simply ignore this data.\nTo add a column with substitutions, then add the substitutions to the metadata file:\n\ntable &lt;- table %&gt;%\n  mutate(replace = c(\"shrub\", \"tree\", \"herb\", NA, \n                     \"graminoid\", \"fern\", \"climber_herbaceous\"))\n\n## an alternative is \n## `mutate(replace = c(\"shrub\", \"tree\", \"herb\", \"epiphyte\", \"graminoid\",  \n##          \"fern\", \"climber_herbaceous\"))` \n## which will result in the epiphyte observations remaining in the excluded data table\n\nmetadata_add_substitutions_list(\"tutorial_dataset_2\", table)\n\nAll required substitutions have been added to the metadata.yml file.\nIf you were to rerun dataset_test(\"tutorial_dataset_2\") the error referring to Unsupported trait values would now have vanished.\n\n\nReplacing “placeholder characters” with NA’s\nThe Values out of range error is triggered for numeric traits when the traits.build pipeline detects values that fall outside the range specified for the trait in the traits dictionary.\nThere are three common situations that lead to this error warning: \n\nValues are truly out of range, possibly due to human error or because a plant really was not performing as expected (i.e. not photosynthesising). \nValues appear to be out of range because of a “unit conversion issue” - that is, the dataset curator or the dataset contributor got the units wrong.  This is fixed by working out the correct units and adjusting this in the traits section of the metadata.yml file. \nA dataset contributor has used a “dummy symbol” to indicate missing data, such as 0, x, missing, etc. Truly missing data should be a blank cell - i.e. NA \n\nThis study is likely an example of (3), where 0 is a placeholder symbol. While the 0’s can be left in the excluded_data table, cluttering the excluded_data table with extraneous measurements makes it difficult to scan for true examples of Value out of allowable range errors in the future. (Values that are NA are, by default, omitted from the excluded_data table.)\n\nadding custom R code\nInstead, you can add R code within the metadata file to replace the placeholder symbol with NA.\n\nLook at metadata.yml in Visual Studio Code. \nThe second field under the dataset section is custom_R_code: .na. \nYou can write any code you’d like within this section. \nThe file R/custom_R_code.R that you sourced at the beginning of this tutorial contains customised functions commonly used in custom_R_code. \n\nFor this example, replace: \n\ncustom_R_code: na\n\nwith: \n\ncustom_R_code: '\n  data %&gt;%\n    mutate(\n      across(c(\"TRAIT Leaf Dry Mass UNITS g\"), ~na_if(.x,0))\n    )\n'\n\nThis code replaces all 0’s in the column with NA’s.\nYou can confirm that the custom R code has made the anticipated change with the function metadata_check_custom_R_code. This function reads in the data.csv file, then applies any manipulations from the custom_R_code: \n\nmetadata_check_custom_R_code(\"tutorial_dataset_2\") %&gt;% View()\n\nNote: \n\nuse the format with the single quotes; this allows you to manually add line breaks, not otherwise permitted in the metadata.yml format. \nyou pipe in data to begin with, but do not need to assign your code back to data; that occurs automatically. \n\nBuild the database again, then check the excluded_data table to confirm there are no longer any excluded measurements: \n\nsource(\"build.R\")\n\ntraits.build_database$excluded_data %&gt;%\n  filter(dataset_id == \"tutorial_dataset_2\") %&gt;%\n  View()\n\n\n\n\nReplacing duplicate values with NA’s\nRun the tests again to confirm the errors related to disallowed trait values and values out of range have vanished: \n\ndataset_test(\"tutorial_dataset_2\")\n\nHowever, there should still be an error indicating that the dataset cannot pivot between long and wide formats. \nThe ability to pivot is important for 2 reasons:{#dataset_pivot} \n\nDatabase users may prefer to display data in wide format to readily compare the values of multiple traits collected on the same individual (or population or species). \nThe pivot test groups together 13 variables that are meant to uniquely identify each row of data (dataset_id, trait_name, observation_id, source_id, taxon_name, entity_type, life_stage, basis_of_record, value_type, population_id, individual_id, temporal_id, method_id, entity_context_id, original_name). An inability to pivot indicates either: \n\nA variable present in the data.csv file to distinguish between unique observations has not been mapped into the metadata file. (Most likely a context property, column with locations, individual_id or source_id) \nDuplicate values exist within the data.csv file and have been read in multiple times. \n\n\nThe error in this dataset is a common one:\n\n\nThe three numeric traits (leaf_mass_per_area, leaf_mass_per_area and leaf_dry_mass) are all population-level measurements, while plant_growth_form is mapped in as having entity_type: species, meaning it is considered a species-level measurement. This means if the same species occurs at multiple sites, its growth form value is read in twice. However, because it is designated as entity_type: species that traits.build workflow does not connect the value to a location, since the species has the same growth form regardless of location. \nTwo options are to:\n\nRecategorise plant_growth_form as having entity_type: population.\nOnly read in a single instance of plant_growth_form per species.\n\n\nEither allows the dataset to pivot, but if the taxon truly displays only a single growth form across all populations it is much better to read in plant growth form once per species. Otherwise the database becomes longer without capturing additional information. This dataset has only a few instance of duplication, but imagine the dataset that has 500 rows of data for the same tree species - suddenly 500 instances of that species being a tree are read into the database.\nThe solution is to modify the existing custom_R_code, adding one of the customised functions from the file R/custom_R_code.R, replace_duplicates_with_NA: \n\ncustom_R_code: '\n  data %&gt;%\n    mutate(\n      across(c(\"TRAIT Leaf Dry Mass UNITS g\"), ~na_if(.x,0))\n    ) %&gt;%\n    group_by(name_original) %&gt;%\n    mutate(\n      across(c(\"TRAIT Growth Form CATEGORICAL EP epiphyte (mistletoe) F fern G grass H herb S shrub T tree V vine\"), \n              replace_duplicates_with_NA)\n    ) %&gt;%\n    ungroup()\n'\n\nRerun the tests and everything should now pass: \n\ndataset_test(\"tutorial_dataset_2\")\n\nThen rebuild the database and look at the output in the traits table for one of the taxa that previously had duplicate plant_growth_form entries: \n\nsource(\"build.R\")\n\ntraits.build_database$traits %&gt;%\n  filter(dataset_id == \"tutorial_dataset_2\") %&gt;%\n  filter(taxon_name == \"Actinotus minor\") %&gt;% View()\n\n  dataset_id     taxon_name      observation_id trait_name         value            unit  entity_type location_id\n  &lt;chr&gt;          &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;              &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;\n1 tutorial_dataset_2 Actinotus minor 010            leaf_area          18.8             mm2   population  02\n2 tutorial_dataset_2 Actinotus minor 010            leaf_dry_mass      7                mg    population  02\n3 tutorial_dataset_2 Actinotus minor 010            leaf_mass_per_area 344.827586206897 g/m2  population  02\n4 tutorial_dataset_2 Actinotus minor 011            leaf_area          75.9             mm2   population  03\n5 tutorial_dataset_2 Actinotus minor 011            leaf_dry_mass      7                mg    population  03\n6 tutorial_dataset_2 Actinotus minor 011            leaf_mass_per_area 89.2857142857143 g/m2  population  03\n7 tutorial_dataset_2 Actinotus minor 012            plant_growth_form  herb             NA    species     NA\n\nThe measurements for the three numeric traits from a single location share a common observation_id, as they are all part of an observation of a common entity (a specific population of Actinotus minor), at a single location, at a single point in time. However the row with the plant growth form measurement has a separate observation_id reflecting that this is an observation of a different entity (the taxon Actinotus minor).\n\n\nBuild dataset report\nAs a final step, build a report for the study\n\ntraits.build_database$build_info$version &lt;- \"5.0.0\"  # a fix because the function was built around specific AusTraits versions\ndataset_report(\"tutorial_dataset_2\", traits.build_database, overwrite = TRUE)",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tutorial 2: Adding a more complex dataset</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_3.html",
    "href": "tutorial_dataset_3.html",
    "title": "19  Tutorial 3: Adding contexts and complex units",
    "section": "",
    "text": "19.1 Overview\nThis is the third of five tutorials on adding datasets to your traits.build database.\nBefore you begin this tutorial, ensure you have installed traits.build, cloned the traits.build-template repository, and have successfully build a database from the datasets in traits.build-template. Instructions are available at Tutorial: Example compilation.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Tutorial 3: Adding contexts and complex units</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_3.html#overview",
    "href": "tutorial_dataset_3.html#overview",
    "title": "19  Tutorial 3: Adding contexts and complex units",
    "section": "",
    "text": "Goals\n\nLearn how to add contexts. \nLearn some complexities with respect to units. \nLearn additional custom_R_code tricks. \n\n\n\nNew functions introduced\n\nmetadata_add_contexts",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Tutorial 3: Adding contexts and complex units</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_3.html#adding-tutorial_dataset_3",
    "href": "tutorial_dataset_3.html#adding-tutorial_dataset_3",
    "title": "19  Tutorial 3: Adding contexts and complex units",
    "section": "19.2 Adding tutorial_dataset_3",
    "text": "19.2 Adding tutorial_dataset_3\n\nEnsure the dataset folder contains the correct data files\nIn the traits.build-template repository, there is a folder titled tutorial_dataset_3 within the data folder. \n\nEnsure that this folder exists on your computer. \nThe file data.csv exists within the tutorial_dataset_3 folder. \nThere is a folder raw nested within the tutorial_dataset_3 folder, that contains one file, notes.txt. \n\n\n\nsource necessary functions\n\nIf you have restarted R Studio since last adding a dataset, ensure all functions are loaded from both the traits.build package and the custom functions file:\n\n\nlibrary(traits.build)\nsource(\"R/custom_R_code.R\")\n\n\n\nUse functions to create a metadata.yml file\n\nCreate a metadata template\nTo create the metadata template, run:\n\nmetadata_create_template(\"tutorial_dataset_3\")\n\nAs with in the previous tutorials, this function leads you through a series of menus requiring user input. Ensure you select:\ndata format: wide\ntaxon_name column: 1: Species\nlocation_name column: 5: site\nindividual_id column: 1: NA\ncollection_date column: 1: NA\nEnter collection_date range in format ‘2007/2009’: 2011-02/2011-03\nDo all traits need repeat_measurements_id’s? 2: No\n\nIn this dataset, unlike the first two, the data being input is at the individual-level. Since there is only a single data row for each individual, it is not required to map in an individual_id. A column with an individual_id is required if you want to keep track of multiple rows of data for the same individual.\nNavigate to the dataset’s folder and open the metadata.yml file in Visual Studio Code, to ensure information is added to the expected sections as you work through the tutorial.\n\n\n\nPropagate source information into the metadata.yml file\nThis dataset is from a published source and therefore the source information can be added with the function metadata_add_source_doi:\n\nmetadata_add_source_doi(dataset_id = \"tutorial_dataset_3\", \n                        doi = \"10.1007/s11104-013-1725-x\")\n\nconfirm:\n\nthe authors’ names are formatted as first name last name or first initial last name\n\nthe article title is in sentence case\n\nthe page numbers are filled in as a range, separated by a double dash\n\n\nYou have just added 3 doi’s that all yield perfect reference information - and indeed most references are added correctly, but some journals and doi’s for many older references are in ALL CAPS or missing page numbers, so it is worth checking.\n\n\n\nAdd location details\nAll data for this dataset was collected at a single location, specified in the data.csv file as The University of Melbourne Burnley campus. No additional details are provided. For such studies, it is best to look up the campus location and input approximate latitude/longitude coordinates.\nAs well as adding locations and location properties from a table, the function metadata_add_locations lets you add a basic location data scaffold in metadata.yml.\nFor instance, for this study:\n\n\nyou add the location names from the data.csv file\n\nthe function automatically adds blank fields for latitude, longitude, and description\n\nvalues for these fields must then be filled in manually\n\n\n\ndata &lt;- read_csv(\"data/tutorial_dataset_3/data.csv\")\n\nmetadata_add_locations(\"tutorial_dataset_3\", data)\n\nYou select the location name, but not any location properties, as none are provided in the data.csv file or another tabular format.\nlocation_name: 4: site\nlocation_property columns: just press enter\n\nThis creates the following scaffold in methdata.yml: \n\n  The University of Melbourne Burnley campus:\n    latitude (deg): na_character\n    longitude (deg): na_character\n    description: na_character\n\n\nmetadata_add_locations automatically selects the unique values in the location name column. \nif no columns with location properties are specified, the function just adds the three core location properties. \nthe values for these location properties are available in the notes file. \n\n\n\n\nAdd traits\nTo select columns in the data.csv file that include trait data, run:\n\nmetadata_add_traits(dataset_id = \"tutorial_dataset_3\")\n\nSelect columns 5 6 7 8 9 10, as these contain trait data.\n\n\n\nAdd contexts\nA context is any piece of ancillary information that helps explain why a certain trait value was measured. \nIn traits.build, some contexts are mapped in as part of the default metadata structure, including the location (& location properties), a general sense of organism age (life_stage), basis_of_record, and the general methods for each trait.\n\nHowever most contexts are pieces of information that are essential to record for a specific dataset, but not recorded for most other datasets. The context field therefore allows any context property to be added manually.\n\nContext properties are divided into 5 categories:\n\n\nmethod contexts: Context properties that capture differences in method between measurements of the same trait. For plants, canopy position and leaf age are two common method contexts.\n\ntemporal contexts: Context properties that capture explicit time-related differences between groups of measurements. This is separate from collection_date, as an explicit meaning should accompany each temporal context property and the distinct values may span a range of collection dates. For plants sampling season (dry versus wet) is a commonly mapped in temporal context.\n\nentity contexts: This context property category pertains to individual-level measurements, and documents features of the individual that explicitly distinguish it from other individuals that are measured. In addition to features like the sex of an individual, it is the location to document individual-level co-variates that are not themselves traits, but are information required to interpret other trait values.\n\ntreatment contexts: Any experimental treatment that has been applied to groups of individuals.\n\nplot contexts: Any variation within a documented location, where different individuals experience know differences in growing/living conditions or growing/living history. For plants, this context category is frequently used to map in slope position or fire history.\n\n\nContext properties are most frequently included in the data.csv file as columns of values. Occasionally, separate columns of trait values might represent measurements with different context property values, a topic for a later tutorial.\nContext properties that are columns in the data file, can be added with the function metadata_add_contexts:\n\nmetadata_add_contexts(\"tutorial_dataset_3\")\n\nThis leads to a user-prompt to select the relevent columns:\nIndicate all columns that contain additional contextual data for tutorial_dataset_3 (by number separated by space; e.g. ‘1 2 4’):\n\n1: Species\n2: Treatment\n3: Replicate\n4: site\n5: life_form\n6: WP leaf (Mpa) predawn\n7: WP leaf (Mpa) midday\n8: LMA kg/m2\n9: Stomatal density Upper surface\n10: Stomatal density Lower surface\n\nSelect column 2 which is the only column with a context property:\nSelection: 2\n\nAdditional user prompts ask for details about the context property category and values:\nWhat category does context Treatment fit in? (by number separated by space; e.g. ‘1 2 4’):\n\n1: treatment_context\n2: plot_context\n3: temporal_context\n4: method_context\n5: entity_context\n\nThis is a treatment context, so select 1:\nSelection: 1\n\nThe following values exist for this context: Drought, Watered.\n\nAre replacement values required? (y/n) y\n\nAlthough the trait values Drought and Watered are probably sufficiently descriptive, for other drought-treatment studies we’ve used drought and well-watered, so prefer to align the context property values with these.\nAre descriptions required? (y/n) y\n\nThe free-form description field let’s you add details about the exact meaning of drought vs well-watered for this study.\nIn the metadata.yml file, there will now be a scaffold for the contexts:\n\ncontexts:\n- context_property: unknown\n  category: treatment\n  var_in: Treatment\n  values:\n  - find: Drought\n    value: unknown\n    description: unknown\n  - find: Watered\n    value: unknown\n    description: unknown\n\nIn addition to filling in the preferred context property values and descriptions, you must also assign a name to the context_property. This is a free-form field, but as with location_property it is best to ensure you align context_propery names throughout the database. In the AusTraits plant trait database, this context_property is always called drought treatment.\nThe finished context section will be:\n\ncontexts:\n- context_property: drought treatment\n  category: treatment\n  var_in: Treatment\n  values:\n  - find: Drought\n    value: drought\n    description: The plants were watered with 20% of the water used by well-watered\n      plants (determined gravimetrically) in the 3-4 days preceding each watering\n      event).\n  - find: Watered\n    value: well-watered\n    description: The plants were watered to pot capacity at (2 L per pot).\n\n\n\n\n\nManual filling in of metadata\nThe components of this dataset that can be propagated with functions are not complete, and the remaining unknown fields must now be filled in manually.\n\n\nthe contributors section\n\ndescription, basis_of_record, life_stage, sampling_strategy, original_file, and notes under the dataset section\n\ndetails for each trait, including unit_in, trait_name, entity_type, value_type, basis_of_record, replicates and methods\n\n\n\nAdding contributors\nThe file data/tutorial_dataset_3/raw/tutorial_dataset_3_notes.txt indicates the main data_contributor for this study.\n\n\n\nDataset fields\nThe file data/tutorial_dataset_3/raw/tutorial_dataset_3_notes.txt indicates how to fill in the unknown dataset fields for this study.\n\n\nTrait details\nThe file data/tutorial_dataset_3/raw/tutorial_dataset_3_notes.txt indicates how to fill in the unknown trait fields for this study, but see below as well.\nRemember, the trait_name must match a trait concept within the traits dictionary. For this example:\n\n\n\n\n\n\n\n\n\n\n\n\ncolumn in dataset\ntrait concept\nunits_in\nentity_type\nvalue_type\nbasis_of_ value\nreplicates\n\n\n\n\nlife_form\nlife_form\n.na\nspecies\nmode\nexpert_score\n.na\n\n\nWP leaf (Mpa) predawn\nwater_potential_predawn\nneg_MPa\nindividual\nraw\nmeasurement\n1\n\n\nWP leaf (Mpa) midday\nwater_potential_midday\nneg_MPa\nindividual\nraw\nmeasurement\n1\n\n\nLMA kg/m2\nleaf_mass_per_area\nkg/m2\nindividual\nraw\nmeasurement\n1\n\n\nStomatal density Upper surface\nleaf_stomatal_density_adaxial\n‘{count}/mm2’\nindividual\nraw\nmeasurement\n1\n\n\nStomatal density Lower surface\nleaf_stomatal_density_abaxial\n‘{count}/mm2’\nindividual\nraw\nmeasurement\n1\n\n\n\nWith the units, note:\n\nIn the data.csv file, all water potential values are positive, indicating the data contributor mapped in the “negative” of the true water potential values (which are always below zero). A negative sign at the beginning of the units field is not recognised and therefore the convention is to use the prefix neg_ to indicate the values input are the negative of the true values.\nstomatal density is a “count density”, a number of stomata per unit area. The actual UCUM standard for this is simply 1/mm2 , but for clarity we use {count}/mm2 . The word count is in curly brackets, since it is a “note” rather than a true unit.\nIf the unit begin with a curly bracket, the unit needs to be placed in single quotes\n\n\n\n\nTesting, error fixes, and report building\nAt this point, run the dataset tests and rebuild the dataset:\n\ndataset_test(\"tutorial_dataset_3\")\n\nbuild_setup_pipeline(method = \"base\", database_name = \"traits.build_database\")\nsource(\"build.R\")\n\nThe dataset test should yield an error that one water_potential_predawn value does not convert to numeric, indicating a placeholder-character is being used in place of an NA {note: this error wasn’t triggering as this vignette was being written)\nLooking at the excluded_data table indicates there is a “*” in one column, so one adds:\n\n  custom_R_code: '\n    data %&gt;%\n      mutate(\n        across(c(\"WP leaf (Mpa) predawn\"), ~na_if(.x,\"*\"))\n      )\n  '\n\nHowever, now you’ll get the error: Caused by error in na_if(): ! Can’t convert y  to match type of x .\nThis indicates a mismatch between column types, necessitating that you change the column to character:\n\n  custom_R_code: '\n    data %&gt;%\n      mutate(\n        across(c(\"WP leaf (Mpa) predawn\"), ~as.character(.x)),\n        across(c(\"WP leaf (Mpa) predawn\"), ~na_if(.x,\"*\"))\n      )\n  '\n\nAt this point, rerunning the tests and rebuilding the database should not generate any errors or excluded values, so you can build and review the report.\nAs a final step, build a report for the study\n\ntraits.build_database$build_info$version &lt;- \"5.0.0\"  \n    # a fix because the function was built around specific AusTraits versions\ndataset_report(\"tutorial_dataset_3\", traits.build_database, overwrite = TRUE)",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Tutorial 3: Adding contexts and complex units</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_4.html",
    "href": "tutorial_dataset_4.html",
    "title": "20  Tutorial 4: Additional complexities",
    "section": "",
    "text": "20.1 Overview\nThis is the fourth tutorial on adding datasets to your traits.build database.\nBefore you begin this tutorial, ensure you have installed traits.build, cloned the traits.build-template repository, and have successfully build a database from the example datasets in traits.build-template. Instructions are available at Tutorial: Example compilation.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Tutorial 4: Additional complexities</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_4.html#overview",
    "href": "tutorial_dataset_4.html#overview",
    "title": "20  Tutorial 4: Additional complexities",
    "section": "",
    "text": "Goals\n\nLearn how to generate location names using custom_R_code\nLearn how to add multiple sources to the reference section. \nLearn how to add map source_ID into the metadata file. \nLearn how to map metadata from columns. \nLearn how to exclude data. \n\n\n\nNew functions introduced\n\nnone.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Tutorial 4: Additional complexities</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_4.html#adding-tutorial_dataset_4",
    "href": "tutorial_dataset_4.html#adding-tutorial_dataset_4",
    "title": "20  Tutorial 4: Additional complexities",
    "section": "20.2 Adding tutorial_dataset_4",
    "text": "20.2 Adding tutorial_dataset_4\nThis dataset is a subset of data from Togashi_2015 in AusTraits. The data are a compilation of many datasets, each with their own references information.\n\nFor such datasets, there are two options: 1) sourcing the data from the original publication, and adding it to the database as its own datset; 2) entering the dataset as part of a broader compilation. For this study, in AusTraits, a combination of both approaches was used. For original sources that included a broader range of traits and similar (or better) resolution, the original source was used. However, in this compilation there were several studies where Togashi had already individually contacted the authors of the source publications, as the data appendix for this publication often had better resolution than the original papers.\n\nThis tutorial focuses on adding a single dataset derived from many original studies.\n\nBefore you begin creating the metadata file, take a look at the data.csv file - you’ll notice that the columns present are quite different from the datasets added so far. There are columns for latitude & longitude, but not location name column. There are columns for the original source. These are columns for entity_type, basis_of_record, and value_type, three metadata fields that, for the previous tutorial datasets, were entered in the metadata file as a fixed value. And the only trait column log_LA.SA is in a non-standard format.\nWith a few small tricks this dataset can also be added seamlessly.\n\nEnsure the dataset folder contains the correct data files\nIn the traits.build-template repository, there is a folder titled tutorial_dataset_4 within the data folder. \n\nEnsure that this folder exists on your computer. \nThe file data.csv exists within the tutorial_dataset_4 folder. \nThere is a folder raw nested within the tutorial_dataset_4 folder, that contains one file, tutorial_dataset_4_notes.txt. \n\n\n\nsource necessary functions\n\nIf you have restarted R Studio since last adding a dataset, ensure all functions are loaded from both the traits.build package and the custom functions file:\n\n\nlibrary(traits.build)\nsource(\"R/custom_R_code.R\")\n\n\n\nCreate the metadata.yml file\n\nNote, that because, for this dataset, there are a number of variables that cannot simply be adding using the metadata_add_... functions, unlike in previous tutorials, you’ll now mix the three steps that were previously separated:\n\n\n\nUse metadata_add... functions where possible.\n\nMutate new columns using custom_R_code.\n\nManually map newly created column names in the appropriate part of the metadata.yml file.\n\n\n\nCreate a metadata template\nTo create the metadata template, run:\n\nmetadata_create_template(\"tutorial_dataset_4\")\n\nAs with in the previous tutorials, this function leads you through a series of menus requiring user input. Ensure you select:\ndata format: wide\ntaxon_name column: 1: Species\nlocation_name column: 1: NA\nindividual_id column: 1: NA\ncollection_date column: 1: NA\nEnter collection_date range in format ‘2007/2009’: 1996/2015\nDo all traits need repeat_measurements_id’s? 2: No\n\nNotes:\n\n\nAs you noted before, there is no location column to map in automatically, so that must be added later. You enter NA for now.\n\nSince this is a compilation, there is nowhere in the manuscript that indicates the collection dates for each study. The best estimate is to list the range of publication dates of the sources: 1996–2015.\n\n\nNavigate to the dataset’s folder and open the metadata.yml file in Visual Studio Code, to ensure information is added to the expected sections as you work through the tutorial.\n\n\n\nPropagate source information into the metadata.yml file\nEntering the reference information for the manuscript from which the data appendix was sourced is straightforward, as this is a single publication:\n\nmetadata_add_source_doi(dataset_id = \"tutorial_dataset_4\", doi = \"10.1002/ece3.1344\")\n\nHowever, you also want to acknowledge the original data sources, those documented in the column References.\n\nread_csv(\"data/tutorial_dataset_4/data.csv\") %&gt;% distinct(References)\n\n# A tibble: 11 × 1\nReferences\n   &lt;chr&gt;\n 1 Barrett et al. 1996\n 2 Benyon et al. 1999\n 3 Bleby et al.2009\n 4 Brodribb and Felid 2000\n 5 Brooksbank et al. 2011\n 6 Canham et al. 2009\n 7 Carter and White 2009\n 8 Cernusak et al. 2006\n 9 Choat et al. 2005\n10 Drake and Franks 2003\n11 Drake et al. 2011\n\nYou would now need to look up each of these references in the reference section of the manuscript and use Google Scholar (or another reference resource) to look up the doi for each reference. To add additional references, you need to add an argument to the metadata_add_source_doi function:\n\n\nmetadata_add_source_doi(dataset_id = \"tutorial_dataset_4\", doi = \"10.1071/bt9960249\", \n                        type = \"original_01\")\n\nPer the traits.build schema, a secondary reference is when there have been two related publications out of a single dataset, while the term original is used if the data were collected as part of a previous dataset (generally by different authors) and added to traits.build as part of a compilation.\n\nWhen you add Benyon_1999 (doi - “10.1016/s0378-3774(98)00080-8”), you’ll need to change the type field to original_02, etc.\nNote that AusTraits will build fine without adding all 11 original sources; it is up to you how many you want to add as a test.\n\n\n\nMap source_id into metadata file\n\nsource_id is a metadata field that is used relatively infrequently. In the AusTraits trait database only 1/20 studies require the mapping of a source_id and therefore as a default the field does not get added to the metadata template.\n\nInstead, you have to manually add it to the files’ dataset section, generally directly below location_name.\n\nSimply add a line source_id: source_id. Make sure the indents line up with the fields above/below.\n\nWhen the AusTraits team initially added this dataset, the curator manually added the source_id column. Otherwise such a column could be mutated from the reference column using custom_R_code or added manually in Excel.\n\n\n\n\n\nAdd location details\nYour protocol for adding locations diverges from the past 3 tutorials, because in this dataset you don’t yet have location names. The data file instead includes the latitude and longitude of each site, information you can use to “create” location names; the actual name doesn’t matter, just that each latitude/longitude combination has a unique location name.\n\nAlthough you could edit the data.csv file directly (and sometimes we do), you could alternatively create a location_name column through custom_R_code:\n\n\n  custom_R_code: '\n    data %&gt;%\n      mutate(\n        location_name = paste0(\"lat_\",Lat,\"_long_\",Long)\n      )\n'\n\nIn this case you’re using custom_R_code to generate many unique location names as a column in the data table as it is first read into the R workflow. \nNote: While, for this example you are generating many unique location names, there are many datasets where all data have been collected at a single location, and therefore the submitted dataset doesn’t include a location_name column. For all of those you simply add code like mutate(location_name = \"Broken Hill\") into custom_R_code.\n\nYou next want to create a table of location names and location properties (i.e latitude & longitude):\n\n\nlocation_table &lt;-\n  metadata_check_custom_R_code(\"tutorial_dataset_4\") %&gt;%\n  select(location_name, Lat, Long) %&gt;%\n  rename(`latitude (deg)` = Lat, `longitude (deg)` = Long) %&gt;%\n  distinct()\n\nmetadata_add_locations(\"tutorial_dataset_4\", location_table)\n\nNotes:\n\n\nRemember the function metadata_check_custom_R_code reads in the data.csv file, applies custom_R_code manipulations, and outputs the updated data table. This is very useful if you want to check your custom_R_code is performing as expected or if you want to perform further manipulations to the output.\n\nThere are many other ways to create a table of location names and properties. You could create a standalone table using R (or Excel), but this solution generates no additional files to store.\n\n\n\n\n\nMap location name into metadata file\n\nBecause the column location_name did not exist when you created the metadata table, you filled in location_name = NA during the initial user prompts.\nYou now need to manually fill the newly mutated location name column into the metadata file. Under the dataset section you’ll find the field location_name: unknown. This needs to be replaced with location_name: location_name.\n\n\n\n\n\nFill in missing dataset-level metadata\n\nManually fill in the the information for the fields description, basis_of_record, life_stage and sampling_strategy, copying information from the supplied text file into metadata.yml.\n\n\n\n\nAdd traits\nThere is a single trait for this study, Huber value, which is the sapwood area to leaf area ratio. However, in the data.csv file it is documented as log_LA.SA and another line of custom R code must be added:\n\n\n  custom_R_code: '\n    data %&gt;%\n      mutate(\n        location_name = paste0(\"lat_\",Lat,\"_long_\",Long),\n        LA.SA = 10^(log_LA.SA)\n      )\n'\n\nYou could take the inverse of LA.SA, but this can also be accomplished through unit conversions.\nYou can then run:\n\nmetadata_add_traits(\"tutorial_dataset_4\")\n\nSelect column 13, your newly created column of trait data.\nAs with previous datasets, the following section has been added to metadata.yml:\n\n- var_in: LA.SA\n  unit_in: unknown\n  trait_name: unknown\n  entity_type: unknown\n  value_type: unknown\n  basis_of_value: unknown\n  replicates: unknown\n  methods: unknown\n\nThis trait has several “non-standard” values:\n\n\nunit_in: The units for the input column are leaf area/sapwood area, a dimensionless “area ratio”. Meanwhile, Huber value is reported as sapwood area/leaf area, the inverse dimensionless “area ratio”.\n\n\nThe UCUM standard to which traits.build conforms specifies that “dimensionless” is only accepted for the very few traits that are truly dimensionless, not traits where units top and bottom simply cancel out. You need to specify that it is a ratio of area/area (or mass/mass, count/count, etc.)\n\nLooking in the trait dictionary, you’ll see that the units are specified as: mm2{sapwood}/mm2{leaf}, specifically to be explicit about which area is the denominator vs numerator. You therefore specify that the units_in are mm2{leaf}/mm2{sapwood}.\n\nSince it is dimensionless, you could, of course specify any area units on top and bottom as long as they are identical, but I know mm2{leaf}/mm2{sapwood} is already in the unit conversions file.\n\n\nentity_type, value_type: Because this study is a compilation of many sources, the entity_type and value_type are not consistent across all measurements. Instead the data curator had to go back to many of the original sources and document which were population-level versus individual-level measurements, and correspondingly which were means vs raw values. For such circumstances (which also can occur within a single study), you can map a column name as the value.\n\nreplicates: For most of the studies the number of replicates comprising the trait values is unknown.\n\nTaking all this into account, you’re left with:\n\n- var_in: LA.SA\n  unit_in: mm2{leaf}/mm2{sapwood}\n  trait_name: huber_value\n  entity_type: entity\n  value_type: value\n  basis_of_value: measurement\n  replicates: unknown\n  methods: Leaf area was measured using a desktop scanner for all leaves on a sampled\n    branch. After bark removal, the branch cross-sectional area was measured with\n    a digital caliper at two points near the cut (methodology that includes the non-conductive\n    part of the sapwood). The pith cross-sectional area was measured and subtracted\n    from the branch cross-sectional area. For compiled and contributed data, measurements\n    on branches were made as described above, although with a variable number of branches\n    sampled per tree. In some studies where the branch diameter was too small (&lt;10\n    mm), the pith was considered part of the sapwood. For whole trees, cross-sectional\n    sapwood area was measured at 1.3 m above the ground from bored cores or harvesting\n    the tree. Leaf area in whole trees was in most cases measured from harvested trees.\n\n\n\n\nAdd contexts\nIf you consider the columns within the data.csv file you’ll note that Sample documents a method context and needs to be added as a context property. In addition, within this dataset, Height (plant height) is not a trait, but a covariate; some datasets documented this, because they thought it might influence the Huber value of the plant. It is therefore a context.\n\nmetadata_add_contexts(\"tutorial_dataset_4\")\n\nFollowing the user prompts select:\n5: Sample\n6: Height\n\nYou are then led sequentially through the user prompts for each of the context properties:\nSample\n4: method_context\n\nThis context is a method context, because it specifies a difference in methodology that might influence that trait value.\n\nThe following values exist for this context: trunk sample branch sample\nAre replacement values required? (y/n) n\nAre descriptions required? (y/n) y\n\nThe answers to the next two questions are up to the dataset curator, but at AusTraits we decided that trunk sample and branch sample were sufficiently explicit context property values, but that it would be helpful to add a description.\n\nTherefore, we filled in context_property: wood sample type and added descriptions for the context property values:\n\n\n- context_property: wood sample type\n  category: method_context\n  var_in: Sample\n  values:\n  - value: trunk sample\n    description: Measurements taken on the trunk of the tree.\n  - value: branch sample\n    description: Measeurements taken on a branch from the tree.\n\nHeight\nPlant height is an entity context. It is a feature of the entity (an individual) that might influence the trait value.\n\n5: entity_context\n\nAgain, the dataset curator may choose what information to document within the metadata file. For continuous traits, like plant height, the general consensus is that the values are self-explanatory, so you’d select:\n\nThe following values exist for this context: 6.7, 4.8, 6.9\nAre replacement values required? (y/n) n\nAre descriptions required? (y/n) n\n\nFilling in that the context property is tree height (m), the metadata file would simply be:\n\n\n- context_property: tree height (m)\n  category: entity_context\n  var_in: Height\n\n\n\n\nTesting, error fixes, and report building\nAt this point, run the dataset tests, rebuild the dataset, and check for excluded data:\n\ndataset_test(\"tutorial_dataset_4\")\n\nbuild_setup_pipeline(method = \"base\", database_name = \"traits.build_database\")\nsource(\"build.R\")\n\ntraits.build_database$excluded_data %&gt;% \n  filter(dataset_id == \"tutorial_dataset_4\") %&gt;%  View()\n\nThere should be no errors and no excluded data, so go ahead and build a report for the study:\n\ntraits.build_database$build_info$version &lt;- \"5.0.0\"  \n    # a fix because the function was built around specific AusTraits versions\ndataset_report(\"tutorial_dataset_4\", traits.build_database, overwrite = TRUE)\n\nOverall, this report isn’t very informative since it is the first Huber value dataset in the new database.\n\nBut let me draw your attention to the list of taxa at the bottom. Because the tutorials are, for now, ignoring taxon alignments (traits.build in a state of flux with regard to this), the tutorials have ignored this section.\nBut let me draw your attention to the list of taxa at the bottom. Because the tutorials are, for now, ignoring taxon alignments (traits.build in a state of flux with regard to this), the tutorials have ignored this section. \nHowever, note the unknown taxa names unk sp. 1 and unk sp. 2. Although the AusTraits database accepts names resolved to genus and family, data collected on a truly unknown taxon is useless and should be excluded. Being a terrestrial vascular plant database, we also exclude mosses and lichens that are sometimes in datasets. The curators for other databases aligned to the traits.build workflow will have their own standards for values to explicitly disallow, based on taxonomy (or some other variable).\nNear the bottom of the metadata file is a section for excluding data.\n\nIt currently reads:\n\n\nexclude_observations: .na\n\nChange this to:\n\nexclude_observations:\n- variable: taxon_name\n  find: unk sp. 1, unk sp. 2\n  reason: omitting completely unknown taxa (E Wenk, 2023.09.20)\n\nNotes:\n\n\nOther variable names can also be used here. Perhaps there is a particular context value or location that is known to have problematic data. In AusTraits this field is almost exclusively used to exclude specific taxa, but the metadata section is designed to have broader applications.\n\nIf you now rebuild the database, you’ll see that the measurements associated with these two data are now in the excluded_data table.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Tutorial 4: Additional complexities</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_5.html",
    "href": "tutorial_dataset_5.html",
    "title": "21  Tutorial 5: Multiple columns for a trait",
    "section": "",
    "text": "21.1 Overview\nThis is the fifth tutorial on adding datasets to your traits.build database.\nBefore you begin this tutorial, ensure you have installed traits.build, cloned the traits.build-template repository, and have successfully build a database from the example datasets in traits.build-template. Instructions are available at Tutorial: Example compilation.\nIt is also recommended that you first work through some of the earlier tutorials, as many steps for adding datasets to a traits.build database are only thoroughly described in the early tutorials.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Tutorial 5: Multiple columns for a trait</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_5.html#overview",
    "href": "tutorial_dataset_5.html#overview",
    "title": "21  Tutorial 5: Multiple columns for a trait",
    "section": "",
    "text": "Goals\n\nLearn how to map context properties into the metadata traits section \nLearn how to add measurement remarks \n\n\n\nNew functions introduced\n\nnone.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Tutorial 5: Multiple columns for a trait</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_5.html#adding-tutorial_dataset_5",
    "href": "tutorial_dataset_5.html#adding-tutorial_dataset_5",
    "title": "21  Tutorial 5: Multiple columns for a trait",
    "section": "21.2 Adding tutorial_dataset_5",
    "text": "21.2 Adding tutorial_dataset_5\nThis dataset is a subset of data from Geange_2017 in AusTraits.\nThis tutorial focuses on how to input a dataset where there are multiple columns for the same trait, with each column indicating measurements made under different context conditions. \nBefore you begin creating the metadata file, take a look at the data.csv file. Note that there are two columns for each photosynthesis and conductance. For this dataset these represent repeat measurements made on the same individuals under different experimental treatments. For other studies, these may be multiple columns if the same trait was measured using separate methods. \n\nEnsure the dataset folder contains the correct data files\nIn the traits.build-template repository, there is a folder titled tutorial_dataset_5 within the data folder. \n\nEnsure that this folder exists on your computer. \nThe file data.csv exists within the tutorial_dataset_5 folder. \nThere is a folder raw nested within the tutorial_dataset_5 folder, that contains one file, tutorial_dataset_5_notes.txt. \n\n\n\nsource necessary functions\n\nIf you have restarted R Studio since last adding a dataset, ensure all functions are loaded from both the traits.build package and the custom functions file:\n\n\nlibrary(traits.build)\nsource(\"R/custom_R_code.R\")\n\n\n\n\nCreate a metadata.yml file\n\nCreate a metadata template\nTo create the metadata template, run:\n\nmetadata_create_template(\"tutorial_dataset_5\")\n\nAs with in the previous tutorials, this function leads you through a series of menus requiring user input. Ensure you select:\ndata format: wide\ntaxon_name column: 1: species_name\nlocation_name column: 1: NA\nindividual_id column: 1: NA\ncollection_date column: 21: date\nDo all traits need repeat_measurements_id’s? 2: No\n\nNotes:\n\n\nThere is no location column to map in automatically, so that must be added later. You enter NA for now.\n\nThe column Abbrev! appears to be a unique identifier for each individual that can be mapped in to identify individual plants. Mapping in an individual_id column is essential if multiple rows include measurements for the same individual, as might happen if individuals are measured repeatedly across time. For this dataset, each row includes measurements on a separate individual, so it isn’t required to map individual_id. Moreover, if you were to look closely at the values in the column Abbrev! you would notice there are 3 instances of duplication. Were you to map in individual_id: Abbrev! you would end up with an error - as occurred initially when this dataset was added to AusTraits.\n\n\nNavigate to the dataset’s folder and open the metadata.yml file in Visual Studio Code, to ensure information is added to the expected sections as you work through the tutorial.\n\n\n\nPropagate source information into the metadata.yml file\nUse the function metadata_add_source_doi to add the source.\n\nThe reference doi is 10.1186/s40665-017-0033-8.\n\n\n\nAdd measurement remarks\nThere is a free-form comments column called measurement_remarks that can be mapped in at the dataset level (i.e. for all measurements) or under specific traits. \nThis column is not used to generate any of the identifiers and therefore cannot be used as a location to document information that is a context property, source, location, method, etc. However, there can be minor notes that have been documented about specific observations or trait measurements that should be retained in the traits.build output and if this information if available in a column it can be mapped into measurement remarks.\n\nFor instance, in this dataset, the column Mother documents the maternal lineage of each individual. This could be recorded as an official context property, or, alternatively could simply be added as a measurement remark, first mutating a column:\n\n\n  custom_R_code: '\n    data %&gt;%\n      mutate(\n        measurement_remarks = paste0(\"maternal lineage \", Mother)\n      )\n'\n\nand then adding measurement_remarks: measurement_remarks to the dataset section of the metadata file, below life_stage\n\n\n\nAdd location details\nThere isn’t a location name specified in the data.csv file, so use custom_R_code to mutate a new column, location_name.\n\n\n  custom_R_code: '\n    data %&gt;%\n      mutate(\n        measurement_remarks = paste0(\"maternal lineage \", Mother),\n        location = \"Australian National University glasshouse\"\n      )\n'\n\nAnd then specify this column as the source of location_name in the dataset section of the metadata file.\n\nAnd manually add the location details to the location section of the metadata file\n\n\n  Australian National University glasshouse:\n    latitude (deg): -35.283\n    longitude (deg): 149.1167\n    precipitation, MAP (mm): 622\n    description: Australian National University glasshouses\n\n\n\nAdd traits\nTo select columns in the data.csv file that include trait data, run:\n\nmetadata_add_traits(dataset_id = \"tutorial_dataset_5\")\n\nSelect columns 13 14 15 16 17 18 19, as these contain trait data.\n\nThen fill in the details for each trait column in the traits section of the metadata file.\n\nRemember, the trait_name must match a trait concept within the traits dictionary. For this example:\n\n\n\n\n\n\n\n\n\n\n\n\ncolumn in dataset\ntrait concept\nunits_in\nentity_type\nvalue_type\nbasis_of_ value\nreplicates\n\n\n\n\nPhoto\nleaf_photosynthetic_rate_per_area_saturated\numol{CO2}/m2/s\nindividual\nraw\nmeasurement\n1\n\n\nCond\nleaf_stomatal_conductance_per_area_at_Asat\nmol{H2O}/m2/s\nindividual\nraw\nmeasurement\n1\n\n\nPhoto_D\nleaf_photosynthetic_rate_per_area_saturated\numol{CO2}/m2/s\nindividual\nraw\nmeasurement\n1\n\n\nCond_D\nleaf_stomatal_conductance_per_area_at_Asat\nmol{H2O}/m2/s\nindividual\nraw\nmeasurement\n1\n\n\narea_mm2\nleaf_area\nmm2\nindividual\nraw\nmeasurement\n1\n\n\nSLA_cm_g:4\nleaf_mass_per_area\ncm2/g\nindividual\nraw\nmeasurement\n1\n\n\n%N:1\nleaf_N_per_dry_mass\n‘%’\nindividual\nraw\nmeasurement\n1\n\n\n\n\n\nAdd contexts\n\nContexts from columns\nThere are two columns in the data.csv file that specify contexts, Elevation (seed provenance) and Treatment (drought treatment).\nTo add these contexts to the metadata file, run:\n\nmetadata_add_contexts(dataset_id = \"tutorial_dataset_5\")\n\nSelect columns 6 7 as these contain context properties\nThe category for both of these is treatment_context.\nAnd as the values for both are abbreviations, it is recommended to replace the values for both context properties with proper terms and descriptions.\nTherefore, the metadata template will now have the following section:\n\ncontexts:\n- context_property: unknown\n  category: treatment_context\n  var_in: Elevation\n  values:\n  - find: LoElev\n    value: unknown\n    description: unknown\n  - find: HiElev\n    value: unknown\n    description: unknown\n- context_property: unknown\n  category: treatment_context\n  var_in: Treatment\n  values:\n  - find: LoWat\n    value: unknown\n    description: unknown\n  - find: HiWat\n    value: unknown\n    description: unknown\n\nWhich will be filled in as:\n\n- context_property: seed provenance\n  category: treatment_context\n  var_in: Elevation\n  values:\n  - find: LoElev\n    value: low elevation\n    description: Seeds sourced from low elevation populations.\n  - find: HiElev\n    value: high elevation\n    description: Seeds sourced from hight elevation populations.\n- context_property: drought treatment\n  category: treatment_context\n  var_in: Treatment\n  values:\n  - find: LoWat\n    value: low water\n    description: Plants assigned to low water treatment.\n  - find: HiWat\n    value: high water\n    description: Plants assigned to high water treatment.\n\n\n\nContexts manually added\nAs background, at the point in the traits.build workflow where the trait metadata is read in, the trait data has been converted to long format, with each trait measurement is its own row. This allows columns such as methods, entity_type, and units to be added, which are inherently unique to a specific trait. It also means that context properties can now be added, with different values assigned to different traits. \nFor this study, in addition to the two contexts that are documented as columns, there is a context property that is documented across columns, the time from last watering to gas exchange measurements. For photosynthesis and conductance, the columns Photo and Cond document measurements made just after a watering cycle, while the columns Photo_D and Cond_D document measurements made at the very end of a watering cycle. \nFor such situations, you add a line to the traits section of the metadata for each of these traits.\nFor instance, for the column Photo, you would add: \n\n  replicates: 1\n  time_since_watering: start of watering cycle\n  methods: Gas exchange was measured using...\n\nThis creates a new column, time_since_watering and for the trait column Photo, the value is start of watering cycle. \nYou add an identical line to the trait column Cond, while for the trait columns Photo_D and Cond_D instead insert a line time_since_watering: end of watering cycle. \nFor the other traits, no lines are added, as these the context property time_since_watering doesn’t apply to them. \nSince the trait metadata is read in long after the custom_R_code code is executed, this context property cannot be read in using a function. Instead it must be manually added as a context_property.\n\n- context_property: time since watering\n  category: temporal\n  var_in: time_since_watering\n  values:\n  - value: start of watering cycle\n    description: Measurements made on the morning following a watering event when the plants were at their least water-limited.\n  - value: end of watering cycle\n    description: Measurements made on the final day of a watering cycle when the plants were at the driest point in the cycle.\n\n\n\n\nAdding contributors\nThe file data/tutorial_dataset_5/raw/tutorial_dataset_5_notes.txt indicates the main data_contributor for this study.\n\n\n\nDataset fields\nThe file data/tutorial_dataset_5/raw/tutorial_dataset_5_notes.txt indicates how to fill in the unknown dataset fields for this study.\n\n\n\nTesting, error fixes, and report building\nAt this point, run the dataset tests, rebuild the dataset, and check for excluded data:\n\ndataset_test(\"tutorial_dataset_5\")\n\nbuild_setup_pipeline(method = \"base\", database_name = \"traits.build_database\")\n\nsource(\"build.R\")\n\ntraits.build_database$excluded_data %&gt;% \n  filter(dataset_id == \"tutorial_dataset_5\") %&gt;%  View()\n\nThere should be no errors.\n\nThere are a handful of excluded values, including both negative photosynthetic rates and negative conductance rates and two instances where leaf_area = 0. The leaf_area = 0 values need to be removed using custom_R_code.\n\n\nmutate(across(c(\"area_mm2\"), ~na_if(.x,0)))\n\nThen remake the database and again check the excluded data table.\nIf the only excluded values remaining are the negative gas exchange rates, build a report for the study:\n\ntraits.build_database$build_info$version &lt;- \"5.0.0\"  \n    # a fix because the function was built around specific AusTraits versions\ndataset_report(\"tutorial_dataset_5\", traits.build_database, overwrite = TRUE)",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Tutorial 5: Multiple columns for a trait</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_6.html",
    "href": "tutorial_dataset_6.html",
    "title": "22  Tutorial 6: Data with repeat measurements",
    "section": "",
    "text": "22.1 Overview\nThis is the sixth tutorial on adding datasets to your traits.build database.\nBefore you begin this tutorial, ensure you have installed traits.build, cloned the traits.build-template repository, and have successfully build a database from the example datasets in traits.build-template. Instructions are available at Tutorial: Example compilation.\nIt is also recommended that you first work through some of the earlier tutorials, as many steps for adding datasets to a traits.build database are only thoroughly described in the early tutorials.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Tutorial 6: Data with repeat measurements</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_6.html#overview",
    "href": "tutorial_dataset_6.html#overview",
    "title": "22  Tutorial 6: Data with repeat measurements",
    "section": "",
    "text": "Goals\n\nLearn how to add repeat measurement id’s \nLearn how to add individual_id’s \n\n\n\nNew functions introduced\n\nnone.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Tutorial 6: Data with repeat measurements</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_6.html#adding-tutorial_dataset_6",
    "href": "tutorial_dataset_6.html#adding-tutorial_dataset_6",
    "title": "22  Tutorial 6: Data with repeat measurements",
    "section": "22.2 Adding tutorial_dataset_6",
    "text": "22.2 Adding tutorial_dataset_6\nThis dataset is data submitted as part of Cernusak_2011 in AusTraits. AusTraits itself does not include the raw A-ci curve data that is being added for this tutorial.\nThis tutorial focuses on how to input a dataset where a single trait measurement consists of a series of time-ordered measurements and the repeat measurements must clearly be identified as being part of the same the same observation. \nBefore you begin creating the metadata file, take a look at the data.csv file. If you are familiar with the output of an IRGA (instrument to measure gas exchange) you will note that many columns of essential metadata have been removed - for simplicity of this tutorial \n\nEnsure the dataset folder contains the correct data files\nIn the traits.build-template repository, there is a folder titled tutorial_dataset_6 within the data folder. \n\nEnsure that this folder exists on your computer. \nThe file data.csv exists within the tutorial_dataset_6 folder. \nThere is a folder raw nested within the tutorial_dataset_6 folder, that contains two files, locations.csv and tutorial_dataset_6_notes.txt. \n\n\n\nsource necessary functions\n\nIf you have restarted R Studio since last adding a dataset, ensure all functions are loaded from both the traits.build package and the custom functions file:\n\n\nlibrary(traits.build)\nsource(\"R/custom_R_code.R\")\n\n\n\n\nCreate a metadata.yml file\n\nCreate a metadata template\nTo create the metadata template, run:\n\nmetadata_create_template(\"tutorial_dataset_6\")\n\nAs with in the previous tutorials, this function leads you through a series of menus requiring user input. Ensure you select:\ndata format: wide\ntaxon_name column: 2: Species\nlocation_name column: 2: Site\nindividual_id column: 1: NA\ncollection_date column: 6: Date\nDo all traits need repeat_measurements_id’s? 1: Yes\n\nNotes:\n\n\nThere currently isn’t an individual_id column, but this is required for repeat_measurements_id’s to properly generate. An individual_id column will need to be added via custom_R_code.\n\nThis is the first tutorial that includes repeat_measurement_id’s. repeat_measurement_id’s are sequential integer identifiers assigned to a sequence of measurements on a single trait that together represent a single observation (and are assigned a single observation_id by the traits.build pipeline. The assumption is that these are measurements that document points on a response curve. Although the exact time of each measurement will of course be different for point on the curve, time is not a temporal context and must be identical for all measurements within a single curve.\n\nFor this dataset - and probably for most datasets that document response curve data - all traits being added will be repeat measurements. However, if some columns of trait data are not part of the response curve data, one can alternatively map repeat_measurement_id: TRUE for individual traits in the traits section of metadata.yml.\nA word of warning for datasets where the output data includes a time stamp. Ensure that there is a separate collection_date column that is a date not a time, as all measurements that comprise a single response curve must have the same collection_date. Otherwise, the traits.build pipeline will assign them each separate observation_id’s.\nNavigate to the dataset’s folder and open the metadata.yml file in Visual Studio Code, to ensure information is added to the expected sections as you work through the tutorial.\n\n\nPropagate source information into the metadata.yml file\nUse the function metadata_add_source_doi to add the source.\n\nThe reference doi is 10.1016/j.agrformet.2011.01.006.\n\n\n\nAdd individual_id\nIn order for repeat_measurements_id’s to properly generate, it is essential to identify which sequence of rows represent a single individual. For this dataset, the columns Site, Species, and Leaf number jointly identify individuals and therefore a new column must be mutated in custom_R_code, then specified as the source of individual_id in the dataset section of metadata.yml: \n\n  custom_R_code: '\n    data %&gt;%\n      mutate(\n        individual_id = paste(Site, Species, `Leaf number`, sep = \"_\")\n      )\n  '\n\nand then add individual_id: individual_id to the dataset section of the metadata file, below location_name.\n\n\n\nAdd location details\nThere is a file in the raw folder with location details: \n\nlocations &lt;- read_csv(\"data/tutorial_dataset_6/raw/locations.csv\")\n\nmetadata_add_locations(\"tutorial_dataset_6\", locations)\n\nAt the user prompts: \nlocation name: 1\ncolumns with location properties: 1 2 3 4 5 6\n\n\n\nAdd traits\nTo select columns in the data.csv file that include trait data, run:\n\nmetadata_add_traits(dataset_id = \"tutorial_dataset_6\")\n\nSelect columns 13 14 15, as these contain trait data.\n\nThen fill in the details for each trait column in the traits section of the metadata file.\n\nRemember, the trait_name must match a trait concept within the traits dictionary. For this example:\n\n\n\n\n\n\n\n\n\n\n\n\ncolumn in dataset\ntrait concept\nunits_in\nentity_type\nvalue_type\nbasis_of_ value\nreplicates\n\n\n\n\nPhotosynthesis (umol m-2 s-1)\nleaf_photosynthetic_rate_per_area_saturated\numol{CO2}/m2/s\nindividual\nraw\nmeasurement\n1\n\n\nConductance to H2O (mol m-2 s-1)\nleaf_stomatal_conductance_per_area_at_Asat\nmol{H2O}/m2/s\nindividual\nraw\nmeasurement\n1\n\n\nCi (umol mol-1)\nleaf_intercellular_CO2_concentration_at_Asat\numol{CO2}/mol\nindividual\nraw\nmeasurement\n1\n\n\n\n\n\nAdd contexts\nThere are no required contexts for this dataset. One could add the column Canopy of understory as a method_context, but as there is only a single value reported (“canopy”) this isn’t essential.\n\n\nAdding contributors\nThe file data/tutorial_dataset_6/raw/tutorial_dataset_6_notes.txt indicates the main data_contributor for this study.\n\n\n\nDataset fields\nThe file data/tutorial_dataset_6/raw/tutorial_dataset_6_notes.txt indicates how to fill in the unknown dataset fields for this study.\n\n\n\nTesting, error fixes, and report building\nAt this point, run the dataset tests, rebuild the dataset, and check for excluded data:\n\ndataset_test(\"tutorial_dataset_6\")\n\nbuild_setup_pipeline(method = \"base\", database_name = \"traits.build_database\")\n\nsource(\"build.R\")\n\ntraits.build_database$excluded_data %&gt;% \n  filter(dataset_id == \"tutorial_dataset_6\") %&gt;%  View()\n\nThere should be no errors. However there are many excluded data values - entirely negative photosynthetic rates. The definition of leaf_photosynthetic_rate_per_area_saturated requires photosynthetic rates to be positive, so these are valid excluded values and simply remain in the excluded data table. So go ahead and build a report for the study:\n\ntraits.build_database$build_info$version &lt;- \"5.0.0\"  \n    # a fix because the function was built around specific AusTraits versions\ndataset_report(\"tutorial_dataset_6\", traits.build_database, overwrite = TRUE)",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Tutorial 6: Data with repeat measurements</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_7.html",
    "href": "tutorial_dataset_7.html",
    "title": "23  Tutorial 7: Adding long format dataset",
    "section": "",
    "text": "23.1 Overview\nThis is the seventh tutorial on adding datasets to your traits.build database.\nBefore you begin this tutorial, ensure you have installed traits.build, cloned the traits.build-template repository, and have successfully build a database from the example datasets in traits.build-template. Instructions are available at Tutorial: Example compilation.\nIt is also recommended that you first work through some of the earlier tutorials, as many steps for adding datasets to a traits.build database are only thoroughly described in the early tutorials.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Tutorial 7: Adding long format dataset</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_7.html#overview",
    "href": "tutorial_dataset_7.html#overview",
    "title": "23  Tutorial 7: Adding long format dataset",
    "section": "",
    "text": "Goals\n\nLearn how to add a long dataset \nLearn how to add units from a column \n\n\n\nNew functions introduced\n\nnone.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Tutorial 7: Adding long format dataset</span>"
    ]
  },
  {
    "objectID": "tutorial_dataset_7.html#adding-tutorial_dataset_7",
    "href": "tutorial_dataset_7.html#adding-tutorial_dataset_7",
    "title": "23  Tutorial 7: Adding long format dataset",
    "section": "23.2 Adding tutorial_dataset_7",
    "text": "23.2 Adding tutorial_dataset_7\nThis dataset is a subset of data from ABRS_1981 in AusTraits. These are data from the original Flora of Australia volumes (Australian Biological Resources Study) and are therefore all species-level trait values.\nThis tutorial focuses on how to input a dataset in long format, where there is a single column with all trait values and a column specifying the trait documented in each row of the data file. \n\nEnsure the dataset folder contains the correct data files\nIn the traits.build-template repository, there is a folder titled tutorial_dataset_7 within the data folder. \n\nEnsure that this folder exists on your computer. \nThe file data.csv exists within the tutorial_dataset_7 folder. \nThere is a folder raw nested within the tutorial_dataset_7 folder, that contains two files, locations.csv and tutorial_dataset_7_notes.txt. \n\n\n\nsource necessary functions\n\nIf you have restarted R Studio since last adding a dataset, ensure all functions are loaded from both the traits.build package and the custom functions file:\n\n\nlibrary(traits.build)\nsource(\"R/custom_R_code.R\")\n\n\n\n\nCreate a metadata.yml file\n\nCreate a metadata template\nTo create the metadata template, run:\n\nmetadata_create_template(\"tutorial_dataset_7\")\n\nAs with previous datasets, the first question asks whether this is a long or wide dataset. You now select long:\nAs with in the previous tutorials, this function leads you through a series of menus requiring user input. Ensure you select:\ndata format: long\n\nThe remaining prompts are now slightly different, since you have to identify columns for trait_name and value:\nSelect column for taxon_name 1: species_name\nSelect column for trait_name 2: trait\nSelect column for value 4: value\nlocation_name column: 1: NA\nindividual_id column: 1: NA\ncollection_date column: 1: NA\nEnter collection_date range in format ‘2007/2009’: unknown/1981\nDo all traits need repeat_measurements_id’s? 2: No\n\nNotes: \n\nAll long-format datasets require an identifier to group rows of data referring to the same entity. If neither a location_name nor an individual_id is provided (as is the case for all flora-derived datasets), the taxon_name becomes the identifier that is used to unite measurements into a single observation.\n\nNavigate to the dataset’s folder and open the metadata.yml file in Visual Studio Code, to ensure information is added to the expected sections as you work through the tutorial.\n\n\nPropagate source information into the metadata.yml file\nSince this dataset is not from a published study with a doi, the source information needs to be manually added:\n\n\n  bibtype: Online\n  year: 1981\n  author: '{Australian Biological Resources Study}'\n  title: Flora of Australia, Australian Biological Resources Study, Canberra.\n  publisher: Department of Climate Change, Energy, the Environment and Water, Canberra.\n  url: http://www.ausflora.org.au\n\nThere are other bibtype’s you will encounter as well, including Unpublished, Book, Misc, Thesis, InBook (for chapters), Report and TechReport. For each there are different required and optional fields (per BibTex’s rules). See the complete guide to adding datasets for examples of each.\n\n\nAdd traits\nTo select columns in the data.csv file that include trait data, run:\n\nmetadata_add_traits(dataset_id = \"tutorial_dataset_7\")\n\nFor long datasets, this function outputs a list of unique values within the trait names column:\nIndicate all columns you wish to keep as distinct traits in tutorial_dataset_7 (by number separated by space; e.g. ‘1 2 4’): 1: leaf length maximum 2: leaf type 3: seed length maximum 4: seed length minimum\nSelect columns 1 2 3 4, you want to include all four traits.\n\nThen fill in the details for each trait column in the traits section of the metadata file.\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrait\ntrait concept\nunits_in\nentity_type\nvalue_type\nbasis_of_ value\nreplicates\n\n\n\n\nleaf length maximum\nleaf_length\nunits\nspecies\nmaximum\nmeasurement\n.na\n\n\nleaf type\nleaf_compoundness\n.na\nspecies\nmode\nexpert_score\n.na\n\n\nseed length maximum\nseed_length\nunits\nspecies\nmaximum\nmeasurement\n.na\n\n\nseed length minimum\nseed_length\nunits\nspecies\nminimum\nmeasurement\n.na\n\n\n\nNotes:\n\nYou may have noticed in the data.csv file that there is also a column units. For many long datasets there is a fixed unit for each trait, just as is standardly the case for wide datasets. In such cases fixed units values are mapped into the traits section of the metadata file, just as occurs with most wide datasets. In this dataset there is a column documenting the units, as different tax have leaf length and seed length reported in different units. The column for units can be mapped in at the trait level, as indicated here, or, for a long dataset, it could be mapped in a single time in the dataset section of the metadata, units_in: units and then you’d delete the line referring to units_in from each of the traits.\nThere are two different trait names that refer to seed length, seed length maximum and seed length minimum. It is not a problem that these both map to the trait concept seed_length as they are different value types.\n\nBecause these are species-level trait values, even the numeric traits do not have a replicate count. The range of values should represent all individuals of the species.\n\n\n\n\nAdding contributors\nThe file data/tutorial_dataset_7/raw/tutorial_dataset_7_notes.txt indicates the main data_contributor for this study.\n\n\n\nDataset fields\nThe file data/tutorial_dataset_7/raw/tutorial_dataset_7_notes.txt indicates how to fill in the unknown dataset fields for this study.\n\n\n\n\nTesting, error fixes, and report building\nAt this point, run the dataset tests, rebuild the dataset, and check for excluded data:\n\ndataset_test(\"tutorial_dataset_7\")\n\nbuild_setup_pipeline(method = \"base\", database_name = \"traits.build_database\")\n\nsource(\"build.R\")\n\ntraits.build_database$excluded_data %&gt;% \n  filter(dataset_id == \"tutorial_dataset_7\") %&gt;%  View()\n\nThe excluded data includes four rows of data with the error Unsupported trait value for the trait leaf_compoundness. The term article does not describe a leaf’s compoundness. As articles are always simple leaves you can add a substitution:\n\n\nmetadata_add_substitution(dataset_id = \"tutorial_dataset_7\", \n                          trait_name = \"leaf_compoundness\", \n                          find = \"articles\", replace = \"simple\")\n\nThen rebuild the database and again check excluded data to ensure the substitution has worked as intended.\n\n\ntraits.build_database$build_info$version &lt;- \"5.0.0\"  \n    # a fix because the function was built around specific AusTraits versions\ndataset_report(\"tutorial_dataset_7\", traits.build_database, overwrite = TRUE)",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Tutorial 7: Adding long format dataset</span>"
    ]
  },
  {
    "objectID": "adding_data_long.html",
    "href": "adding_data_long.html",
    "title": "24  Adding datasets, a lengthy guide",
    "section": "",
    "text": "24.1 Getting started\nThis vignette is an exhaustive reference for adding datasets to a traits.build database.\nIf you are embarking on building a new database using the traits.build standard a better place to get started are 7 tutorials.\nThen come back to this document for details and unusual dataset circumstances that are not covered in the tutorials.\nOther chapters you may want to read include:\nThe traits.build package offers a workflow to build a harmonised trait database from disparate sources, with different data formats and containing varying metadata.\nThere are two key components required to merge datasets into a database with a common output structure:\nThis document details all the steps to format datasets into a pair of standardised files for input, a tabular data file and a structured metadata file. It includes examples of code you might use.\nTo begin, install the traits.build package.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Adding datasets, a lengthy guide</span>"
    ]
  },
  {
    "objectID": "adding_data_long.html#getting-started",
    "href": "adding_data_long.html#getting-started",
    "title": "24  Adding datasets, a lengthy guide",
    "section": "",
    "text": "A workflow to wrangle datasets into a standardised input format, using a combination of {traits.build} functions and manual steps.\nA process to harmonise information across datasets and build them into a single database.\n\n\n\n#remotes::install_github(\"traitecoevo/traits.build\", quick=TRUE)\n\nlibrary(traits.build)",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Adding datasets, a lengthy guide</span>"
    ]
  },
  {
    "objectID": "adding_data_long.html#standardised-input-files-required",
    "href": "adding_data_long.html#standardised-input-files-required",
    "title": "24  Adding datasets, a lengthy guide",
    "section": "24.2 Standardised input files required",
    "text": "24.2 Standardised input files required",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Adding datasets, a lengthy guide</span>"
    ]
  },
  {
    "objectID": "adding_data_long.html#create-a-dataset-folder",
    "href": "adding_data_long.html#create-a-dataset-folder",
    "title": "24  Adding datasets, a lengthy guide",
    "section": "24.3 Create a dataset folder",
    "text": "24.3 Create a dataset folder\nAdd a new folder within the data folder. Its name should be the study’s unique dataset_id.\nThe preferred format for dataset_id is the surname of the first author of any corresponding publication, followed by the year, as surname_year. E.g. Falster_2005. Wherever there are multiple studies with the same id, we add a suffix _2, _3 etc. E.g.Falster_2005, Falster_2005_2.\ndataset_id is one of the core identifiers within a traits.build database.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Adding datasets, a lengthy guide</span>"
    ]
  },
  {
    "objectID": "adding_data_long.html#csv_file",
    "href": "adding_data_long.html#csv_file",
    "title": "24  Adding datasets, a lengthy guide",
    "section": "24.4 Constructing the data.csv file",
    "text": "24.4 Constructing the data.csv file\nThe trait data for each study (dataset_id) must be in a single table, data.csv. The data.csv file can either be in a wide format (1 column for each trait, with the various trait names as the column headers) or long format (a single column for all trait values and an additional column for trait name.\n\nRequired columns\n\ntaxon_name\n\ntrait_name (many columns for wide format; 1 column for long format)\nvalue (trait value; for long format only)\nlocation_name (if required)\n\ncontexts (if required)\n\ncollection_date (if required)\nindividual_id (if required)\n\n\nFor all field studies, ensure there is a column for location_name. If all measurements were made at a single location, a location_name column can easily be mutated using custom_R_code within the metadata.yml file. See sections adding locations and adding contexts below for more information on compiling location and context data.\nIf available, be sure to include a column with collection date. If possible, provide dates in yyyy-mm-dd (e.g. 2020-03-05) format or, if the day of the month isn’t known, as yyyy-mm (e.g. 2020-03). However, any format is allowed and the column can be parsed to the proper yyyy-mm-dd format using custom_R_code. If the same collection date applies to the entire study it can be added directly into the metadata.yml file.\nIf applicable, ensure there are columns for all context properties, including experimental treatments, specific differences in method, a stratified sampling scheme within a plot, or sampling season. Additional context columns could be added through custom_R_code or keyed in where traits are added, but it is best to include a column in the data.csv file whenever possible. The protocol for adding context properties to the metadata file is under adding contexts\n\n\n\nData may need to be summarised\nData submitted by a contributor should be in the rawest form possible; always request data with individual measurements over location/species means.\nSome datasets include replicate measurements on an individual at a single point in time, such as the leaf area of 5 individual leaves. In AusTraits (the Australian plant trait database) we generally merge such measurements into an individual mean in the data.csv file, but the raw values are preserved in the contributor’s raw data files. Be sure to calculate the number of replicates that contributed to each mean value.\nWhen there is just a single column of trait values to summarise, use:\nreadr::read_csv(\"data/dataset_id/raw/raw_data.csv\") %&gt;%\n  dplyr::group_by(individual, `species name`, location, context, etc) %&gt;%\n  dplyr::summarise(\n    leaf_area_mean = mean(leaf_area),\n    leaf_area_replicates = n()\n    ) %&gt;%\n  dplyr::ungroup()\nMake sure you group_by all categorical variables you want to retain, for only columns that are grouping variables will be kept.\nWhen you want to take the mean of multiple data columns simultaneously, use:\nreadr::read_csv(\"data/dataset_id/raw/raw_data.csv\") %&gt;%\n  dplyr::group_by(individual, `species name`, location, context, etc) %&gt;%\n  dplyr::summarise(\n    across(c(leaf_area, `leaf N`), ~ mean(.x, na.rm = TRUE)),\n    across(c(growth_form, `photosynthetic pathway`), ~ first(.x)),\n    replicates = n()\n  ) %&gt;%\n  dplyr::ungroup()\n{dplyr} hints:\n\nCategorical variables not included as grouping variables will return NA.\nGenerally use the function first for categorical variables - it simply retains the trait value in the first column.\nYou can identify runs of columns by column number/position. For instance c(5:25), ~ mean(.x, na.rm = TRUE) or c(leaf_area:leaf_N), ~ mean(.x, na.rm = TRUE).\nBe sure to ungroup at the end.\nBefore summarising, ensure variables you expect are numeric, are indeed numeric: utils::str(data).\n\n\n\nMerging multiple spreadsheets\nIf multiple spreadsheets of data are submitted these must be merged together.\n\nIf the spreadsheets include different trait measurements made on the same individual (or location means for the same species), they are best merged using dplyr::left_join, specifying all conditions that need to be matched across spreadsheets (e.g. individual, species, location, context). Ensure the column names are identical between spreadsheets or specify columns that need to be matched.\n\nreadr::read_csv(\"data/dataset_id/raw/data_file_1.csv\") -&gt; data_1\nreadr::read_csv(\"data/dataset_id/raw/data_file_2.csv\") -&gt; data_2\n\ndata_1 %&gt;% \n  dplyr::left_join(\n    data_2,\n    by = c(\"Individual\", \"Taxon\" = \"taxon\", \"Location\", \"Context\")\n  )\n\nIf the spreadsheets include trait measurements for different individuals (or possibly data at different scales - such as individual level data for some traits and species means for other traits), they are best merged using dplyr::bind_rows. Ensure the column names for taxon name, location name, context, individual, and collection date are identical between spreadsheets. If there are data for the same traits in both spreadsheets, make sure those column headers are identical as well.\n\nreadr::read_csv(\"data/dataset_id/raw/data_file_1.csv\") -&gt; data_1\nreadr::read_csv(\"data/dataset_id/raw/data_file_2.csv\") -&gt; data_2\n\ndata_1 %&gt;% \n  dplyr::bind_rows(data_2)\n\n\nTaxon names\nTaxon names need to be complete names. If the main data file includes code names, with a key as a separate file, they are best merged now to avoid many individual replacements later.\nreadr::read_csv(\"data/dataset_id/raw/species_key.csv\") -&gt; species_key\nreadr::read_csv(\"data/dataset_id/raw/data_file.csv\")  -&gt; data\n\ndata %&gt;%\n  dplyr::left_join(species_key, by = \"code\")\n\n\nUnexpected hangups\n\nWhen Excel saves an .xls file as a .csv file it only preserves the number of significant figures that are displayed on the screen. This means that if, for some reason, a column has been set to display a very low number of significant figures or a column is very narrow, data quality is lost.\nIf you’re reading a file into R where there are lots of blanks at the beginning of a column of numeric data, the defaults for readr::read_csvfail to register the column as numeric. It is fixed by adding the argumentguess_max`:\n\nread_csv(\"data/dataset_id/raw/raw_data.csv\", guess_max = 10000)\nThis checks 10,000 rows of data before declaring the column is non-numeric.\n(When data.csv files are read in through the {traits.build} workflow, guess_max = 100000.)",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Adding datasets, a lengthy guide</span>"
    ]
  },
  {
    "objectID": "adding_data_long.html#metadata_file",
    "href": "adding_data_long.html#metadata_file",
    "title": "24  Adding datasets, a lengthy guide",
    "section": "24.5 Constructing the metadata.yml file",
    "text": "24.5 Constructing the metadata.yml file\nAs described in detail here the metadata.yml file maps the meanings of the individual columns within the data.csv file and documents all additional dataset metadata.\nBefore beginning, it is a good idea to look at the two example dataset metadata files in the traits.build-template repository, to become familiar with the general structure.\nThe sections of the metadata.yml file are:\n\nsource\ncontributors\ndataset (includes adding custom R code)\nlocations\ncontexts\ntraits\nsubstitutions\ntaxonomic_updates\nexclude_observations\nquestions\n\nThis document covers these metadata sections in sequence.\n\nUse a proper text editor\n\nInstall a proper text editor, such as Visual Studio Code (our favorite), Rstudio, textmate, or sublime text. Using Microsoft word will make a mess of the formatting.\n\n\n\nSource the {traits.build} functions\nTo assist you in constructing the metadata.yml file, we have developed functions to help propagate and fill in the different sections of the file.\nIf you haven’t already, run:\nlibrary(traits.build)\nThe functions for populating the metadata file all begin with metadata_.\nA full list is available here.\n\n\nCreating a template\nThe first step is to create a blank metadata.yml file.\ntraits.build::metadata_create_template(\"Yang_2028\")\nAs each function prompts you to enter the dataset_id, it can be useful to assign the dataset’s id to a variable you can use repeatedly:\ncurrent_study &lt;- \"Yang_2028\"\n\ntraits.build::metadata_create_template(current_study)\nThis function cycles through a series of user-input menus, querying about both the data format (long versus wide) and which columns contain which variables (taxon name, location name, individual identifiers, collection date). It then creates a relatively empty metadata file data/dataset_id/metadata.yml.\nThe questions are:\n\nIs the data long or wide format?\n\nA wide dataset has each variable (i.e. trait ) as a column. A long dataset has a single row containing all trait values.\n\nSelect column for taxon_name\nSelect column for trait_name (long datasets only)\nSelect column for trait values (long datasets only)\nSelect column for location_name\n\nIf your data.csv file does not yet have a location_name column, this information can later be added manually.\n\nSelect column for individual_id (a column that links measurements on the same individual)\nSelect column for collection_date\n\nIf your data.csv file does not have a collection_date column, you will be prompted to Enter collection_date range in format ‘2007/2009’. A fixed value in a yyyy, yyyy-mm or yyyy-mm-dd format is accepted, either as a single value or range of values. This information can be edited later.\n\nIndicate whether all traits need repeat_measurements_id’s\n\nrepeat_measurements_id’s are only required if the dataset documents response curve data (e.g. an A-ci or light response curve for plants; or a temperature response curve for animal or plant behaviour). They can also be added to individual traits (later). They are intended to capture multiple “sub-measurements” that together comprise a single “trait measurement”.\n\n\nAdding a source\nThe skeletal metadata.yml file created by metadata_create_template included a section for the primary source with default fields for a journal article.\nYou can manually enter citation details, but whenever possible, use one of the three functions developed to automatically propagate citation details.\n\nAdding source from a doi\nIf you have a doi for your study, use the function.\ntraits.build::metadata_add_source_doi(dataset_id = current_study, doi = \"doi\")\nThe different elements within the source will automatically be generated.\nDouble check the information added to ensure:\n\nThe title is in sentence case.\n\nThe information isn’t in all caps (sources from a few journals gets read in as all caps).\nPages numbers are present and include -- between page numbers (for example, 123 -- 134).\nIf there is a colon (:) or apostrophe (’) in a reference, the text for that line must be in quotes (“).\n\nBy default, details are added as the primary source. If multiple sources are linked to a single dataset_id, you can specify a source as secondary.\ntraits.build::metadata_add_source_doi(dataset_id = current_study, doi = \"doi\", \n                                      type = \"secondary\")\n\nAttempting to add a second primary source will overwrite the information already input. Instead, if there is a third resource to add, use type = \"secondary_2\"\nAlways check the key field, as it can be incorrect for hyphenated last names.\nIf the dataset being entered is a compilation of many original sources, you should add all the original sources, specifying, type = \"original_01\", type = \"original_02\" etc. See Richards_2008 for an example of a complex source list.\n\n\n\nAdding source from a bibtex file\ntraits.build::metadata_add_source_doi(dataset_id, file = \"myref.bib\")\n(These options require the packages rcrossref and RefManageR to be installed.)\n\n\nProper formatting of different source types\nDifferent source types require different fields, formatting:\nBook:\nsource:\n  primary:\n      key: Cooper_2013\n      bibtype: Book\n      year: 2013\n      author: Wendy Cooper and William T. Cooper\n      title: Australian rainforest fruits\n      publisher: CSIRO Publishing\n      pages: 272\nOnline resource:\nsource:\n  primary:\n    key: TMAG_2009\n    bibtype: Online\n    author: '{Tasmanian Herbarium}'\n    year: 2009\n    title: Flora of Tasmania Online\n    publisher: Tasmanian Museum & Art Gallery (Hobart)\n    url: http://www.tmag.tas.gov.au/floratasmania\nThesis:\nsource:\n  primary:\n      key: Kanowski_2000\n      bibtype: Thesis\n      year: 1999\n      author: John Kanowski\n      title: Ecological determinants of the distribution and abundance of the folivorous\n        marsupials endemic to the rainforests of the Atherton uplands, north Queensland.\n      type: PhD\n      institution: James Cook University, Townsville\nUnpublished dataset:\nsource:\n  primary:\n    key: Ooi_2018\n    bibtype: Unpublished\n    year: 2018\n    author: Mark K. J. Ooi\n    title: \"Unpublished data: Herbivory survey within Royal National Park, University\n      of New South Wales\"\n\nNote the title of an unpublished dataset must begin with the words “Unpublished data” and include the data collectors affiliation.\n\n\n\n\nAdding contributors\nThe skeletal metadata.yml file created by the function metadata_create_template includes a template for entering details about data contributors. Edit this manually, duplicating if details for multiple people are required.\n\ndata_collectors are people who played a key intellectual role in the study’s experimental design and data collection. Most studies have 1-3 data_collectors listed. Four fields of information are required for each data collector: last_name, given_name, affiliation and ORCID (if available). Nominate a single data collector to be the dataset’s point of contact.\nAdditional field assistants can be listed under assistants.\nThe data entry person is listed under dataset_curators.\nemail addresses for the data_collectors are not included in the metadata.yml file, but it is recommended that a database curator maintain a list of email addresses of all data collectors to whom authorship may be extended on a future database data paper. Authorship “rules” will vary across databases, but for AusTraits we extend authorship to all data_collectors who we successfully contact.\n\nFor example, in Roderick_2002:\ncontributors:\n  data_collectors:\n  - last_name: Roderick\n    given_name: Michael\n    ORCID: 0000-0002-3630-7739\n    affiliation: The Australian National University, Australia\n    additional_role: contact\n  assistants: Michelle Cochrane\n  dataset_curators: Elizabeth Wenk\n\n\nCustom R code\nThe goal is always to maintain data.csv files that are as similar as possible to the contributed dataset. However, for many studies there are minor changes we want to make to a dataset before the data.csv file is processed by the {traits.build} workflow. These may include applying a function to transform a particular column of data, a function to filter data, or a function to replace a contributor’s “measurement missing” placeholder symbol with NA. In each case it is appropriate to leave the rawer data in data.csv and edit the data table as it is read into the {traits.build} workflow.\n\nBackground\nTo allow custom modifications to a particular dataset before the common pipeline of operations gets applied, the workflow permits for some customised R code to be run as a first step in the processing pipeline. That pipeline (the function process_custom_code called within dataset_process) looks like this:\ndata &lt;-\n  readr::read_csv(filename_data_raw, col_types = cols(), guess_max = 100000, \n                  progress = FALSE) %&gt;%\n  process_custom_code(metadata[[\"dataset\"]][[\"custom_R_code\"]])()\nThe second line shows that the custom code gets applied, right after the file is loaded.\n\n\nOverview of options and syntax\n\nA copy of the file containing functions the AusTraits team have explicitly developed to use within the custom_R_code field is available at custom_R_code.R and should be placed with the R folder within your database repository, then sourced (source(\"R/custom_R_code.R\")).\nPlace a single apostrophe (’) at the start and end of your custom R code; this allows you to add line breaks between pipes.\nBegin your custom R code with data %&gt;%, then apply whatever fixes are needed.\nUse functions from the packages dplyr, tiydr, stringr (e.g. mutate, rename, summarise, str_detect), but avoid other packages.\nAlternatively, use the functions we’ve created explicitly for pre-processing data that were sourced through the file custom.R. You may choose to expand this file within your own database repository.\nCustom R code is not intended for reading in files. Any reading in and merging of multiple files should be done before creating the dataset’s data.csv file.\nUse pipes to weave together a single statement, where possible. If you need to manipulate/subset the data.csv file into multiple data frames and then bind them back together, you’ll need to use semi colons ; at the end of each statement.\n\n\nExamples of appropriate use of custom R code\n\nConverting times to NY strings\n\nMost sources from herbaria record flowering_time and fruiting_time as a span of months, while AusTraits codes these variables as a sequence of 12 N’s and Y’s for the 12 months. A series of functions make this conversion in custom_R_code. These include:\n\n‘format_flowering_months’ (Create flowering times from start to end pair)\n‘convert_month_range_string_to_binary’ (Converts flowering and fruiting month ranges to 12 element character strings of binary data)\n‘convert_month_range_vec_to_binary’ (Convert vectors of month range to 12 element character strings of binary data)\n‘collapse_multirow_phenology_data_to_binary_vec’ (Converts multi-row phenology data to a 12 digit binary string)\n\n\nSplitting ranges into min, max pairs\n\nMany datasets from herbaria record traits like leaf_length, leaf_width, seed_length, etc. as a range (e.g. 2-8). The function separate_range separates this data into a pair of columns with minimum and maximum values, which is the preferable way to merge the data into a trait database.\n\nRemoving duplicate values within a dataset\n\nDuplicate values within a study need to be filtered out using the custom function replace_duplicates_with_NA\nIf a species-level trait value has been entered repeatedly on rows containing individual-level trait measurements, you need to filter out the duplicates. For instance, plant growth form is generally a species-level observation, with the same value on every row with individual-level trait measurements. There are also instances, where a population-level numeric trait appears repeatedly, such as if nutrient analyses were performed on a bulked sample at each site.\nBefore applying the function, you must group by the variable(s) that contain the unique values. This might be at the species or population level. For instance, use group_by(Species, Location) if there are unique values at the species x location level.\ndata %&gt;%\n  dplyr::group_by(Species) %&gt;%\n    dplyr::mutate(\n      across(c(`leaf_percentN`, `plant growth form`), replace_duplicates_with_NA)\n      ) %&gt;%\n  dplyr::ungroup()\n\nRemoving duplicate values across datasets\n\nValues that were sourced from a different study need to be filtered out. See Duplicates between studies below -functions to automate this process are in progress.\n\nReplacing “missing values” with NA’s\n\nIf missing data values in a dataset are represented by a symbol, such as 0 or *, these need to be converted to NA’s:\ndata %&gt;% \n  dplyr::mutate(\n    across(c(`height (cm)`, `leaf area (mm2)`), ~ na_if(., 0))\n  )\n\nMapping data from one trait to a second trait, part 1\n\nIf a subset of data in a column are also values for a second trait in AusTraits, some data values can be duplicated into a second temporary column. In the example below, some data in the contributor’s fruit_type column also apply to the trait fruit_fleshiness in AusTraits:\ndata %&gt;% \n  dplyr::mutate(\n    fruit_fleshiness = ifelse(`fruit type` == \"pome\", \"fleshy\", NA)\n  )\nThe function move_values_to_new_trait is being developed to automate this and currently resides in the custom_R_code.R file within the austraits.build repository.\n\nMapping data from one trait to a second trait, part 2\n\nIf a subset of data in a column are instead values for a second trait in AusTraits, some data values can be moved to a second column (second trait), also using the function ‘move_values_to_new_trait’. In the example below, some data in the contributor’s growth_form column only apply to the trait parasitic in AusTraits. Note you need to create a blank variable, before moving the trait values.\ndata %&gt;%\n  dplyr::mutate(new_trait = NA_character) %&gt;%\n  move_values_to_new_trait(\n    original_trait = \"growth form\",\n    new_trait = \"parasitic\",\n    original_values = \"parasitic\",\n    values_for_new_trait = \"parasitic\",\n    values_to_keep = \"xx\") %&gt;%\n  dplyr::mutate(across(c(original_trait), ~ na_if(., \"xx\")))\nor\ndata %&gt;%\n  dplyr::mutate(dispersal_appendage = NA.char) %&gt;%\n  move_values_to_new_trait(\n    \"fruits\", \"dispersal_appendage\",\n    c(\"dry & winged\", \"enclosed in aril\"),\n    c(\"wings\", \"aril\"),\n    c(\"xx\", \"enclosed\") %&gt;%\n  dplyr::mutate(across(c(original_trait), ~ na_if(., \"xx\")))\n\nNote, the parameter values_to_keep doesn’t accept NA, leading to the clunky coding. This bug is known, but we haven’t managed to fix it.\n\n\nMutating a new trait from other traits\n\nIf the data.csv file includes raw data that you want to manipulate into a trait, or the contributor presents the data in a different formulation than AusTraits, you may choose to mutate a new column, containing a new trait.\ndata %&gt;% \n  dplyr::mutate(\n    root_mass_fraction = `root mass` / (`root mass` + `shoot mass`)\n  )\n\nMutating a location name column\n\nIf the dataset has location information, but lacks unique location names (or any location name), you might mutate a location name column to map in. (See also Adding location details).\ndata %&gt;%\n  dplyr::mutate(\n    location_name = ifelse(location_name == \"Mt Field\" & habitat == \"Montane rainforest\", \n                           \"Mt Field_wet\", location_name),\n    location_name = ifelse(location_name == \"Mt Field\" & habitat == \"Dry sclerophyll\", \n                           \"Mt Field_dry\", location_name)\n  )\nor\ndata %&gt;% \n  dplyr::mutate(\n    location_name = dplyr::case_when(\n      longitude == 151.233056 ~ \"heath\",\n      longitude == 151.245833 ~ \"terrace\",\n      longitude == 151.2917 ~ \"diatreme\"\n    )\n  )\n# Note with `dplyr::case_when`, \n# any rows that do not match any of the conditions become `NA`'s.\nor\ndata %&gt;% \n  dplyr::mutate(\n    location_name = paste0(\"lat_\", round(latitude,3),\"_long_\", round(longitude,3))\n    )\n  )\n\nGenerating measurement_remarks\n\nSometimes there is a note column with abbreviated information about individual rows of data that is appropriate to map as a context. This could be included in the field measurement_remarks:\ndata %&gt;%\n  dplyr::mutate(\n    measurement_remarks = paste0(\"maternal lineage \", Mother)\n  )\n\nReformatting dates\n\nYou can reformat collection_dates to conform to the yyyy-mm-dd format, or add a date column\nConverting from any mdy format to yyyy-mm-dd (e.g. Dec 3 2015 to 2015-12-03)\ndata %&gt;% \n  dplyr::mutate(\n    Date = Date %&gt;% lubridate::mdy()\n    )\nConverting from any dmy format to yyyy-mm-dd (e.g. 3-12-2015 to 2015-12-03)\ndata %&gt;% \n  dplyr::mutate(\n    Date = Date %&gt;% lubridate::dmy()\n    )\nConverting from a mmm-yyyy (string) format to yyyy-mm (e.g. Dec 2015 to 2015-12)\ndata %&gt;% \n  dplyr::mutate(\n    Date = \n      lubridate::parse_date_time(Date, orders = \"my\") %&gt;% \n      base::format.Date(\"%Y-%m\")\n    )\nConverting from a mdy format to yyyy-mm (e.g. Excel has reinterpreted the data as full dates 12-01-2015 but the resolution should be “month” 2015-12)\ndata %&gt;% \n  dplyr::mutate(\n    Date = \n      lubridate::parse_date_time(Date, orders = \"mdy\") %&gt;% \n      base::format.Date(\"%Y-%m\")\n    )\nA particularly complicated example where some dates are presented as yyyy-mm and others as yyyy-mm-dd\ndata %&gt;%\n    dplyr::mutate(\n      weird_date = ifelse(stringr::str_detect(gathering_date, \"^[0-9]{4}\"), \n                          gathering_date, NA),\n      gathering_date = gathering_date %&gt;% \n          lubridate::mdy(quiet = T) %&gt;% as.character(),\n      gathering_date = coalesce(gathering_date, weird_date)\n    ) %&gt;%\n    select(-weird_date)\n\n\n\nTesting your custom R code\nAfter you’ve added the custom R code to a file, check that output is indeed as intended:\nmetadata_check_custom_R_code(\"Blackman_2010\")\n\n\n\nFill in metadata[[\"dataset\"]]\nThe dataset section includes fields that are:\n\nfilled in automatically by the function metadata_create_template()\nmandatory fields that need to be filled in manually for all datasets\noptional fields that are included and filled in only for a subset of datasets\n\n\nfields automatically filled in\n\ndata_is_long_format yes/no\ntaxon_name\nlocation_name\ncollection_date If this is not read in as a specified column, it needs to be filled in manually as start date/end date in yyyy-mm-dd, yyyy-mm, or yyyy format, depending on the relevant resolution. If the collection dates are unknown, write unknown/publication year, as in unknown/2022\nindividual_id Individual_id is one of the fields that can be read in during metadata_create_template. However, you may instead mutate your own individual_id using custom_R_code and add it in manually. For a wide dataset individual_id is required anytime there are multiple rows of data for the same individual and you want to keep these linked. This field should only be included if it is required.\nWARNING If you have an entry individual_id: unknown this assigns all rows of data to an individual named “unknown” and the entire dataset will be assumed to be from a single individual. This is why it is essential to omit this field if there isn’t an actual row of data being read in.\nNOTE For individual-level measurements, each row of data is presumed to be a different individual during dataset processing. Individual_id is only required if there are multiple rows of data (long or wide format) with information for the same individual.\nrepeat_measurements_id repeat_measurement_id’s are sequential integer identifiers assigned to a sequence of measurements on a single trait that together represent a single observation (and are assigned a single observation_id by the traits.build pipeline. The assumption is that these are measurements that document points on a response curve. The function metadata_create_template offers an option to add it to metadata[[\"dataset\"]], but it can alternately be specified under specific traits, as repeat_measurements_id: TRUE\n\n\n\nrequired fields manually filled in\n\ndescription: 1-2 sentence description of the study’s goals. The abstract of a manuscript usually includes some good sentences/phrases to borrow.\nbasis_of_record: Basis of record can be coded in as a fixed value for an entire dataset, by trait, by location or read in from a column in the data.csv file. If it is being read in from a column list the column name in the field, otherwise input the fixed value. Allowable values are: field, field_experiment, captive_cultivated, lab, preserved_specimen, and literature. See the database structure vignette for definitions of these accepted basis_of_record values. If fixed values are specified for both the entire dataset under metadata[[\"dataset\"]] and for specific locations/traits under metadata[[\"locations\"]] or metadata[[\"traits\"]], the location/trait value overrides that entered under metadata[[\"dataset\"]].\nlife_stage: Life stage can be coded in as a fixed value for an entire dataset, by trait, by location or read in from a column in the data.csv file. If it is being read in from a column list the column name in the field, otherwise input the fixed value. Allowable values are: adult, sapling, seedling, juvenile. See the database structure vignette for definitions of these accepted basis_of_record values. If fixed values are specified for both the entire dataset under metadata[[\"dataset\"]] and for specific locations/traits under metadata[[\"locations\"]] or metadata[[\"traits\"]], the location/trait value overrides that entered under metadata[[\"dataset\"]].\nsampling_strategy: Often a quite long description of the sampling strategy, extracted verbatim from a manuscript whenever possible.\noriginal_file: The name of the file initially submitted to the database curators. It is generally archived in the dataset folder, in a subfolder named raw. For AusTraits datasets are also usually archived in the project’s GoogleDrive folder.\nnotes: Notes about the study and processing of data, especially if there were complications or if some data is suspected duplicates with another study and were filtered out.\n\n\n\noptional fields manually filled in\n\nmeasurement_remarks: Measurement remarks is a field to capture a miscellaneous notes column. This should be information that is not captured by trait methods (which is fixed to a single value for a trait) or as a context. Measurement_remarks can be coded in as a fixed value for an entire dataset, by trait, by location or read in from a column in the data.csv file.\nentity_type is standardly added to each trait, and is described below under traits, but a fixed value or column could be read in under metadata[[\"dataset\"]]\n\n\n\nAdding location details\nLocation data includes location names, latitude/longitude coordinates, verbal location descriptions, and any additional abiotic/biotic location variables provided by the contributor (or in the accompanying manuscript). For studies with more than a few locations, it is most efficient to create a table of this data that is automatically read into the metadata.yml file.\nThe function metadata_add_locations automatically propagates location information from a stand-alone location properties table into metadata[[\"locations\"]]:\nlocations &lt;- read_csv(\"data/dataset_id/raw/locations.csv\")\ntraits.build::metadata_add_locations(current_study, locations)\nThe function metadata_add_locations first prompts the user to identify the column with the location name and then to list all columns that contain location data. This automatically fills in the location component on the metadata file.\nRules for formatting a locations table to read in:\n\nLocation names must be identical (including syntax, case) to those in data.csv\nColumn headers for latitude and longitude data must read latitude (deg) and longitude (deg)\nLatitude and longitude must be in decimal degrees (i.e. -46.5832). There are many online converters to convert from degrees,minutes,seconds format or UTM. Or use the following formula: decimal_degrees = degrees + (minutes/60) + (seconds/3600)\nIf there is a column with a general vegetation description (i.e. rainforest, coastal heath it should be titled description)\nAlthough location properties are not restricted to a controlled vocabulary, newly added studies should use the same location property syntax as others whenever possible, to allow future discoverability. To generate a list of already used under location_property:\n\ndatabase$locations %&gt;% dplyr::distinct(location_property)\nSome examples of syntax to add locations data that exists in different formats.\n\nWhen the main data.csv file has columns for a few location properties:\n\nlocations &lt;-\n  check_custom_R_code(current_study) %&gt;%\n    dplyr::distinct(location_name, latitude, longitude, `veg type`) %&gt;%\n    dplyr::rename(dplyr::all_of(c(\"latitude (deg)\" = \"latitude\",\n                                  \"longitude (deg)\" = \"longitude\", \n                                  \"description\" = \"veg type\")))\n\ntraits.build::metadata_add_locations(current_study, locations)\n\nIf you were to want to add or edit the data, it is probably easiest to save the locations table, then edit in Excel, before reading it back into R\nIt is possible that you will want to specify life_stage or basis_of_record at the location_level. When required, it is usually easiest to manually add these fields to some or all locations.\n\n\n\n\nAdding contexts\nThe dictionary definition of a context is the situation within which something exists or happens, and that can help explain it. This is exactly what context_properties are in AusTraits, ancillary information that is important to explaining and understanding a trait value.\nAusTraits recognises 5 categories of contexts:\n\ntreatment contexts Context property that is a feature of a plot (subset of a location) that might affect the trait values measured on an individual, population or species-level entity. Examples include soil nutrient manipulations, growing temperatures, or CO2 enhancement.\nplot contexts Context property that is a feature of a plot (subset of a location) that might affect the trait values measured on an individual, population or species-level entity. Examples are an property that is stratified within a “geographic location”, such as topographic position. Plots are of course locations themselves; what is a location vs plot_context depends on the geographic resolution a dataset collector has applied to their locations.\nentity contexts Context property that is information about an organismal entity (individual, population or taxon) that does not comprise a trait-centered observation but might affect the trait values measured on the entity. This might be the entity’s sex, caste (for social insects), or host plant (for insects).\ntemporal contexts Context property that is a feature of a “point in time” that might affect the trait values measured on an individual, population or species-level entity. They generally represent repeat measurements on the same entity across time and may simply be numbered observations or might be explicitly linked to growing season or time of day.\nmethod contexts Context property that records specific information about a measurement method that is modified between measurements. These might be samples from different canopy light environments, different leaf ages, or sapwood samples from different branch diameters.\n\nContext properties are not restricted to a controlled vocabulary. However, newly added studies should use the same context property syntax as others whenever possible, to allow future discoverability. To generate a list of terms already used under context_property, use:\ndatabase$contexts %&gt;% \n  dplyr::distinct(context_property, category)\nContext properties are most easily read into the metadata.yml file with the dedicated function:\ntraits.build::metadata_add_contexts(dataset_id)\nThe function first displays a list of all data columns (from the data.csv file) and prompts you to select those that are context properties.\n\nFor each column you are asked to indicate its category (those described above).\nYou are shown a list of the unique values present in the data column and asked if these require any substitutions. (y/n)\nYou are asked if descriptions are required for the context property values (y/n)\n\nThis function then adds the contexts to the metadata[[\"contexts\"]] section.\nIf you selected both substitutions and descriptions required:\n- context_property: unknown\n  category: temporal_context\n  var_in: month\n  values:\n  - find: AUG\n    value: unknown\n    description: unknown\n  - find: DEC\n    value: unknown\n    description: unknown\n  - find: FEB\n    value: unknown\n    description: unknown\n- context_property: unknown\n  category: treatment_context\n  var_in: CO2_Treat\n  values:\n  - find: ambient CO2\n    value: unknown\n    description: unknown\n  - find: added CO2\n    value: unknown\n    description: unknown\nIf you selected just substitutions required:\n- context_property: unknown\n  category: temporal_context\n  var_in: month\n  values:\n  - find: AUG\n    value: unknown\n  - find: DEC\n    value: unknown\n  - find: FEB\n    value: unknown\n- context_property: unknown\n  category: treatment_context\n  var_in: CO2_Treat\n  values:\n  - find: ambient CO2\n    value: unknown\n  - find: added CO2\n    value: unknown\nIf you selected neither substitutions nor descriptions required:\n- context_property: unknown\n  category: temporal_context\n  var_in: month\n- context_property: unknown\n  category: treatment_context\n  var_in: CO2_Treat\n\nYou must then manually fill in the fields designated as unknown.\nIf there is a value in a column that is not a context property, set its value to value: .na\n\nIf there are additional context properties that were designated in the traits section, these will have to be added manually, as this information is not captured in a column that is read in. A final output might be:\n- context_property: sampling season\n  category: temporal_context\n  var_in: month\n  values:\n  - find: AUG\n    value: August\n    description: August (late winter)\n  - find: DEC\n    value: December\n    description: December (early summer)\n  - find: FEB\n    value: February\n    description: February (late summer)\n- context_property: CO2 treatment\n  category: treatment_context\n  var_in: CO2_Treat\n  values:\n  - find: ambient CO2\n    value: 400 ppm\n    description: Plants grown at ambient CO2 (400 ppm).\n  - find: added CO2\n    value: 640 ppm\n    description: Plants grown at elevated CO2 (640 ppm); 240 ppm above ambient.\n- context_property: measurement temperature\n  category: method_context\n  var_in: method_context          # this field would be included in the relevant traits\n  values:\n  - value: 20°C                   # this value would be keyed in through the relevant traits\n    description: Measurement made at 20°C\n  - value: 25°C\n    description: Measurement made at 25°C\n\n\nAdding traits\nThe function metadata_add_traits() adds a scaffold for trait metadata to the skeletal metadata.yml file.\nmetadata_add_traits(current_study)\nYou will be asked to indicate which columns include trait data.\nThis automatically propagates the following metadata fields for each trait selected into metadata[[\"traits\"]. var_in is the name of a column in the data.csv file (for wide datasets) or a unique trait name in the trait_name column (for a long dataset):\n- var_in: leaf area (mm2)\n  unit_in: .na\n  trait_name: .na\n  entity_type: .na\n  value_type: .na\n  basis_of_value: .na\n  replicates: .na\n  methods: .na\nThe trait details then need to be filled in manually.\n\nunits: fill in the units associated with the trait values in the submitted dataset - such as mm2 in the example above. If you’re uncertain about the syntax/format used for some more complex units, look through the traits definition file (config/traits.yml) or the file showing unit conversions (config/unit_conversions.csv). For categorical variables, leave this as .na.\n\nAusTraits uses the Unified Code for Units of Measure (UCUM) standard for units (https://ucum.org/ucum), but each database using the traits.build workflow can select their own choices for unit abbreviations. The UCUM standard follows clear, simple rules, but also has a flexible syntax for documenting notes that are recorded as part of the ‘unit’ for specific traits, yet are not formally units, in curly brackets. For instance, {count}/mm2 or umol{CO2}/m2/s, where the actual units are 1/mm2 and umol/m2/s. There are a few not-very-intuitive units in UCUM. a is year (annum).\nNotes:\n- If the units start with a punctuation symbol, the units must be in single, straight quotes, such as: unit_in: '{count}/mm2'\n- It is best not to start units with a - (negative sign). In AusTraits we’ve adopted the convention of using, for instance, neg_MPa instead of -MPa\n\ntrait_name: This is the trait name of the appropriate trait concept for the datasets config/traits.yml. For currently unsupported traits, leave this as .na but then fill in the rest of the data and flag this study as having a potential new trait concept. Then in the future, if an appropriate trait concept is added to the traits.yml file, the data can be read into the database by simply replacing the .na with a trait name. Each database will have their own criteria/rules for adding traits to the trait dictionary, and likely rules that evolve as a trait database grows. In AusTraits, if no appropriate trait concept exists in the trait dictionary, a new trait must be defined within the accompanying AusTraits Plant Dictionary and should only be added if it is clearly a distinct trait concept, can be explicitly defined, and there exists sufficient trait data that the measurements have comparative value.\nentity_type: Entity type indicates “what” is being observed for the trait measurements - as in the organismal-level to which the trait measurements apply. As such, entity_type can be individual, population, species, genus, family or order. Metapopulation-level measurements are coded as population and infraspecific taxon-level measurements are coded as species. See the database structure vignette for definitions of these accepted entity_type values.\n\nNote:\n- entity_type is about the “organismal-level” to which the trait measurement refers; this is separate from the taxonomic resolution of the entity’s name.\n\nvalue_type: Value type indicates the statistical nature of the trait value recorded. Allowable value types are mean, minimum, maximum, mode, range, raw, and bin. See the database structure vignette for definitions of these accepted value types. All categorical traits are generally scored as being a mode, the most commonly observed value. Note that for values that are bins, the two numbers are separated by a double-hyphen, 1 -- 10.\nbasis_of_value: Basis of value indicates how a value was determined. Allowable terms are measurement, expert_score, model_derived, and literature. See the database structure vignette for definitions of these accepted basis_of_value values, but most categorical traits measurements are values that have been scored by an expert (expert_score) and most numeric trait values are measurements.\nreplicates: Fill in with the appropriate number of measurements that comprise each value.\n\nIf the values are raw values (i.e. a measurement of an individual) replicates: 1.\nIf the values are, for instance, means of 5 leaves from an individual, replicates: 5.\nIf there is just a single population-level value for a trait, that comprises measurements on 5 individuals, replicates: 5.\nFor categorical variables, leave this as .na.\nIf there is a column that specifies replicate number, you can list the column name in the field.\n\nmethods: This information can usually be copied verbatim from a manuscript and is a textual description of all components of the method used to measure the trait.\n\nIn general, methods sections extracted from pdfs include “special characters” (non-UTF-8 characters). Non-English alphabet characters are recognised (e.g. é, ö) and should remain unchanged. Other characters will be re-formatted during the study input process, so double check that degree symbols (º), en-dashes (–), em-dashes (—), and curly quotes (‘,’,“,”) have been maintained or reformatted with a suitable alternative. Greek letters and some other characters are replaced with their Unicode equivalent (e.g. &lt;U+03A8&gt; replaces Psi (Ψ)); for these it is best to replace the symbol with an interpretable English-character equivalent.\nIf the there are two columns of data with measurements for the same trait using completely different methods, simply add the respective methods to the metadata for the respective columns. A method_id counter will be added to these during processing to ensure the correct trait values are linked to the correct methods. This is separate to method_contexts which are minor tweaks to the methods between measurements, that are expected to have concurrent effects on trait values (see below).\nNOTE:\n- If the identical methods apply to a string of traits, for the first trait use the following syntax, where the &leaf_length_method notation assigns the remaining text in the field as the leaf_length_method.\n  methods: &leaf_length_method All measurements were from dry herbarium \n    collections, with leaf and bracteole measurements taken from the largest \n    of these structures on each specimen.\nThen for the next trait that uses this method you can just include. At the end of processing you can read/write the yml file and this will fill in the assigned text throughout.\n  methods: *leaf_length_method\nIn addition to the automatically propagated fields, there are a number of optional fields you can add if appropriate.\n\nlife_stage If all measurements in a dataset were made on plants of the same life stage a global value should be entered under metadata[[\"dataset\"]]. However if different traits were measured at different life stages you can specify a unique life stage for each trait or indicate a column where this information is stored.\nbasis_of_record If all measurements in a dataset represent the same basis_of_record a global value should be entered under metadata[[\"dataset\"]]. However if different traits have different basis_of_record values you can specify a unique basis_of_record value for each trait or indicate a column where this information is stored.\nmeasurement_remarks: Measurement remarks is a field to indicate miscellaneous comments. If these comments only apply to specific trait(s), this field should be specified with those trait’s metadata sections. This meant to be information that is not captured by “methods” (which is fixed to a single value for a trait).\nmethod_context If different columns in a wide data.csv file indicate measurements on the same trait using different methods, this needs to be designated. At the bottom of the trait’s metadata, add a method_context_name field (e.g. method_context or leaf_age_type are good options). Write a word or short phrase that indicate the method context property value that applies to that trait (data column). For instance, one trait might have method_context: fully expanded leaves and a second traits entry might have the same trait name and methods, but method_context: leaves still expanding. The method context details must also be added to the contexts section.\ntemporal_context If different columns in a wide data.csv file indicate measurements on the same trait, on the same individuals at different points in time, this needs to be designated. At the bottom of the trait’s metadata, add a temporal_context_name field (e.g. temporal_context or measurement_time_of_day work well). Write a word or short phrase that indicates which temporal context applies to that trait (data column). For instance, one trait might have temporal_context: dry season and a second entry with the same trait name and method might have temporal_context: after rain. The temporal context details must also be added to the contexts section.\n\n\n\nAdding substitutions\nIt is very unlikely that a contributor will use categorical trait values that are entirely identical to those listed as allowed trait values for the corresponding trait concept in the traits.yml file. You need to add substitutions for those that do not exactly align to match the wording and syntax of the trait values in the trait dictionary.\nmetadata[[\"substitutions\"]] entries are formatted as:\nsubstitutions:\n- trait_name: dispersal_appendage\n  find: attached carpels\n  replace: floral_parts\n- trait_name: dispersal_appendage\n  find: awn\n  replace: bristles\n- trait_name: dispersal_appendage\n  find: awn bristles\n  replace: bristles\nThe three elements it includes are:\n- trait_name is the AusTraits defined trait name.\n- find is the trait value used in the data.csv file.\n- replace is the trait value supported by AusTraits.\nYou can manually type substitutions into the metadata.yml file, ensuring you have the syntax and spacing accurate.\nAlternately, function metadata_add_substitution adds single substitutions directly into metadata[[\"substitutions\"]]:\ntraits.build::metadata_add_substitution(current_study, \"trait_name\", \"find\", \"replace\")\nNotes:\n- Combinations of multiple trait values are allowed - simply list them, space delimited (e.g. shrub tree for a species whose growth form includes both).\n- Combinations of multiple trait values are reorganised into alphabetic order in order to collapse into fewer combinations (e.g. “fire_killed resprouts” and “resprouts fire_killed” are alphabetised and hence collapsed into one combination, “fire_killed resprouts”).\n- If a trait value is N or Y that needs to be in single, straight quotes (usually edited later, directly in the metadata.yml file)\nIf you have many substitutions to add, it is more efficient to create a spreadsheet with a list of all trait_name by trait_value combinations requiring substitutions. The spreadsheet would have four columns with headers dataset_id, trait_name, find and replace. This table can be read directly into the metadata.yml file using the function metadata_add_substitutions_table:\nsubstitutions_to_add &lt;- \n  readr::read_csv(\"data/dataset_id/raw/substitutions_required.csv\")\n\ntraits.build::metadata_add_substitutions_list(current_study, substitutions_to_add)\nOnce you’ve build the new dataset (see below), you can quickly create a table of all values that require substitutions:\naustraits$excluded_data %&gt;%\n  filter(\n    dataset_id == current_study,\n    error == \"Unsupported trait value\"\n  ) %&gt;%\n  distinct(dataset_id, trait_name, value) %&gt;%\n  rename(\"find\" = \"value\") %&gt;%\n  select(-dataset_id) %&gt;%\n  write_csv(\"data/dataset_id/raw/substitutions_required.csv\")\nManually add the aligned values in Excel, then:\nsubstitutions_to_add &lt;-\n  readr::read_csv(\"data/dataset_id/raw/substitutions_required_after_editing.csv\")\n\nmetadata_add_substitutions_list(dataset_id, substitutions_to_add)\n\n\nAdding taxonomic updates\nmetadata[[\"taxonomic_updates\"]] is a metadata section to document edits to taxonomic names to align the names submitted by the dataset contributor with a taxon name in the databases taxonomic resources master list, config/taxon_list.csv. This includes correcting typos, standardising syntax (punctuation, abbreviations used for words like subspecies), and reformatting names to adhere to taxonomic standards for a specific taxon group and a specific databases’ rules.\nmetadata[[\"taxonomic_updates\"]] entries are formatted as:\ntaxonomic_updates:\n- find: Acacia ancistrophylla/sclerophylla\n  replace: Acacia sp. [Acacia ancistrophylla/sclerophylla; White_2020]\n  reason: Rewording taxon where `/` indicates uncertain species identification \n    to align with `APC accepted` genus (2022-11-10)\n  taxonomic_resolution: genus\n- find: Pimelea neo-anglica\n  replace: Pimelea neoanglica\n  reason: Fuzzy alignment with accepted canonical name in APC (2022-11-22)\n  taxonomic_resolution: species\n- find: Plantago gaudichaudiana\n  replace: Plantago gaudichaudii\n  reason: Fuzzy alignment with accepted canonical name in APC (2022-11-10)\n  taxonomic_resolution: species\n- find: Poa sp.\n  replace: Poa sp. [Angevin_2011]\n  reason: Adding dataset_id to genus-level taxon names. (2023-06-16)\n  taxonomic_resolution: genus\n- find: Polyalthia (Wyvur)\n  replace: Polyalthia sp. (Wyvuri B.P.Hyland RFK2632)\n  reason: Fuzzy match alignment with species-level canonical name in `APC known` \n    when everything except first 2 words ignored (2022-11-10)\n  taxonomic_resolution: Species\nNotes:\n- Each trait database will have their own conventions for how to align names that cannot be perfectly matched to an accepted/valid taxon concept. The examples and notes provided here indicate the conventions used by AusTraits.\n- Poa sp. and Acacia ancistrophylla/sclerophylla are examples of taxon names that can only be aligned to genus. The taxonomic_resolution is therefore specified as genus. The portion of the name that can be aligned to the taxonomic resource must be before the square brackets. Any information within the square brackets is important for uniquely identifying this entry within the trait database, but does not provide additional taxonomic information.\n- Polyalthia (Wyvur) is a poorly formatted phrase name that has been matched to its appropriate syntax in the APC.\nThe four elements it includes are:\n- find: The original name given to taxon in the original data supplied by the authors.\n- replace: The updated taxon name, that should now to aligned to a taxon name within the chosen taxonomic reference.\n- reason: Records why the change was implemented, e.g. typos, taxonomic synonyms, and standardising spellings.\n- taxonomic_resolution: The rank of the most specific taxon name (or scientific name) to which a submitted original name resolves.\nThe function metadata_add_taxonomic_change adds single taxonomic updates directly into metadata[[\"taxonomic_updates\"]]:\ntraits.build::metadata_add_taxonomic_change(current_study, \n                                            \"find\", \"replace\", \"reason\", \n                                            \"taxonomic_resolution\")\nThe function metadata_add_taxonomic_changes_list adds a table of taxonomic updates directly into metadata[[\"taxonomic_updates\"]]. The column headers must be find, replace, reason, and taxonomic_resolution.\ntraits.build::metadata_add_taxonomic_changes_list(current_study, table_of_substitutions)\nWorking manually through taxonomic alignments for all datasets in a database can be a huge time sink. The AusTraits team developed the R-package {APCalign} to automate the process of aligning names of Australian plants to names within the National Species Lists, the APC and APNI. This is supplemented by an AusTraits-specific function build_align_taxon_names that uses {APCalign} to automatically add taxonomic_updates to metadata.yml files. While these packages/functions are Australian-plant specific, they include code that can be re-purposed for other global regions or taxonomic groups.\nFor instance,\ntaxon_list &lt;- readr::read_csv(\"config/taxon_list.csv\")\n\nnames_to_align &lt;- \n  database$taxonomic_updates %&gt;%\n    dplyr::filter(dataset_id == current_study) %&gt;%\n    # next row down might be modified to also filter names in an external taxonomic resource\n    dplyr::filter(!aligned_name %in% taxon_list$aligned_name) %&gt;%\n    dplyr::filter(is.na(taxonomic_resolution)) %&gt;%\n    dplyr::distinct(original_name)\nSome of these names will require alignments and others might be truly garbage (unknown species 1) and should instead be excluded.\n\n\nExcluded observations\nmetadata[[\"exclude_observations\"]] is a metadata section for excluding specific variable (column) values. It is most often used to exclude specific taxon names, but could be used for locations, trait_name, etc. These are values that are in the data.csv file but should be excluded from AusTraits.\nmetadata[[\"exclude_observations\"]] entries are formatted as:\nexclude_observations:\n- variable: taxon_name\n  find: Campylopus introflexus, Dicranoloma menziesii, Philonotis tenuis, Polytrichastrum\n    alpinum, Polytrichum juniperinum, Sphagnum cristatum\n  reason: moss (E Wenk, 2020.06.18)\n- variable: taxon_name\n  find: Xanthoparmelia semiviridis\n  reason: lichen (E Wenk, 2020.06.18)\nThe three elements it includes are: - variable: A variable from the traits table, typically taxon_name, location_name or context_name\n- find: Value of variable to remove\n- reason: Records why the data were removed, e.g. exotic\nNOTE: Multiple, comma-delimited values can be added under find.\nThe function metadata_exclude_observations adds single exclusions directly into metadata[[\"exclude_observations\"]]:\ntraits.build::metadata_exclude_observations(current_study, \"variable\", \"find\", \"reason\")\n\n\nQuestions\nThe final section of the metadata.yml file is titled questions. This is a location to:\n\nAsk the data contributor targeted questions about their study. When you generate a report (described below) these questions will appear at the top of the report.\n\nPreface the first question you have with contributor: (indented once), and additional questions with question2:, etc.\nAsk contributors about missing metadata\nPoint contributors attention to odd data distributions, to make sure they look at those traits extra carefully.\nLet contributors know if you’re uncertain about their units or if you transformed the data in a fairly major way.\nAsk the contributors if you’re uncertain you aligned their trait names correctly.\n\nThis is a place to list any trait data that are not yet traits supported by AusTraits. Use the following syntax, indented once: additional_traits:, followed by a list of traits.\n\n\n\nHooray! You now have a fully propagated metadata.yml file!\nNext is making sure it has captured all the data exactly as you’ve intended.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Adding datasets, a lengthy guide</span>"
    ]
  },
  {
    "objectID": "adding_data_long.html#quality_checks",
    "href": "adding_data_long.html#quality_checks",
    "title": "24  Adding datasets, a lengthy guide",
    "section": "24.6 Quality checks",
    "text": "24.6 Quality checks\nIf you haven’t done so already, assign the dataset_id to a variable, current_study:\ncurrent_study &lt;- \"Wright_2001\"\nThis lets you have a list of tests you run for each study and you just have to reassign a new dataset_id to current_study.\n\nClear formatting\nThe clear formatting code below reads and re-writes the yaml file. This is the same process that is repeated when running functions that automatically add substitutions or check taxonomy. Running it first ensures that any formatting issues introduced (or fixed) during the read/write process are identified and solved first.\nFor instance, the write_metadata function inserts line breaks every 80 characters and reworks other line breaks (except in custom_R_code). It also reformats special characters in the text, substituting in its accepted format for degree symbols, en-dashes, em-dashes and quotes, and substituting in Unicode codes for more obscure symbols.\nf &lt;- file.path(\"data\", current_study, \"metadata.yml\")\ntraits.build::read_metadata(f) %&gt;% traits.build::write_metadata(f)\n\n\nRunning tests\nAn extensive dataset test protocol ensures: - the metadata.yml file is complete and properly formatted - details entered into the metadata.yml file match those in the accompanying data.csv file (column names, values for locations, contexts) - details for each trait (trait name, categorical trait values) match those in the trait dictionary\nCertain special characters may show up as errors and need to be manually adjusted in the metadata.yml file\nTo run the dataset tests,\n# Tests run test on one study\ntraits.build::dataset_test(current_study)\n\n# Tests run test on all studies\ntraits.build::dataset_test(dir(\"data\"))\nMessages identify errors in the dataset, hopefully pointing you quickly to the changes that are required.\nDo not be disheartened by errors when you first run tests on a newly entered dataset - even after adding 100’s of datasets into AusTraits it is very rare to have zero errors on a first run of dataset_test().\nFix as many errors as you can and then rerun dataset_test() repeatedly until no errors remain.\nYou may want to fix errors in tandem with building the new dataset, such as to be able to quickly compile a list of trait values requiring substitutions or taxon names requiring taxonomic updates\nSee the common issues chapter for solutions to common issues, such as:\n- dataset not pivoting\n- unsupported trait values\n\n\nRebuild AusTraits\nTo continue your checks it is necessary to rebuild your database.\nUntil tests come back clean you can simply build the new dataset:\ntraits.build::build_setup_pipeline(method = \"remake\", database_name = \"database\")\naustraits &lt;- remake::make(current_study)\nTo continue on to building the dataset report, you need to rebuild the entire database:\ntraits.build::build_setup_pipeline(method = \"remake\", database_name = \"database\")\naustraits &lt;- remake::make(\"austraits\")\n\n\nCheck excluded data\nAusTraits automatically excludes measurements for a number of reasons. Data might be excluded for legitimate reasons (value far out of range for a numeric trait) or because\nThese are available in the frame database$excluded_data.\nPossible reasons for excluding measurements include:\n\nMissing species name: Species name is missing from data.csv file for a given row of data. This usually occurs when there are stray characters in the data.csv file below the data – delete these rows.\nMissing unit conversion: Value was present but appropriate unit conversion was missing. This requires that you add a new unit conversion to the file config/unit_conversions.csv. Add additional conversions near similar unit conversions already in the file for easier searching in the future.\nObservation excluded in metadata: Specific values, usually certain taxon names can be excluded in the metadata. This is generally used when a study includes a number of non-native and non-naturalised species that need to be excluded. These should be intentional exclusions, as they have been added by you.\nTrait name not in trait dictionary: trait_name not listed in config/traits.yml as a trait concept. Double check you have used the correct spelling/exact syntax for the trait_name, adding a new trait concept to the traits.yml file if appropriate. If there is a trait that is currently unsupported by AusTraits, leave trait_name: .na. Do not fill in an arbitrary name.\nUnsupported trait value: This error, referencing categorical traits, means that the value for a trait is not included in the list of supported trait values for that trait in config/traits.yml. See adding many substitutions if there are many trait values requiring substitutions. If appropriate, add another trait value to the traits.yml file, but confer with other curators, as the lists of trait values have been carefully agreed upon through workshop sessions.\nValue does not convert to numeric: Is there a strange character in the file preventing easy conversion? This error is rare and generally justified.\nValue out of allowable range: This error, referencing numeric traits, means that the trait value, after unit conversions, falls outside of the allowable range specified for that trait in config/traits.yml. Sometimes the AusTraits range is too narrow and other times the author’s value is truly an outlier that should be excluded. Look closely at these and adjust the range in config/traits.yml if justified. Generally, don’t change the range until you’ve create a report for the study and confirmed that the general cloud of data aligns with other studies as excepted. Most frequently the units or unit conversion is what is incorrect.\nValue contains unsupported characters: This error appears if there are unusual punctuation characters in the trait name. As such characters do not appear as allowed values within the trait dictionary, these represent transient errors that need to be corrected through either metadata[[\"substitutions\"]] or, occasionally, in the data.csv file.\n\nWhen you are finished running quality checks, no data should be excluded due to Missing unit conversion, Trait name not in trait dictionary, and it should be very rare that any data is excluded due to Missing species name or Value contains unsupported characters.\nThe dataset curator should be confident that every value that lands in the excluded data table is their legitimately.\nFor instance, out of the 1.8 million+ records in AusTraits v5.0.0, the excluded data table contains:\n\n\n\nError\nCount\n\n\n\n\nObservation excluded in metadata\n4061\n\n\nUnsupported trait value\n354\n\n\nValue does not convert to numeric\n12\n\n\nValue out of allowable range\n427\n\n\n\nThe best way to view excluded data for a study is:\naustraits$excluded_data %&gt;%\n  dplyr::filter(\n    dataset_id == current_study,\n    error != \"Observation excluded in metadata\"\n  ) %&gt;%\n  View()\nMissing values (blank cells, cells with NA) are not included in the excluded_data table, because they are assumed to be legitimate blanks. If you want to confirm this, you need to temporarily change the default arguments for the internal function dataset_process where it is called within the remake.yml or build.R file that compiles the database. For instance, the default,\n      dataset_process(\"data/Ahrens_2019/data.csv\",\n                  Ahrens_2019_config,\n                  schema\n                 )\nneeds to be changed to:\n      dataset_process(\"data/Ahrens_2019/data.csv\",\n                  Ahrens_2019_config,\n                  schema,\n                  filter_missing_values = FALSE\n                 )\nTo check how many of each error type are present for a study:\ndatabase$excluded_data %&gt;%\n  dplyr::filter(dataset_id == current_study) %&gt;%\n  dplyr::pull(error) %&gt;%\n  table()\nOr produce a table of error type by trait:\ndatabase$excluded_data %&gt;%\n  dplyr::filter(\n    dataset_id == current_study,\n  ) %&gt;%\n  dplyr::select(trait_name, error) %&gt;%\n  table()\n\n\nBuild study report\nAnother important check for each study is building a study report, that summarises all metadata and trait data.\nMake sure you’ve rebuilt the entire database (not just the new study) before building the report.\ndatabase &lt;- remake::make(\"database\")\ntraits.build::dataset_report(database, current_study, overwrite = TRUE)\nNOTES:\n- The report will appear in the folder export/reports\n- The argument overwrite = TRUE overwrites pre-existing copies of the report in this folder.\nCheck the study report to ensure:\n\nAll possible metadata fields were filled in\n\nThe locations plot sensibly on the map\n\nFor numeric traits, the trait values plot sensibly relative to other studies\n\nThe list of unknown/unmatched species doesn’t include names you think should be recognised/aligned\n\nIf necessary, cycle back through earlier steps to fix any errors, rebuilding the study report as necessary\nAt the very end, re-clear formatting, re-run tests, rebuild AusTraits, rebuild report.\nTo generate a report for a collection of studies:\ntraits.build::dataset_reports(database, c(\"Falster_2005_1\", \"Wright_2002\"), \n                              overwrite = TRUE)\nOr for all studies:\ntraits.build::dataset_reports(database, overwrite = TRUE)\n(Reports are written in Rmarkdown and generated via the knitr package. The template is here).",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Adding datasets, a lengthy guide</span>"
    ]
  },
  {
    "objectID": "check_dataset_functions.html",
    "href": "check_dataset_functions.html",
    "title": "25  Check data quality functions",
    "section": "",
    "text": "25.1 Functions to summarise excluded data\nChecking the data quality in each newly input dataset is essential to maintain the credibility of a trait database. The automated components of the workflow offer a number of quality checks, but can only include tests for situations where there is a solution to every “error”. Other erroneous data values are placed in the excluded_data table. And there are categories of data that simply need a closer look.\nThe functions here are additional checks that should be run on datasets, such that the database curator is confident data are appropriately included or excluded.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Check data quality functions</span>"
    ]
  },
  {
    "objectID": "check_dataset_functions.html#functions-to-summarise-excluded-data",
    "href": "check_dataset_functions.html#functions-to-summarise-excluded-data",
    "title": "25  Check data quality functions",
    "section": "",
    "text": "dataset_check_categorical_substitutions\noutput: Table of categorical trait values that require substitutions\nIf a categorical trait value is not identical to an allowed value in the corresponding trait concept in the accompanying trait dictionary (traits.yml file), it is moved to the excluded_data table. The following function generates a table of values requiring substitutions, as described in adding data\nThe output table needs to be edited, to map an appropriate replacement for each unsupported trait value. This is generally most easily accomplished in Excel or a text editor.\n\ndataset_check_categorical_substitutions &lt;- function(database, dataset) {\n\n  required_substitutions &lt;-\n    database$excluded_data %&gt;%\n      dplyr::filter(\n        dataset_id == dataset,\n        error == \"Unsupported trait value\"\n      ) %&gt;%\n      dplyr::distinct(dataset_id, trait_name, value) %&gt;%\n      dplyr::rename(find = value) %&gt;%\n      dplyr::select(-\"dataset_id\") %&gt;%\n      dplyr::mutate(replace = NA)\n\n  required_substitutions\n\n}\n\n\n\ndataset_check_numeric_values\noutput: Table of out-of-range numeric trait values:\nFor numeric traits, if a trait value falls outside the allowed range, as defined for the specific trait concept in the accompanying trait dictionary (traits.yml file), it is moved to the excluded_data table. The following function generates a table of values that have been excluded. If the table is long, it is almost certainly due to a units-conversion error. This is not likely to be a list to save or edit, but simply confirming there isn’t an error in how a trait was mapped or calculated and that the excluded trait values are legitimately excluded.\n\ndataset_check_numeric_values &lt;- function(database, dataset) {\n\n  out_of_range_values &lt;-\n    database$excluded_data %&gt;%\n      dplyr::filter(\n        dataset_id == dataset,\n        error == \"Value out of allowable range\"\n      ) %&gt;%\n      dplyr::select(\n        dplyr::all_of(c(\"dataset_id\", \"trait_name\", \"value\", \n                        \"observation_id\", \"unit\", \"original_name\")))\n\n  out_of_range_values\n\n}\n\n\n\ndataset_check_taxonomic_updates\noutput: Table of taxon names requiring taxonomic_updates\nAn aligned_name in the taxonomic_updates table of a newly added dataset might not be in the database’s taxon_list.csv file for two reasons: 1) It requires aligning due to typos, non-standard syntax; 2) The taxon_list.csv file does not include all possible taxon names and needs to be updated from an external resource. Each database requires its own taxonomy functions and taxonomic references, but this function creates a list of names that require further effort to align.\n\ntaxon_list &lt;- readr::read_csv(\"config/taxon_list.csv\")\n\ndataset_check_taxonomic_updates &lt;- function(taxon_list, database, dataset) {\n\n  database$taxonomic_updates %&gt;%\n    dplyr::filter(dataset_id == dataset) %&gt;%\n    dplyr::filter(!aligned_name %in% taxon_list$aligned_name,  \n                    !aligned_name %in% taxon_list$taxon_name) %&gt;%\n    dplyr::filter(is.na(taxonomic_resolution)) %&gt;%\n    dplyr::distinct(original_name)\n\n}",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Check data quality functions</span>"
    ]
  },
  {
    "objectID": "check_dataset_functions.html#functions-to-troubleshoot-tests",
    "href": "check_dataset_functions.html#functions-to-troubleshoot-tests",
    "title": "25  Check data quality functions",
    "section": "25.2 Functions to troubleshoot tests",
    "text": "25.2 Functions to troubleshoot tests\n\ndataset_check_not_pivoting\noutput: Table of trait measurements that are preventing the dataset from pivoting\nOne of the automated tests is the function dataset_test() confirms the dataset can pivot from longer to wider. This tests is confirming that each row in the traits table has a unique combination of a particular 7 columns: dataset_id, trait_name, observation_id, value_type, repeat_measurements_id, method_id, method_context_id. When a dataset does not pivot wider, it is generally because observation_id has not been correctly parsed during the dataset processing. observation_id is an integral counter within a dataset that represents unique combinations of taxon_name, population_id, individual_id, temporal_context_id, entity_type, life_stage, source_id, entity_context_id, basis_of_record, collection_date, original_name. If any of these 11 pieces of metadata are incorrectly encoded in the metadata file, two distinct observations of traits might be assigned identical observation_id’s. The most likely culprits are forgetting to map in a context property or a column with source_id’s.\nOverall, there are 17 separate columns that could be causing the db_traits_pivot_wider() test from dataset_test() to fail, making it difficult to discern where to trouble shoot. This function outputs a list of trait measurements that is causing the pivot test to fail, allowing you to hone in on the source of the problem.\n\ndataset_check_not_pivoting &lt;- function(database, dataset) {\n\n  # Check for duplicates\n  rows_cannot_pivot &lt;-\n    database$traits %&gt;%\n      dplyr::filter(.data$dataset_id %in% dataset) %&gt;%\n      dplyr::select(\n        # `taxon_name` and `original_name` are not needed for pivoting but are included for informative purposes\n        dplyr::all_of(\n          c(\"dataset_id\", \"trait_name\", \"value\", \"taxon_name\", \"original_name\", \n          \"observation_id\", \"value_type\", \"repeat_measurements_id\", \"method_id\", \n          \"method_context_id\"))\n      ) %&gt;%\n      tidyr::pivot_wider(\n        names_from = \"trait_name\",\n        values_from = \"value\",\n        values_fn = length\n      ) %&gt;%\n      tidyr::pivot_longer(cols = 9:ncol(.)) %&gt;%\n      dplyr::rename(dplyr::all_of(\n        c(\"trait_name\" = \"name\", \"number_of_duplicates\" = \"value\")\n        )) %&gt;%\n      dplyr::select(\n        dplyr::all_of(c(\"dataset_id\", \"trait_name\", \"number_of_duplicates\",\n        \"taxon_name\", \"original_name\", \"observation_id\", \"value_type\")), everything()\n      ) %&gt;%\n      dplyr::filter(.data$number_of_duplicates &gt; 1)\n\n  rows_cannot_pivot\n\n}",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Check data quality functions</span>"
    ]
  },
  {
    "objectID": "check_dataset_functions.html#functions-to-detect-outliers-duplicates",
    "href": "check_dataset_functions.html#functions-to-detect-outliers-duplicates",
    "title": "25  Check data quality functions",
    "section": "25.3 Functions to detect outliers, duplicates",
    "text": "25.3 Functions to detect outliers, duplicates\n\ndataset_check_outlier_by_species\noutput: Table for numeric trait values that are x% higher/lower than the mean trait value for the species.\nAlthough there is an automated process for eliminating trait values outside the allowable range specified in the accompanying trait dictionary, this filter cannot determine if a trait value is in range for a specific taxon. For plants, checking outliers on a taxon-by-taxon basis is particularly relevant for a trait like seed_dry_mass where values across all taxa can vary by 10^10, but values within a taxon are quite constrained. It is fraught to implement this as an automated filter, as the “correct” value for taxa is not known. Instead, this function, and the accompanying dataset_check_outlier_by_genus() allow the user to look at outliers (per their definition) on a trait-by-trait basis, deciding if specific values appear erroneous. Note that this function of course only “works” once a database that already has some data for the taxon. The function also filters for taxa that have at least 5 observations of the trait.\nA multiplier value of 100 or 1000 will often help identify true outliers, while a multiplier value of 10 is likely to flag legitimate trait values.\n\ndataset_check_outlier_by_species &lt;- function(database, dataset, trait, multiplier) {\n\n  to_compare &lt;-\n    database$traits %&gt;%\n    dplyr::filter(dataset_id == dataset)\n\n  comparisons &lt;- database$traits %&gt;%\n    dplyr::filter(trait_name == trait) %&gt;%\n    dplyr::filter(dataset_id != dataset) %&gt;%\n    dplyr::filter(taxon_name %in% to_compare$taxon_name) %&gt;%\n    dplyr::select(dplyr::all_of(c(\"taxon_name\", \"trait_name\", \"value\"))) %&gt;%\n    dplyr::group_by(taxon_name) %&gt;%\n    dplyr::mutate(\n      count = n(),\n      value = as.numeric(value)\n      ) %&gt;%\n    dplyr::filter(count &gt; 5) %&gt;%\n    dplyr::summarise(\n      trait_name = first(trait_name),\n      mean_value = mean(value),\n      std_dev = sd(value),\n      min_value = min(value),\n      max_value = max(value),\n      count = first(count)\n    ) %&gt;%\n    dplyr::ungroup()\n\n  need_review &lt;- to_compare %&gt;%\n    dplyr::filter(trait_name == trait) %&gt;%\n    dplyr::filter(taxon_name %in% comparisons$taxon_name) %&gt;%\n    dplyr::select(dplyr::all_of(c(\"taxon_name\", \"trait_name\", \"value\", \n                                  \"observation_id\", \"unit\", \"original_name\"))) %&gt;%\n    dplyr::left_join(\n      by = c(\"taxon_name\", \"trait_name\"),\n      comparisons) %&gt;%\n    dplyr::filter(as.numeric(value) &gt; multiplier*mean_value | \n                  as.numeric(value) &lt; (1/multiplier)*mean_value) %&gt;%\n    dplyr::mutate(value_ratio = as.numeric(value)/mean_value) %&gt;%\n    dplyr::arrange(dplyr::desc(value_ratio))\n\n  need_review\n\n}\n\n\n\ndataset_check_outlier_by_genus\noutput: Table for numeric trait values that are x% higher/lower than the mean trait value for the genus.\nAlthough there is an automated process for eliminating trait values outside the allowable range specified in the accompanying trait dictionary, this filter cannot determine if a trait value is in range for a specific taxon, for this function represented by the organism’s genus. For plants, checking outliers on a taxon-by-taxon basis is particularly relevant for a trait like seed_dry_mass where values across all plant taxa can vary by 10^10, but values within a taxon are quite constrained. It is fraught to implement this as an automated filter, as the “correct” value for taxa is not known. Instead, this function, and the accompanying dataset_check_outlier_by_species() allow the user to look at outliers (per their definition) on a trait-by-trait basis, deciding if specific values appear erroneous when compared to the average for all measurements recorded for members of the specified genus. Note that this function of course only “works” once a database already has some data for the genus. Also note, that this function is worthless for traits where members of the genus display a broad range of trait values; it will readily identify “outliers” for species whose trait values correctly lie well outside of the “normal” range for the genus.\n\ndataset_check_outlier_by_genus &lt;- function(database, dataset, trait, multiplier) {\n\n  to_compare &lt;-\n    database$traits %&gt;%\n    dplyr::filter(dataset_id == dataset) %&gt;%\n    dplyr::left_join(by = c(\"taxon_name\"), \n                     database$taxa %&gt;% dplyr::select(dplyr::all_of(c(\"taxon_name\", \"genus\"))))\n\n  comparisons &lt;- database$traits %&gt;%\n    dplyr::filter(trait_name == trait) %&gt;%\n    dplyr::filter(dataset_id != dataset) %&gt;%\n    dplyr::left_join(by = c(\"taxon_name\"), \n                     database$taxa %&gt;% dplyr::select(dplyr::all_of(c(\"taxon_name\", \"genus\")))) %&gt;%\n    dplyr::filter(genus %in% to_compare$genus) %&gt;%\n    dplyr::select(dplyr::all_of(c(\"genus\", \"trait_name\", \"value\"))) %&gt;%\n    dplyr::group_by(genus) %&gt;%\n    dplyr::mutate(\n      count = n(),\n      value = as.numeric(value)\n    ) %&gt;%\n    dplyr::filter(count &gt; 5) %&gt;%\n    dplyr::summarise(\n      trait_name = first(trait_name),\n      mean_value = mean(value),\n      std_dev = sd(value),\n      min_value = min(value),\n      max_value = max(value),\n      count = first(count)\n    ) %&gt;%\n    dplyr::ungroup()\n\n  need_review &lt;- to_compare %&gt;%\n    dplyr::filter(trait_name == trait) %&gt;%\n    dplyr::filter(genus %in% comparisons$genus) %&gt;%\n    dplyr::select(dplyr::all_of(c(\"taxon_name\", \"trait_name\", \"value\", \"genus\", \n                                  \"observation_id\", \"unit\", \"original_name\"))) %&gt;%\n    dplyr::left_join(\n      by = c(\"genus\", \"trait_name\"),\n      comparisons) %&gt;%\n    dplyr::filter(as.numeric(value) &gt; multiplier*mean_value | \n                  as.numeric(value) &lt; (1/multiplier)*mean_value) %&gt;%\n    dplyr::mutate(value_ratio = as.numeric(value)/mean_value) %&gt;%\n    dplyr::arrange(dplyr::desc(value_ratio))\n\n  need_review\n\n}\n\n\n\ndataset_check_duplicates_across_datasets\noutput: Table of suspected duplicates across datasets.\nThis function still needs to be written. AusTraits team members have developed trait-specific and dataset-specific code in the past, but extrapolating it into a generalised function is difficult, as it requires assumptions about how many significant figures to retain when comparing trait values and for traits where all plants display a narrow range of values (such as nutrient contents), it is likely to mistakenly flag values as duplicates. The core purpose of this function will be to identify clusters of identical trait measurements that have been submitted to the database twice, either because two collaborators submitted the same dataset or because a dataset was contributed both by the data collector and as part of a broader compilation. For AusTraits, the function should identify “legitimate” duplicates, where information was extracted for the same taxon from different state floras; these will likely include mostly identical trait values.\nIf you would like to help write such a function for use with {traits.build} databases, please leave an issue here, then flag that you are working on it.\n\ndataset_check_duplicates_across_datasets &lt;- function(database, dataset, trait) {\n\n  ## TO BE WRITTEN\n\n}\n\n\n\ndataset_check_duplicates_within_dataset\noutput: Table of suspected duplicates within a datasets\nThis function will flag duplicate taxon x trait values within a dataset. Duplicates within a dataset are common when a species-level trait value (i.e. plant_growth_form) is reported on every row, beside individual level measurements (i.e. leaf_mass_per_area). There are also instances where, for some traits, there is a single bulked measurement across many individuals, with that value reported for each individual that contributed to the bulked sample (i.e. leaf_N_per_dry_mass). If the same measurement is reported twice, it needs to be removed using custom_R_code, as described here under item 3.\nFor numeric traits where all individuals of a taxon will display a narrow range of values, especially if the trait is standardly reported to only a few significant figures (e.g. nutrient contents) duplication is absolutely expected. It is only if n_duplicates is a large number or you note that, for instance, n_duplicates is identical for every taxon for a specific trait that you should be suspicious of within-dataset duplication.\nNote that the value reported in the traits table may have many significant figures, even though the values in the data.csv file do not, if the value has been manipulated by custom_R_code or during trait parsing - for instance, if the value reported is the inverse of the value submitted, as commonly occurs in plant trait datasets as specific_leaf_area is converted to leaf_mass_per_area.\n\ndataset_check_duplicates_within_dataset &lt;- function(database, dataset) {\n\n  duplicates_within_dataset &lt;-\n    database$traits %&gt;%\n      dplyr::filter(dataset_id == dataset) %&gt;%\n      dplyr::select(dplyr::all_of(c(\"taxon_name\", \"trait_name\", \"value\", \"entity_type\"))) %&gt;%\n      dplyr::group_by(taxon_name, trait_name, entity_type, value) %&gt;%\n        dplyr::summarise(\n          n_duplicates = n()\n        ) %&gt;%\n      dplyr::ungroup() %&gt;%\n      dplyr::filter(n_duplicates &gt; 1)\n\n  duplicates_within_dataset\n\n}",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Check data quality functions</span>"
    ]
  },
  {
    "objectID": "data_common_issues.html",
    "href": "data_common_issues.html",
    "title": "26  Common issues",
    "section": "",
    "text": "26.1 Unsupported trait values\nNote, this chapter is a work in progress. It will be expanded over time.\nThis error occurs when, for a categorical trait, the value in data.csv is different to the value in the traits dictionary (config/traits.yml).\ntable &lt;- my_database$excluded_data %&gt;%\n  filter(dataset_id == current_study) %&gt;%\n  filter(error == \"Unsupported trait value\") %&gt;%\n  select(dataset_id, trait_name, value) %&gt;%\n  distinct()\nYou can individually add substitutions to metadata.yml using the function metadata_add_substitution\nmetadata_add_substitution(\n  dataset_id = current_study,\n  trait_name = \"plant_growth_form\",\n  find = \"T\",\n  replace = \"tree\"\n)\nOr, you can add an additional column to the table output (code above) and read it into metadata.yml using the function metadata_add_substitutions_table\nThe table read in must have the columns dataset_id, trait_name, find, and replace.\nThis is a hypothetical example for a table that contains 5 rows with plant_growth_form value that need updating.\ntable &lt;- table %&gt;%\n  rename(find = value) %&gt;%\n  mutate(replace = c(\"tree\", \"mallee\", \"shrub\", \"graminoid\", \"herb\"))\n\nmetadata_add_substitutions_table(\n  table,\n  dataset_id = dataset_id,\n  trait_name = trait_name,\n  find = find,\n  replace = replace\n)\nYou can of course also write the table to a csv file, edit it in Excel or a text editor, then read it back into R.\nwrite_csv(table, \"data/dataset_id/raw/substitutions_required.csv\")\n\n...edit outside of R\n\ntable &lt;- read_csv(\"data/dataset_id/raw/substitutions_required.csv\")",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Common issues</span>"
    ]
  },
  {
    "objectID": "data_common_issues.html#cannot_pivot",
    "href": "data_common_issues.html#cannot_pivot",
    "title": "26  Common issues",
    "section": "26.2 Dataset can’t pivot wider",
    "text": "26.2 Dataset can’t pivot wider\nIn order to convert a traits.build database into a wide format, the traits.build$traits table must be able to pivot wider.\nOne of the tests run during dataset_test is the function traits.build::check_pivot_wider(). This function checks that each row in the traits table has a unique combination of a particular 7 columns: dataset_id, trait_name, observation_id, value_type, repeat_measurements_id, method_id, method_context_id\nThere are two likely explanations – and solutions – to this error:\n\nIf your dataset combines individual (or population) level measurements with species-level measurements, the same species-level measurement may be read in many times. To solve this problem, you need to retain only the first instance of each species-level measurement, by including the following custom_R_code, where taxon_name is the column that contains taxon names and column 1, column 2, etc is a vector of the columns with categorical traits that require de-duplicating.\n\n\ndata %&gt;%\n  group_by(taxon_name) %&gt;%\n  mutate(across(c(\"column 1\", \"column 2\", \"column 3\"), replace_duplicates_with_NA))\n  ungroup()\n\n\nRows of data that represent measurements made at different times,\n\n… TBC",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Common issues</span>"
    ]
  },
  {
    "objectID": "github.html",
    "href": "github.html",
    "title": "27  Using GitHub",
    "section": "",
    "text": "27.1 Working with your GitHub repository\nFor {traits.build} users, the preferred way of hosting your database is on GitHub.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Using GitHub</span>"
    ]
  },
  {
    "objectID": "github.html#working-with-your-github-repository",
    "href": "github.html#working-with-your-github-repository",
    "title": "27  Using GitHub",
    "section": "",
    "text": "Setting up the repository\nThere are some GitHub settings we recommend: - General: Enable “Always suggest updating pull request branches” to keep the branch up to date with the main branch before merging - General: Enable “Automatically delete head branches” to delete the branch after merging, which keeps your branches clean - Branches: Add a branch protection rule for your main or develop branch and enable “Require a pull request before merging”, “Require conversation resolution before merging”, “Require deployments to succeed before merging”\n\nAutomated tests during pull requests\nTo run automated tests that must pass before a pull request can be merged in, you can set up GitHub workflows via the Actions tab on GitHub. The setting “Require deployments to succeed before merging” must be enabled for the main or develop branch. You can write your own workflows which are stored in .github/workflows/. For {austraits.build}, the GitHub workflow runs dataset_test on all data sources and compiles the database (see here).\n\n\n\nAdding to the repository\nNew data can be added to the repository by creating a branch and then opening a pull request (PR). Those who want to contribute but aren’t approved maintainers of the database, must fork and clone the database from GitHub.\nIn short,\n\nCreate a Git branch for your new work, either within the repo (if you are an approved contributor) or as a fork of the repo.\nMake commits and push these up onto the branch.\nMake sure everything runs fine before you send a PR (see tutorials for adding datasets).\nSubmit the PR and tag someone as a reviewer.\nSquash and merge the PR once approved and any changes have been made.\n\nTip: For working with git and GitHub, we recommend GitHub Desktop, a user-friendly graphical interface tool.\n\nMerging a pull request\nThe easiest way to merge a PR is to use GitHub’s built-in options for squashing and merging. This leads to:\n\nA single commit\nThe work is attributed to the original author\n\nYou can merge in a PR after it has been approved. To merge a PR, you need to be an approved maintainer. You do not need to be the original author of the PR (the commit will still be by the original author).\n\nSend the PR.\nTag someone to review.\nIf there are any updates to the main branch, merge those into your new branch and resolve any conflicts.\nOnce ready, merge into the main branch, choosing “Squash & Merge”, using an informative commit message. “Squash” merges all your commits on the branch into one.\n\n\nCommit messages\nInformative commit messages are ideal. They should clearly describe the work done and value added to the database in a few, clear, bulleted points. If relevant, they should reference any GitHub issues. You can link to and directly close GitHub issues via the commit message. To link to another commit you can also use the SHA-hash or its 7-character prefix.\nAn example commit message:\nSmith_1996: Add study\n- For #224, closes #286\n- Trait data for Nothofagus forests across Australia, New Zealand and South America",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Using GitHub</span>"
    ]
  },
  {
    "objectID": "github.html#bugs-and-feature-requests-for-traits.build",
    "href": "github.html#bugs-and-feature-requests-for-traits.build",
    "title": "27  Using GitHub",
    "section": "27.2 Bugs and feature requests for {traits.build}",
    "text": "27.2 Bugs and feature requests for {traits.build}\nIf you find a bug or have a feature request for {traits.build}, file a GitHub issue on {traits.build}. Illustrate the bug with a minimal reprex (reproducible example). Please feel free to contribute by implementing the fix or feature via pull request. For substantial pull requests, it is best to first check with the {traits.build} team that it’s worth pursuing the problem.",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Using GitHub</span>"
    ]
  },
  {
    "objectID": "versioned_releases.html",
    "href": "versioned_releases.html",
    "title": "28  Version updating & making a new release",
    "section": "",
    "text": "Releases of your database are snapshots that are archived and available for use.\nWe suggest semantic versioning to label your versions. As discussed in Falster et al 2019, semantic versioning can apply to datasets as well as code.\nThe version number will have 3 components for actual releases, and 4 for development versions. The structure is major.minor.patch.dev, where dev is at least 9000. The dev component provides a visual signal that this is a development version. So, if the current version is 0.9.1.9000, the release will be be 0.9.2, 0.10.0 or 1.0.0.\nOur approach to incrementing version numbers is:\n\nmajor: Increment when you make changes to the structure that are likely incompatible with any code written to work with previous versions.\nminor: Increment to communicate any changes to the structure that are likely to be compatible with any code written to work with the previous versions (i.e., allows code to run without error). Such changes might involve adding new data within the existing structure, so that the previous database version exists as a subset of the new version. For tabular data, this includes adding columns or rows. On the other hand, removing data should constitute a major version because records previously relied on may no longer exist.\npatch: Increment to communicate correction of errors in the actual data, without any changes to the structure. Such changes are unlikely to break or change analyses written with the previous version in a substantial way.\n\n\nFigure: Semantic versioning communicates to users the types of changes that have occurred between successive versions of an evolving dataset, using a tri-digit label where increments in a number indicate major, minor, and patch-level changes, respectively. From Falster et al 2019, (CC-BY).\nThe process of making a release is as follows. Note that corresponding releases and versions are needed in both austraits and traits.build: #TODO - this is no longer true right?\n\nUpdate the version number in the DESCRIPTION file, using:\n\n\ndesc::desc_bump_version() # Specify `which` argument for type of version increment\n\n\nCompile the database.\nUpdate documentation.\nCommit and push to GitHub (using PR workflow).\nMake a release on GitHub, adding version number.\nPrepare for the next version by updating version numbers.\n\n\ndesc::desc_bump_version(\"dev\")",
    "crumbs": [
      "Guide to adding data",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Version updating & making a new release</span>"
    ]
  },
  {
    "objectID": "austraits_database.html",
    "href": "austraits_database.html",
    "title": "29  AusTraits, Australia’s Plant Trait Database",
    "section": "",
    "text": "29.1 AusTraits data records\nAusTraits, Australia’s largest plant trait database was the first trait database to be build using the traits.build workflow.\nAs of October, 2023, AusTraits has:",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>AusTraits, Australia's Plant Trait Database</span>"
    ]
  },
  {
    "objectID": "austraits_database.html#austraits-data-records",
    "href": "austraits_database.html#austraits-data-records",
    "title": "29  AusTraits, Australia’s Plant Trait Database",
    "section": "",
    "text": "370+ datasets \n250+ contributors \n1,800,000+ data records \n500+ traits \n30,000 Australian plant taxa",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>AusTraits, Australia's Plant Trait Database</span>"
    ]
  },
  {
    "objectID": "austraits_database.html#accessing-austraits-data",
    "href": "austraits_database.html#accessing-austraits-data",
    "title": "29  AusTraits, Australia’s Plant Trait Database",
    "section": "29.2 Accessing AusTraits data",
    "text": "29.2 Accessing AusTraits data\nThere are multiple ways to access and manipulate AusTraits data.\n\n\nDownload the dataset from Zenodo\n\nSource AusTraits using the austraits R package\n\nClone the austraits.build GitHub repository and build AusTraits from the current develop branch (not easily reproducible)\n\n\nDownload database with austraits.R package\nFirst install and source the package: \n\ninstall.packages(\"remotes\")  # if it isn't already installed on your machine\n\nremotes::install_github(\"traitecoevo/austraits\", dependencies = TRUE, upgrade = \"ask\")\n\nlibrary(austraits) \n\nBefore loading AusTraits, see what versions are available,\n\naustraits::get_versions()\n\n# A tibble: 6 × 4\n  publication_date doi                     version id      \n  &lt;date&gt;           &lt;chr&gt;                   &lt;chr&gt;   &lt;chr&gt;   \n1 2024-05-14       10.5281/zenodo.11188867 6.0.0   11188867\n2 2023-11-19       10.5281/zenodo.10156222 5.0.0   10156222\n3 2023-09-18       10.5281/zenodo.8353840  4.2.0   8353840 \n4 2023-01-30       10.5281/zenodo.7583087  4.1.0   7583087 \n5 2022-11-27       10.5281/zenodo.7368074  4.0.0   7368074 \n6 2021-07-14       10.5281/zenodo.5112001  3.0.2   5112001 \n\n\nDownload the most recently released version:\n\nmost_recent_doi &lt;- austraits::get_versions()|&gt; dplyr::pull(\"doi\") |&gt; dplyr::first()\n\nmost_recent_doi\n\naustraits &lt;- austraits::load_austraits(doi = most_recent) # you can load from the Zenodo doi\n\naustraits &lt;- austraits::load_austraits(version = \"5.0.0\") # you can load from the version\n                                                          # the `path` argument stores a copy for future use.",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>AusTraits, Australia's Plant Trait Database</span>"
    ]
  },
  {
    "objectID": "AusTraits_tutorial.html",
    "href": "AusTraits_tutorial.html",
    "title": "30  AusTraits tutorial",
    "section": "",
    "text": "30.1 Introduction\nWith more than 1.8 million data records, AusTraits is Australia’s largest plant trait database, created using the {traits.build} R package\nThis tutorial introduces:\nTo access more information about traits.build, see traits.build-book\nOr you can visit the Github repositories for individual packages/data repos:",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>AusTraits tutorial</span>"
    ]
  },
  {
    "objectID": "AusTraits_tutorial.html#introduction",
    "href": "AusTraits_tutorial.html#introduction",
    "title": "30  AusTraits tutorial",
    "section": "",
    "text": "the database structure\n{austraits} R package functions\nadditional examples of analyses using the database\n\n\n\n\nthe database structure: traits.build\nthe database contents: austraits.build\nan R package for exploring and wrangling the data: austraits",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>AusTraits tutorial</span>"
    ]
  },
  {
    "objectID": "AusTraits_tutorial.html#download-austraits-data",
    "href": "AusTraits_tutorial.html#download-austraits-data",
    "title": "30  AusTraits tutorial",
    "section": "30.2 Download AusTraits data",
    "text": "30.2 Download AusTraits data\nBefore you begin, download and source essential packages and functions.\n\n# Packages need to be installed the first time you use them.\n# They are commented out here, so they aren't reinstalled each time you run the code, \n# but install any packages you require the first time you run this tutorial.\n\n#install.packages(\"readr\", \"tidyr\", \"dplyr\", \"stringr\", \"remotes\")\nlibrary(readr)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(stringr)\n\n#remotes::install_github(\"traitecoevo/austraits\", dependencies = TRUE, upgrade = \"ask\")\n#remotes::install_github(\"traitecoevo/traits.build\", dependencies = TRUE, upgrade = \"ask\")\n\nlibrary(austraits)    # functions for exploring a traits.build database, available at Github repo\n# XX library(traits.build) # additional functions for exploring a traits.build database, available at Github repo\n\n#source(\"https://raw.githubusercontent.com/traitecoevo/traits.build-book/master/data/extra_functions.R\")\nsource(\"data/extra_functions.R\")\n\nThen download (or build) the latest AusTraits database, using one of the methods described here.\nThis tutorial uses the most recent AusTraits release, version 6.0.0\n\nmost_recent &lt;- austraits::get_versions() %&gt;%\n  dplyr::pull(\"doi\") %&gt;%\n  dplyr::first()\n\nmost_recent\n\n[1] \"10.5281/zenodo.11188867\"\n\naustraits &lt;- austraits::load_austraits(doi = most_recent)\n\nDownloading AusTraits to 'data/austraits'\n\n\nLoading data from 'data/austraits/austraits-6.0.0.rds'",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>AusTraits tutorial</span>"
    ]
  },
  {
    "objectID": "AusTraits_tutorial.html#exploring",
    "href": "AusTraits_tutorial.html#exploring",
    "title": "30  AusTraits tutorial",
    "section": "30.3 A first look at data",
    "text": "30.3 A first look at data\nIf you’re not familiar with AusTraits, you may want to begin by exploring the breadth and depth of data within the database. The database can be explored by trait name, species, or genus using either austraits functions or dplyr functions.\nHow many taxa have leaf_N_per_dry_mass data in AusTraits?\n\n(austraits %&gt;% \n  austraits::extract_trait(trait_name = \"leaf_N_per_dry_mass\"))$traits %&gt;%\n  dplyr::distinct(taxon_name) %&gt;% nrow()\n\n[1] 2230\n\n\nHow are these data distributed across datasets?\n\naustraits::plot_trait_distribution_beeswarm(database = austraits, trait_name = \"leaf_N_per_dry_mass\", y_axis_category = \"dataset_id\")\n\n\n\n\n\n\n\n\nHow much data exist for other nitrogen traits?\n\naustraits::lookup_trait(austraits, \"_N_\") -&gt; N_traits\n\naustraits %&gt;% \n  austraits::extract_trait(trait_name = N_traits) %&gt;% \n  austraits::summarise_database(var = \"trait_name\") %&gt;%\n  dplyr::arrange(-n_taxa)\n\n# A tibble: 16 × 5\n   trait_name                           n_records n_dataset n_taxa percent_total\n   &lt;chr&gt;                                    &lt;int&gt;     &lt;int&gt;  &lt;int&gt;         &lt;dbl&gt;\n 1 leaf_N_per_dry_mass                      11314        87   2230      0.657   \n 2 leaf_N_per_area                           3726        30    708      0.216   \n 3 leaf_senesced_N_per_dry_mass               542         9     81      0.0315  \n 4 wood_N_per_dry_mass                        539         8     69      0.0313  \n 5 bark_N_per_dry_mass                        413         5     49      0.024   \n 6 seed_N_per_seed_dry_mass                    47         6     42      0.00273 \n 7 leaf_rubisco_N_per_total_leaf_N             68         1     29      0.00395 \n 8 leaf_thylakoid_N_per_total_leaf_N           70         1     29      0.00407 \n 9 stem_N_per_dry_mass                        157         3     28      0.00912 \n10 fruit_N_per_dry_mass                        31         5     22      0.0018  \n11 leaf_cell_wall_N_per_cell_wall_dry_…        29         1     22      0.00168 \n12 leaf_cell_wall_N_per_leaf_N                 29         1     22      0.00168 \n13 root_N_per_dry_mass                        141         4     22      0.00819 \n14 leaf_N_resorption                           86         1     14      0.005   \n15 wood_dead_N_per_dry_mass                     9         3      7      0.000523\n16 flower_N_per_dry_mass                       10         2      2      0.000581\n\n\nHow many “hydraulic” traits are in AusTraits? How much data exist for these traits?\n\naustraits::lookup_trait(austraits, \"hydraulic\") -&gt; hydraulic_traits\n\naustraits %&gt;% \n  austraits::extract_trait(trait_name = hydraulic_traits) %&gt;%\n  austraits::summarise_database(var = \"trait_name\") %&gt;%\n  dplyr::arrange(-n_taxa)\n\n# A tibble: 10 × 5\n   trait_name                           n_records n_dataset n_taxa percent_total\n   &lt;chr&gt;                                    &lt;int&gt;     &lt;int&gt;  &lt;int&gt;         &lt;dbl&gt;\n 1 stem_vessel_diameter_hydraulic             741         9    264       0.285  \n 2 sapwood_specific_hydraulic_conducti…       419         9    179       0.161  \n 3 leaf_specific_hydraulic_conductivity       472         9    168       0.181  \n 4 sapwood_specific_hydraulic_conducti…       343         6    164       0.132  \n 5 leaf_specific_hydraulic_conductance         81         2     79       0.0311 \n 6 stem_hydraulic_conductivity                261         5     51       0.1    \n 7 hydraulic_safety_margin_50                  46         2     31       0.0177 \n 8 hydraulic_safety_margin_88                  40         2     26       0.0154 \n 9 leaf_hydraulic_vulnerability                20         1     20       0.00768\n10 stem_specific_hydraulic_conductivity       181         3     14       0.0695 \n\n\nWhere have trait data for Acacia aneura been collected?\n\ndata &lt;-\n  austraits %&gt;%\n     austraits::extract_taxa(taxon_name = \"Acacia aneura\") %&gt;%\n     austraits::join_location_coordinates()\n\ndata$traits %&gt;% austraits::plot_locations(\"taxon_name\")\n\n\n\n\n\n\n\n\nWhere have data for Hibbertia species been collected?\n\ndata &lt;-\n  austraits %&gt;%\n     austraits::extract_taxa(genus = \"Hibbertia\") %&gt;%\n     austraits::join_location_coordinates() %&gt;%\n     austraits::join_taxa(var = \"genus\")\n\ndata$traits %&gt;% austraits::plot_locations(\"genus\")",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>AusTraits tutorial</span>"
    ]
  },
  {
    "objectID": "AusTraits_tutorial.html#database_structure",
    "href": "AusTraits_tutorial.html#database_structure",
    "title": "30  AusTraits tutorial",
    "section": "30.4 The database structure",
    "text": "30.4 The database structure\nThe {traits.build} R package is the workflow that builds AusTraits from its component datasets.\nThe database is output as a list, a collection of relational tables, described in detail here.\nA traits.build data object includes both the relational data tables and additional tables documenting database metadata and a traits dictionary.\n\naustraits\n\n\n\n\n── This is 6.0.0 of AusTraits: a curated plant trait database for the Australian\n\n\nℹ This database is built using traits.build version 1.1.0.9000\n\n\nℹ This database contains a total of 1726024 records, for 33494 taxa and 497\n  traits.\n\n\n\n\n\n── This object is a 'list' with the following components: ──\n\n\n\n\n\n• traits: A table containing measurements of traits.\n\n\n• locations: A table containing observations of location/site characteristics\nassociated with information in `traits`. Cross referencing between the two\ndataframes is possible using combinations of the variables `dataset_id`,\n`location_name`.\n\n\n• contexts: A table containing observations of contextual characteristics\nassociated with information in `traits`. Cross referencing between the two\ndataframes is possible using combinations of the variables `dataset_id`,\n`link_id`, and `link_vals`.\n\n\n• methods: A table containing details on methods with which data were\ncollected, including time frame and source. Cross referencing with the `traits`\ntable is possible using combinations of the variables `dataset_id`,\n`trait_name`.\n\n\n• excluded_data: A table of data that did not pass quality test and so were\nexcluded from the master dataset.\n\n\n• taxonomic_updates: A table of all taxonomic changes implemented in the\nconstruction of AusTraits. Changes are determined by comapring against the APC\n(Australian Plant Census) and APNI (Australian Plant Names Index).\n\n\n• taxa: A table containing details on taxa associated with information in\n`traits`. This information has been sourced from the APC (Australian Plant\nCensus) and APNI (Australian Plant Names Index) and is released under a CC-BY3\nlicense.\n\n\n• contributors: A table of people contributing to each study.\n\n\n• sources: Bibtex entries for all primary and secondary sources in the\ncompilation.\n\n\n• definitions: A copy of the definitions for all tables and terms. Information\nincluded here was used to process data and generate any documentation for the\nstudy.\n\n\n• schema: A copy of the schema for all tables and terms. Information included\nhere was used to process data and generate any documentation for the study.\n\n\n• metadata: Metadata associated with the dataset, including title, creators,\nlicense, subject, funding sources.\n\n\n• build_info: A description of the computing environment used to create this\nversion of the dataset, including version number, git commit and R\nsession_info.\n\n\nℹ To access a component, try using the $ e.g. austraits$traits\n\n\n\nTraits table\nThe core AusTraits table is the traits table. It is in “long” format, with each row documenting a single trait measurement.\n\naustraits$traits %&gt;% dplyr::slice(1:20)\n\n# A tibble: 20 × 26\n   dataset_id taxon_name       observation_id trait_name value unit  entity_type\n   &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n 1 ABRS_1981  Acanthocarpus c… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n 2 ABRS_1981  Acanthocarpus c… 0001           seed_leng… 3     mm    species    \n 3 ABRS_1981  Acanthocarpus h… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n 4 ABRS_1981  Acanthocarpus p… 0003           leaf_comp… simp… &lt;NA&gt;  species    \n 5 ABRS_1981  Acanthocarpus p… 0004           leaf_comp… simp… &lt;NA&gt;  species    \n 6 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 4     mm    species    \n 7 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 5     mm    species    \n 8 ABRS_1981  Acanthocarpus r… 0005           leaf_comp… simp… &lt;NA&gt;  species    \n 9 ABRS_1981  Acanthocarpus r… 0006           leaf_comp… simp… &lt;NA&gt;  species    \n10 ABRS_1981  Acanthocarpus r… 0006           seed_leng… 2.5   mm    species    \n11 ABRS_1981  Acanthocarpus v… 0007           leaf_comp… simp… &lt;NA&gt;  species    \n12 ABRS_1981  Acer pseudoplat… 0008           leaf_phen… deci… &lt;NA&gt;  species    \n13 ABRS_1981  Acidonia microc… 0009           leaf_comp… comp… &lt;NA&gt;  species    \n14 ABRS_1981  Callitris acumi… 0010           leaf_comp… simp… &lt;NA&gt;  species    \n15 ABRS_1981  Callitris arena… 0011           leaf_comp… simp… &lt;NA&gt;  species    \n16 ABRS_1981  Callitris pyram… 0012           leaf_comp… simp… &lt;NA&gt;  species    \n17 ABRS_1981  Adenanthos acan… 0013           leaf_comp… simp… &lt;NA&gt;  species    \n18 ABRS_1981  Adenanthos apic… 0014           leaf_comp… simp… &lt;NA&gt;  species    \n19 ABRS_1981  Adenanthos apic… 0014           leaf_leng… 5     mm    species    \n20 ABRS_1981  Adenanthos apic… 0014           leaf_leng… 20    mm    species    \n# ℹ 19 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;,\n#   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;\n\n\nThe columns include:\n\ncore columns\n\n\ndataset_id\n\ntaxon_name\n\ntrait_name\n\nvalue (trait value)\n\n\nentity metadata\n\nentity_type\n\nlife_stage\n\nvalue metadata\n\nvalue_type\n\nunit\n\nbasis_of_value\n\nreplicate\n\nbasis_of_record\n\n\nadditional metadata\n\ncollection_date\nmeasurement_remarks\n\nidentifiers for specific observations, individuals, etc.\n\nobservation_id\n\nindividual_id\n\npopulation_id\n\nrepeat_measurements_id\n\n\nidentifiers that provide links to ancillary tables with additional metadata\n\nlocation_id\n\ntreatment_context_id\n\nplot_context_id\n\nentity_context_id\n\ntemporal_context_id\n\nmethod_context_id\n\nmethod_id\n\nsource_id\n\n\n\n\nAncillary data tables\nThe remaining metadata accompanying each trait record is recorded across multiple relational tables.\nThese include: \n\naustraits$locations \naustraits$contexts \naustraits$methods \naustraits$taxa \naustraits$taxonomic_updates \naustraits$contributors \n\nLike the core traits table, each is in ‘long’ format.\nThe tables locations, contexts, methods, taxa and taxonomic_updates include metadata that links seamlessly to individual rows within traits.\nA collection of join_ functions within austraits join the ancillary tables to the traits table, based on columns shared across tables.\n\n\n\n\n\n\n\n\ntable\nmetadata in table\ncolumns that link to austraits$traits\n\n\n\n\nlocations\nlocation name, location properties, latitude, longitude\ndataset_id, location_id\n\n\ncontexts\ncontext name, context category (method context, temporal, entity context, plot, treatment), context property\ndataset_id, link_id (identifier to link to: method_context_id, temporal_context_id, entity_context_id, plot_context_id, treatment_context_id), link_vals (identifier value to link to)\n\n\nmethods\ndataset description, dataset sampling strategy, trait collection method, data collectors, data curators, dataset citation, source_id & citation\ndataset_id, trait_name, method_id\n\n\ntaxa\ngenus, family, scientific name, APC/APNI taxon concept/taxon name identifiers\ntaxon_name\n\n\ntaxonomic_updates\noriginal name (name submitted), aligned name (typos removed; standardised syntax), identifiers for aligned name\ndataset_id, taxon_name, original_name\n\n\ncontributors\npeople who contributed data, including their ORCIDs, affiliations, roles\ndataset_id",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>AusTraits tutorial</span>"
    ]
  },
  {
    "objectID": "AusTraits_tutorial.html#exploring-austraits",
    "href": "AusTraits_tutorial.html#exploring-austraits",
    "title": "30  AusTraits tutorial",
    "section": "30.5 Exploring AusTraits",
    "text": "30.5 Exploring AusTraits\nWith 1726024 rows of trait values in the main traits table, knowing how to explore the contents is essential.\nThe R package {austraits} offers a collection of functions to explore and wrangle AusTraits data – or indeed any data using the traits.build format.\nAn austraits package vignette is available here.\nFunction categories include:\n\nsummarise and lookup functions: These functions offer summaries by taxon name or trait, summarising taxa per trait (or other variable), datasets per trait, and observations per trait.\nfiltering functions: These functions begin with the word extract and filter all of the relational tables simultaneously.\njoin functions: These functions allow columns from the relational tables to be joined to the core traits table.\npivot functions: These functions allow the traits table to be pivoted to wide format.\nplotting functions: These functions offer a means of rapidly visualising AusTraits data, either plotting collection locations on a map of Australia or plotting trait values by dataset.\n\n\naustraits.R function reference\nReference guide to: austraits functions\n\n\nSummarising data: data coverage\nThere are two function families for summarising AusTraits data:\n\nlookup_()\n\nsummarise_database()\n\nUse the function summarise_database to output summaries of total records, datasets with records, and taxa with records across families, genera or traits:\n\naustraits::summarise_database(database = austraits, var = \"trait_name\") %&gt;% dplyr::slice(100:130)\n\n# A tibble: 31 × 5\n   trait_name                      n_records n_dataset n_taxa percent_total\n   &lt;chr&gt;                               &lt;int&gt;     &lt;int&gt;  &lt;int&gt;         &lt;dbl&gt;\n 1 flower_pollen_length                  701         1    333     0.000406 \n 2 flower_structural_carpels_count      1411         2   1003     0.000817 \n 3 flower_structural_sex_type           1982         2   1675     0.00115  \n 4 flower_style_differentiation         1656         2   1547     0.000959 \n 5 flower_style_fusion                   319         2    267     0.000185 \n 6 flowering_cues                        278         1    244     0.000161 \n 7 flowering_time                      33685        36  18710     0.0195   \n 8 fruit_Ca_per_dry_mass                  27         4     21     0.0000156\n 9 fruit_K_per_dry_mass                   27         4     21     0.0000156\n10 fruit_Mg_per_dry_mass                  27         4     21     0.0000156\n# ℹ 21 more rows\n\naustraits::summarise_database(database = austraits, var = \"family\") %&gt;% dplyr::slice(1:20)\n\n# A tibble: 20 × 5\n   family           n_records n_dataset n_taxa percent_total\n   &lt;chr&gt;                &lt;int&gt;     &lt;int&gt;  &lt;int&gt;         &lt;dbl&gt;\n 1 Acanthaceae           3719        57    149     0.00216  \n 2 Achariaceae            162        14      3     0.0000939\n 3 Actinidiaceae          186        16      3     0.000108 \n 4 Agapanthaceae          107        13      3     0.000062 \n 5 Aizoaceae             5004        63    102     0.0029   \n 6 Akaniaceae             123        16      1     0.0000713\n 7 Alismataceae           892        30     20     0.000517 \n 8 Alliaceae              561        19     18     0.000325 \n 9 Alseuosmiaceae         318        13      3     0.000184 \n10 Alstroemeriaceae       175        15      2     0.000101 \n11 Amaranthaceae         9873        85    267     0.00572  \n12 Amaryllidaceae        1400        38     56     0.000812 \n13 Anacardiaceae         2214        64     26     0.00128  \n14 Anarthriaceae          779        32     20     0.000452 \n15 Annonaceae            4172        50     62     0.00242  \n16 Aphanopetalaceae       193        23      3     0.000112 \n17 Apiaceae             12759        94    195     0.0074   \n18 Apocynaceae          16341       111    238     0.00947  \n19 Apodanthaceae           75        11      4     0.0000435\n20 Aponogetonaceae        493        19     14     0.000286 \n\naustraits::summarise_database(database = austraits, var = \"genus\") %&gt;% dplyr::slice(1:20)\n\n# A tibble: 20 × 5\n   genus          n_records n_dataset n_taxa percent_total\n   &lt;chr&gt;              &lt;int&gt;     &lt;int&gt;  &lt;int&gt;         &lt;dbl&gt;\n 1 (Dockrillia            3         2      1    0.00000174\n 2 Abelia                16         4      1    0.00000928\n 3 Abelmoschus          271        19      8    0.000157  \n 4 Abildgaardia          74         7      2    0.0000429 \n 5 Abrodictyum          123        14      3    0.0000713 \n 6 Abroma                39         7      2    0.0000226 \n 7 Abrophyllum          181        19      3    0.000105  \n 8 Abrotanella          183        18      4    0.000106  \n 9 Abrus                202        26      3    0.000117  \n10 Abutilon            1975        52     54    0.00115   \n11 Acacia            109792       191   1558    0.0637    \n12 Acaciella             66         5      3    0.0000383 \n13 Acaena              1150        44     14    0.000667  \n14 Acalypha             561        20     14    0.000325  \n15 Acanthocarpus        986        22      9    0.000572  \n16 Acanthocereus         22         4      1    0.0000128 \n17 Acanthocladium        48        12      1    0.0000278 \n18 Acanthospermum       117        16      2    0.0000679 \n19 Acanthus             209        19      4    0.000121  \n20 Acer                 221        14      4    0.000128  \n\n\nSince this function summarises the variable selected for ALL of AusTraits, you may want to first filter the data before summarising by “taxon_name” – or even “trait_name”.\nAlternatively, you can look up traits that contain a specific search term:\n\naustraits::lookup_trait(database = austraits, term = \"leaf\") %&gt;% length()\n\n[1] 213\n\naustraits::lookup_trait(database = austraits, term = \"leaf\")[1:30]\n\n [1] \"leaf_compoundness\"                   \n [2] \"leaf_phenology\"                      \n [3] \"leaf_length\"                         \n [4] \"leaf_width\"                          \n [5] \"leaf_margin\"                         \n [6] \"leaf_shape\"                          \n [7] \"leaf_lamina_posture\"                 \n [8] \"leaf_base_shape\"                     \n [9] \"leaf_lobation\"                       \n[10] \"leaf_phyllotaxis\"                    \n[11] \"leaf_glaucousness\"                   \n[12] \"leaf_arrangement\"                    \n[13] \"leaf_margin_posture\"                 \n[14] \"leaf_pendulousness\"                  \n[15] \"leaf_N_per_dry_mass\"                 \n[16] \"leaf_area\"                           \n[17] \"leaf_delta13C\"                       \n[18] \"leaf_mass_per_area\"                  \n[19] \"leaf_photochemical_reflectance_index\"\n[20] \"leaf_water_band_index\"               \n[21] \"leaf_dry_matter_content\"             \n[22] \"leaf_thickness\"                      \n[23] \"leaf_water_use_efficiency_intrinsic\" \n[24] \"leaf_hairs_adult_leaves\"             \n[25] \"leaf_hydraulic_vulnerability\"        \n[26] \"leaf_specific_hydraulic_conductance\" \n[27] \"leaf_turgor_loss_point\"              \n[28] \"leaf_NP_ratio\"                       \n[29] \"leaf_N_per_area\"                     \n[30] \"leaf_P_per_area\"                     \n\naustraits::lookup_trait(database = austraits, term = \"_N_\") \n\n [1] \"leaf_N_per_dry_mass\"                    \n [2] \"leaf_N_per_area\"                        \n [3] \"wood_N_per_dry_mass\"                    \n [4] \"leaf_senesced_N_per_dry_mass\"           \n [5] \"bark_N_per_dry_mass\"                    \n [6] \"fruit_N_per_dry_mass\"                   \n [7] \"seed_N_per_seed_dry_mass\"               \n [8] \"stem_N_per_dry_mass\"                    \n [9] \"wood_dead_N_per_dry_mass\"               \n[10] \"flower_N_per_dry_mass\"                  \n[11] \"leaf_N_resorption\"                      \n[12] \"leaf_cell_wall_N_per_cell_wall_dry_mass\"\n[13] \"leaf_cell_wall_N_per_leaf_N\"            \n[14] \"root_N_per_dry_mass\"                    \n[15] \"leaf_rubisco_N_per_total_leaf_N\"        \n[16] \"leaf_thylakoid_N_per_total_leaf_N\"      \n\n # elemental contents use their symbol and are *almost* always in the middle of a trait name\naustraits::lookup_trait(database = austraits, term = \"photo\")\n\n [1] \"plant_photosynthetic_organ\"                             \n [2] \"leaf_photochemical_reflectance_index\"                   \n [3] \"leaf_photosynthetic_nitrogen_use_efficiency_saturated\"  \n [4] \"leaf_photosynthetic_phosphorus_use_efficiency_saturated\"\n [5] \"leaf_photosynthetic_rate_per_area_maximum\"              \n [6] \"leaf_photosynthetic_rate_per_area_saturated\"            \n [7] \"leaf_photosynthetic_rate_per_dry_mass_maximum\"          \n [8] \"leaf_photosynthetic_rate_per_dry_mass_saturated\"        \n [9] \"leaf_photosynthesis_Jmax_per_area_25C\"                  \n[10] \"leaf_photosynthesis_Vcmax_per_area\"                     \n[11] \"leaf_photosynthesis_Jmax_per_area\"                      \n[12] \"leaf_photosynthetic_rate_per_area_ambient\"              \n[13] \"photosynthetic_pathway\"                                 \n[14] \"leaf_photosynthesis_Jmax_per_mass\"                      \n[15] \"leaf_photosynthesis_Vcmax_per_mass\"                     \n[16] \"leaf_photosynthetic_nitrogen_use_efficiency_maximum\"    \n[17] \"leaf_photosynthetic_phosphorus_use_efficiency_maximum\"  \n[18] \"leaf_photosynthesis_Jmax_over_Vcmax_25C\"                \n[19] \"leaf_photosynthesis_Vcmax_per_area_25C\"                 \n[20] \"bark_photosynthetic_status\"                             \n\n\nAlso visit the AusTraits Plant Dictionary to learn more about the traits included in AusTraits, https://w3id.org/APD.\nYou can also search the locations and contexts tables for location_properties and/or context_properties included as metadata for many trait measurements:\n\naustraits::lookup_location_property(database = austraits, term = \"soil\")\n\n [1] \"soil type\"                               \n [2] \"soil P, total (mg/kg)\"                   \n [3] \"soil pH (H2O)\"                           \n [4] \"soil P, SE total (mg/kg)\"                \n [5] \"soil clay (%)\"                           \n [6] \"soil sand (%)\"                           \n [7] \"soil silt (%)\"                           \n [8] \"soil P, extractable (mg/kg)\"             \n [9] \"soil exchangeable Al (mg/kg)\"            \n[10] \"soil exchangeable Fe (mg/kg)\"            \n[11] \"soil organic carbon (%)\"                 \n[12] \"soil pH (CaCl2)\"                         \n[13] \"soil carbonates content (%)\"             \n[14] \"soil cation exchange capacity (cmol/kg)\" \n[15] \"soil K (mg/kg)\"                          \n[16] \"soil N, total (%)\"                       \n[17] \"soil P, total\"                           \n[18] \"soil pH\"                                 \n[19] \"soil P, description\"                     \n[20] \"soil N, total (ppm)\"                     \n[21] \"soil N, total (g/100g)\"                  \n[22] \"soil bulk density (g/cm3)\"               \n[23] \"soil cation exchange capacity (meq/kg)\"  \n[24] \"soil conductivity (dS/m)\"                \n[25] \"soil depth to gravel or laterite (m)\"    \n[26] \"soil pH, 1-10 cm\"                        \n[27] \"soil texture\"                            \n[28] \"soil water holding capacity (v/v)\"       \n[29] \"soil C, total (%)\"                       \n[30] \"soil nutrient summary\"                   \n[31] \"soil\"                                    \n[32] \"soil Al (mg/kg)\"                         \n[33] \"soil Ca (mg/kg)\"                         \n[34] \"soil P, available (ppm)\"                 \n[35] \"incubated soil NH4 content (mg/kg)\"      \n[36] \"soil N:P\"                                \n[37] \"soil NH4 content (mg/kg)\"                \n[38] \"soil NO3 content\"                        \n[39] \"soil TEB (cmol/kg)\"                      \n[40] \"soil age\"                                \n[41] \"soil disolved organic nitrogen\"          \n[42] \"soil exchangeable Al (cmol/kg)\"          \n[43] \"soil exchangeable Ca (cmol/kg, meq/100g)\"\n[44] \"soil exchangeable Ca (mg/kg)\"            \n[45] \"soil exchangeable Fe (cmol/kg, meq/100g)\"\n[46] \"soil exchangeable K (cmol/kg, meq/100g)\" \n[47] \"soil exchangeable K (mg/kg)\"             \n[48] \"soil exchangeable Mg (cmol/kg, meq/100g)\"\n[49] \"soil exchangeable Mg (mg/kg)\"            \n[50] \"soil exchangeable Mn (cmol/kg, meq/100g)\"\n[51] \"soil exchangeable Mn (mg/kg)\"            \n[52] \"soil exchangeable Na (cmol/kg, meq/100g)\"\n[53] \"soil exchangeable Na (mg/kg)\"            \n[54] \"soil Ca (cmol/kg)\"                       \n[55] \"soil Fe (mg/kg)\"                         \n[56] \"soil Mg (mg/kg)\"                         \n[57] \"soil Mn (mg/kg)\"                         \n[58] \"soil P, Olsen (mg/kg)\"                   \n[59] \"soil P, Resin (mg/kg)\"                   \n[60] \"soil organic content (%)\"                \n[61] \"soil organic matter (%)\"                 \n[62] \"soil N, total (mg/g)\"                    \n[63] \"soil temperature (C)\"                    \n[64] \"soil nutrient status\"                    \n[65] \"soil P, total ICP\"                       \n[66] \"soil N, Kjeldahl (mg/kg)\"                \n[67] \"soil N, oxidised (mg/kg)\"                \n[68] \"soil water content (%)\"                  \n[69] \"soil series\"                             \n[70] \"soil K\"                                  \n[71] \"soil depth class\"                        \n[72] \"soil morphology\"                         \n[73] \"soil profile description\"                \n[74] \"soil texture (subsoil)\"                  \n[75] \"soil texture (surface)\"                  \n[76] \"soil C:N\"                                \n[77] \"soil C:P\"                                \n[78] \"soil notes\"                              \n\naustraits::lookup_location_property(database = austraits, term = \"temperature\")\n\n [1] \"temperature, max (C)\"             \"temperature, MAT (C)\"            \n [3] \"temperature, mean summer max (C)\" \"temperature, mean winter max (C)\"\n [5] \"temperature, max MAT (C)\"         \"temperature, min MAT (C)\"        \n [7] \"temperature, mean winter min (C)\" \"temperature variation (C)\"       \n [9] \"temperature, monthly max (C)\"     \"temperature, monthly min (C)\"    \n[11] \"soil temperature (C)\"             \"temperature, mean daily max (C)\" \n[13] \"temperature, mean daily min (C)\"  \"temperature, mean yearly max (C)\"\n[15] \"temperature, summer mean (C)\"     \"temperature, winter mean (C)\"    \n\naustraits::lookup_context_property(database = austraits, term = \"season\")\n\n[1] \"sampling season\" \"fire season\"    \n\naustraits::lookup_context_property(database = austraits, term = \"fire\")\n\n[1] \"fire intensity\"     \"fire history\"       \"fire response type\"\n[4] \"fire severity\"      \"fire season\"       \n\n\nFor instance, to just look at number of records, datasets, and taxa with data for nitrogen-related traits:\n\nN_traits &lt;- austraits %&gt;% \n  austraits::extract_trait(trait_name = \"_N_\") %&gt;%\n  austraits::summarise_database(var = \"trait_name\")",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>AusTraits tutorial</span>"
    ]
  },
  {
    "objectID": "AusTraits_tutorial.html#wrangling-austraits",
    "href": "AusTraits_tutorial.html#wrangling-austraits",
    "title": "30  AusTraits tutorial",
    "section": "30.6 Wrangling AusTraits",
    "text": "30.6 Wrangling AusTraits\n\nFiltering data\nThere are four austraits functions that filter data: extract_trait, extract_taxon or extract_dataset_id, and extract_data.\nEach of these functions simultaneously filters all database tables to only include trait measurements (and associated metadata) meeting the specified criteria, retaining the original database structure.\nNote, although the extract_ functions were explicitly developed to return the original traits.build database structure, they will also work when the “database” is just a single table, such as if prior manipulations have separated the traits table from the rest of the database.\n\nextract_trait, extract_dataset and extract_taxa\nThree of the functions extract data based on pre-set columns: 1. extract_trait filters by trait_name 2. extract_dataset filters by dataset_id 3. extract_taxa filters by taxon_name, genus or family\nSearch terms can either be exact or partial matches.\n\nleaf_mass_per_area_data &lt;-\n  austraits %&gt;% \n     austraits::extract_trait(trait_names = c(\"leaf_mass_per_area\"))\n\nWestoby_2014_datasets &lt;-\n  austraits %&gt;%\n     austraits::extract_dataset(\"Westoby_2014\")\n\nall_Westoby_datasets &lt;-\n  austraits %&gt;%\n     austraits::extract_dataset(\"Westoby\")\n\nEucalyptus_data &lt;-\n  austraits %&gt;%\n     austraits::extract_taxa(genus = \"Eucalyptus\")\n\nBanksia_serrata_data &lt;-\n  austraits %&gt;%\n     austraits::extract_taxa(taxon_name = \"Banksia serrata\")\n\n\n\nextract_data\nextract_data offers the ability of filtering the database based on a value(s) in any column of any of the seven data tables (traits, locations, contexts, methods, taxa, taxonomic_updates, contributors).\nSee the database structure chapter for names and definitions of each column and, for those with controlled vocabulary, their allowed values.\nAlternatively to see the list of column names to use:\n\nnames(austraits$traits)\n\n [1] \"dataset_id\"             \"taxon_name\"             \"observation_id\"        \n [4] \"trait_name\"             \"value\"                  \"unit\"                  \n [7] \"entity_type\"            \"value_type\"             \"basis_of_value\"        \n[10] \"replicates\"             \"basis_of_record\"        \"life_stage\"            \n[13] \"population_id\"          \"individual_id\"          \"repeat_measurements_id\"\n[16] \"temporal_context_id\"    \"source_id\"              \"location_id\"           \n[19] \"entity_context_id\"      \"plot_context_id\"        \"treatment_context_id\"  \n[22] \"collection_date\"        \"measurement_remarks\"    \"method_id\"             \n[25] \"method_context_id\"      \"original_name\"         \n\nnames(austraits$methods)\n\n [1] \"dataset_id\"                       \"trait_name\"                      \n [3] \"methods\"                          \"method_id\"                       \n [5] \"description\"                      \"sampling_strategy\"               \n [7] \"source_primary_key\"               \"source_primary_citation\"         \n [9] \"source_secondary_key\"             \"source_secondary_citation\"       \n[11] \"source_original_dataset_key\"      \"source_original_dataset_citation\"\n[13] \"data_collectors\"                  \"assistants\"                      \n[15] \"dataset_curators\"                \n\n\nAnd to see the list of possible values for a column:\n\nunique(austraits$traits$life_stage)\n\n [1] \"adult\"                     \"sapling\"                  \n [3] \"seedling\"                  \"adults\"                   \n [5] \"adult, seedling\"           \"unknown\"                  \n [7] \"seedling, adult\"           \"saplings\"                 \n [9] \"seedling sapling adult\"    \"juvenile\"                 \n[11] \"adult juvenile\"            NA                         \n[13] \"adult, sapling [by trait]\"\n\nunique(austraits$traits$basis_of_record)\n\n [1] \"preserved_specimen\"                \"field_experiment\"                 \n [3] \"field\"                             \"lab\"                              \n [5] \"field field_experiment\"            \"literature field\"                 \n [7] \"literature\"                        \"unknown\"                          \n [9] \"captive_cultivated\"                \"literature field field_experiment\"\n[11] \"field lab\"                         \"field preserved_specimen\"         \n[13] NA                                  \"field captive_cultivated\"         \n\nunique(austraits$locations$location_property)[1:20]\n\n [1] \"latitude (deg)\"                   \"longitude (deg)\"                 \n [3] \"aridity index (MAP/PET)\"          \"precipitation, MAP (mm)\"         \n [5] \"temperature, max (C)\"             \"locality\"                        \n [7] \"recorded by\"                      \"description\"                     \n [9] \"notes\"                            \"soil type\"                       \n[11] \"temperature, MAT (C)\"             \"population\"                      \n[13] \"elevation (m)\"                    \"biome\"                           \n[15] \"crown height, max (m)\"            \"leaf area index\"                 \n[17] \"soil P, total (mg/kg)\"            \"climate description\"             \n[19] \"temperature, mean summer max (C)\" \"temperature, mean winter max (C)\"\n\nunique(austraits$contexts$context_property)[1:20]\n\n [1] \"trait scoring method\"       \"entity_measured\"           \n [3] \"replicate observations\"     \"entity measured\"           \n [5] \"sampling season\"            \"measurement CO2\"           \n [7] \"seed provenance\"            \"measurement irradiance\"    \n [9] \"repeat observations\"        \"habitat flammability\"      \n[11] \"time to flowering type\"     \"fire intensity\"            \n[13] \"groundwater requirement\"    \"slope position\"            \n[15] \"plot elevation (m)\"         \"inundation duration (days)\"\n[17] \"fire history\"               \"canopy layer\"              \n[19] \"drought treatment\"          \"sampling time of day\"      \n\n\nThe function then allows you to filter down to the components of each table that are relevant to the search criteria specified:\n\nfield_data &lt;- austraits %&gt;% austraits::extract_data(table = \"traits\", col = \"basis_of_record\", col_value = \"field\")\n\nfield_data$traits %&gt;% head()\n\n# A tibble: 6 × 26\n  dataset_id  taxon_name       observation_id trait_name value unit  entity_type\n  &lt;chr&gt;       &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n1 Ahrens_2019 Corymbia caloph… 001            leaf_N_pe… 9     mg/g  individual \n2 Ahrens_2019 Corymbia caloph… 001            leaf_area  1288… mm2   individual \n3 Ahrens_2019 Corymbia caloph… 001            leaf_delt… -27.… {del… individual \n4 Ahrens_2019 Corymbia caloph… 001            leaf_mass… 185.… g/m2  individual \n5 Ahrens_2019 Corymbia caloph… 001            leaf_phot… 0.02… {dim… individual \n6 Ahrens_2019 Corymbia caloph… 001            leaf_wate… 1.06… {dim… individual \n# ℹ 19 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;,\n#   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;\n\ndata_with_soils_data &lt;- austraits %&gt;% austraits::extract_data(table = \"locations\", col = \"location_property\", col_value = \"soil\")\n\ndata_with_soils_data$traits %&gt;% head()\n\n# A tibble: 6 × 26\n  dataset_id  taxon_name       observation_id trait_name value unit  entity_type\n  &lt;chr&gt;       &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n1 Apgaua_2017 Aglaia meridion… 001            leaf_delt… -34.… {del… individual \n2 Apgaua_2017 Aglaia meridion… 001            leaf_wate… 0.02… umol… individual \n3 Apgaua_2017 Aglaia meridion… 001            sapwood_s… 14.6… kg/m… individual \n4 Apgaua_2017 Aglaia meridion… 001            stem_vess… 71.0… {cou… individual \n5 Apgaua_2017 Aglaia meridion… 001            stem_vess… 53.9… um    individual \n6 Apgaua_2017 Aglaia meridion… 001            stem_vess… 82.5… um    individual \n# ℹ 19 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;,\n#   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;\n\ndata_with_soils_data$locations %&gt;% head() # all location properties are retained for the measurements for measurements for which at least location property pertains to soil\n\n# A tibble: 6 × 5\n  dataset_id  location_id location_name                  location_property value\n  &lt;chr&gt;       &lt;chr&gt;       &lt;chr&gt;                          &lt;chr&gt;             &lt;chr&gt;\n1 Apgaua_2017 01          Daintree Rainforest Observato… description       lowl…\n2 Apgaua_2017 01          Daintree Rainforest Observato… latitude (deg)    -16.…\n3 Apgaua_2017 01          Daintree Rainforest Observato… longitude (deg)   145.…\n4 Apgaua_2017 01          Daintree Rainforest Observato… precipitation, M… 4900 \n5 Apgaua_2017 01          Daintree Rainforest Observato… soil type         high…\n6 Apgaua_2017 01          Daintree Rainforest Observato… temperature, MAT… 24.4 \n\ndata_contributed_by_Wright &lt;- austraits %&gt;% austraits::extract_data(table = \"contributors\", col = \"last_name\", col_value = \"Wright\")\n\ndata_contributed_by_Wright$traits %&gt;% head()\n\n# A tibble: 6 × 26\n  dataset_id     taxon_name    observation_id trait_name value unit  entity_type\n  &lt;chr&gt;          &lt;chr&gt;         &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n1 Gallagher_2018 Acacia myrti… 001            leaf_area  199.5 mm2   individual \n2 Gallagher_2018 Acacia myrti… 001            leaf_dry_… 27.51 mg    individual \n3 Gallagher_2018 Acacia myrti… 001            leaf_mass… 137.… g/m2  individual \n4 Gallagher_2018 Acacia myrti… 002            leaf_area  314.… mm2   individual \n5 Gallagher_2018 Acacia myrti… 002            leaf_dry_… 39.4  mg    individual \n6 Gallagher_2018 Acacia myrti… 002            leaf_mass… 125.… g/m2  individual \n# ℹ 19 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;,\n#   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;\n\ndata_contributed_by_Wright$contributors %&gt;% head() # all contributors are retained for datasets where at least one of the contributors on the dataset has the last name \"Wright\"\n\n# A tibble: 6 × 6\n  dataset_id     last_name         given_name ORCID  affiliation additional_role\n  &lt;chr&gt;          &lt;chr&gt;             &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;       &lt;chr&gt;          \n1 Gallagher_2018 Gallagher         Rachael    0000-… Hawkesbury… contact        \n2 Gallagher_2018 Laugier-Kitchener Bree-Anne  0000-… Department… &lt;NA&gt;           \n3 Gallagher_2018 McPherson         Hannah     0000-… National H… &lt;NA&gt;           \n4 Gallagher_2018 Rossetto          Maurizio   0000-… National H… &lt;NA&gt;           \n5 Gallagher_2018 van der Merwe     Marlien    0000-… Research C… &lt;NA&gt;           \n6 Gallagher_2018 Wright            Ian        0000-… Hawkesbury… &lt;NA&gt;           \n\n\nMultiple extract_’s can be linked together to rapidly restrict data to the subset desired:\n\nsubset &lt;- austraits %&gt;%\n  austraits::extract_data(table = \"traits\", col = \"basis_of_record\", col_value = \"field\") %&gt;%\n  austraits::extract_trait(trait_name = c(\"leaf_mass_per_area\", \"leaf_thickness\", \"leaf_length\", \"leaf_area\")) %&gt;%\n  austraits::extract_taxa(genus = \"Eucalyptus\")\n\nsubset$traits[1:20]\n\n# A tibble: 10,067 × 20\n   dataset_id      taxon_name  observation_id trait_name value unit  entity_type\n   &lt;chr&gt;           &lt;chr&gt;       &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n 1 Atkinson_2020_2 Eucalyptus… 35             leaf_area  4065  mm2   individual \n 2 Atkinson_2020_2 Eucalyptus… 35             leaf_mass… 189.… g/m2  individual \n 3 Atkinson_2020_2 Eucalyptus… 36             leaf_area  4012… mm2   individual \n 4 Atkinson_2020_2 Eucalyptus… 36             leaf_mass… 172.… g/m2  individual \n 5 Atkinson_2020_2 Eucalyptus… 37             leaf_area  2561… mm2   individual \n 6 Atkinson_2020_2 Eucalyptus… 37             leaf_mass… 138.… g/m2  individual \n 7 Atkinson_2020_2 Eucalyptus… 38             leaf_area  2617… mm2   individual \n 8 Atkinson_2020_2 Eucalyptus… 38             leaf_mass… 141.… g/m2  individual \n 9 Atkinson_2020_2 Eucalyptus… 39             leaf_area  4364  mm2   individual \n10 Atkinson_2020_2 Eucalyptus… 39             leaf_mass… 172.… g/m2  individual \n# ℹ 10,057 more rows\n# ℹ 13 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;\n\n\n\n\n\nJoining relational tables\nFor many research purposes you will want to join metadata from one of the relational tables to the core traits table. There are eight {austraits} functions that facilitate this by adding the columns you select from the ancillary data tables to the database’s traits table, seven functions that merge information from a single table (join_...) and a function that joins columns from all seven ancillary data tables (flatten_database). All functions output the database with the original database structure allowing you to follow up joining with extracting and to continue joining additional columns.\n\nJoining location metadata\nThe locations table includes information on all location properties measured, including the actual location (latitude/longitude), climatic data, soil properties, fire history, vegetation history, geologic history, etc.\nThe austraits function join_location_coordinates just adds location name, latitude, and longitude to the core traits table:\n\ntraits_with_lat_long &lt;- austraits %&gt;% \n  austraits::extract_dataset(dataset_id = \"Westoby\") %&gt;%\n  austraits::join_location_coordinates()\n\ntraits_with_lat_long$traits %&gt;% names()\n\n [1] \"dataset_id\"             \"taxon_name\"             \"observation_id\"        \n [4] \"trait_name\"             \"value\"                  \"unit\"                  \n [7] \"entity_type\"            \"value_type\"             \"basis_of_value\"        \n[10] \"replicates\"             \"basis_of_record\"        \"life_stage\"            \n[13] \"population_id\"          \"individual_id\"          \"repeat_measurements_id\"\n[16] \"temporal_context_id\"    \"source_id\"              \"location_id\"           \n[19] \"entity_context_id\"      \"plot_context_id\"        \"treatment_context_id\"  \n[22] \"collection_date\"        \"measurement_remarks\"    \"method_id\"             \n[25] \"method_context_id\"      \"original_name\"          \"location_name\"         \n[28] \"latitude (deg)\"         \"longitude (deg)\"       \n\n\nThe function join_location_properties joins other location properties to the traits table. It has two arguments:\n\nvars, specifies the location properties, via complete or partial string matches, that should be added to the traits table; defaults to “all”\nformat offers three output formats:\n\n*   `many_columns` (each location property is added as a separate column)  \n*   `single_column_pretty` (all location properties compacted into a single column delimited in a way that is easy for humans to read; this is the default)\n*   `single_column_json` (all location properties compacted into a single column, using json formatting)  \nExamples of joining location properties to the traits table:\n\n# method to add location properties that you know exist from previous database exploration; this example showcases `format = \"many_columns\"\nlocations1 &lt;- austraits %&gt;%\n  austraits::join_location_properties(vars = c(\"description\", \"aridity index (MAP/PET)\", \n                                         \"soil type\", \"fire history\"), format = \"many_columns\")\n\nlocations1$traits %&gt;% names()\n\n [1] \"dataset_id\"                                \n [2] \"taxon_name\"                                \n [3] \"observation_id\"                            \n [4] \"trait_name\"                                \n [5] \"value\"                                     \n [6] \"unit\"                                      \n [7] \"entity_type\"                               \n [8] \"value_type\"                                \n [9] \"basis_of_value\"                            \n[10] \"replicates\"                                \n[11] \"basis_of_record\"                           \n[12] \"life_stage\"                                \n[13] \"population_id\"                             \n[14] \"individual_id\"                             \n[15] \"repeat_measurements_id\"                    \n[16] \"temporal_context_id\"                       \n[17] \"source_id\"                                 \n[18] \"location_id\"                               \n[19] \"entity_context_id\"                         \n[20] \"plot_context_id\"                           \n[21] \"treatment_context_id\"                      \n[22] \"collection_date\"                           \n[23] \"measurement_remarks\"                       \n[24] \"method_id\"                                 \n[25] \"method_context_id\"                         \n[26] \"original_name\"                             \n[27] \"location_name\"                             \n[28] \"location_property: aridity index (MAP/PET)\"\n[29] \"location_property: description\"            \n[30] \"location_property: soil type\"              \n[31] \"location_property: fire history\"           \n\nlocations1$traits[1:10]\n\n# A tibble: 1,726,024 × 10\n   dataset_id taxon_name       observation_id trait_name value unit  entity_type\n   &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n 1 ABRS_1981  Acanthocarpus c… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n 2 ABRS_1981  Acanthocarpus c… 0001           seed_leng… 3     mm    species    \n 3 ABRS_1981  Acanthocarpus h… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n 4 ABRS_1981  Acanthocarpus p… 0003           leaf_comp… simp… &lt;NA&gt;  species    \n 5 ABRS_1981  Acanthocarpus p… 0004           leaf_comp… simp… &lt;NA&gt;  species    \n 6 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 4     mm    species    \n 7 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 5     mm    species    \n 8 ABRS_1981  Acanthocarpus r… 0005           leaf_comp… simp… &lt;NA&gt;  species    \n 9 ABRS_1981  Acanthocarpus r… 0006           leaf_comp… simp… &lt;NA&gt;  species    \n10 ABRS_1981  Acanthocarpus r… 0006           seed_leng… 2.5   mm    species    \n# ℹ 1,726,014 more rows\n# ℹ 3 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;, replicates &lt;chr&gt;\n\n# method where you first lookup location properties using the function `lookup_location_property`; this example showcases `format = \"single_column_pretty\"\nprecipitation_properties &lt;- lookup_location_property(database = austraits, term = \"precipitation\")\n\nlocations2 &lt;- austraits %&gt;%\n  austraits::join_location_properties(vars = precipitation_properties, format = \"single_column_pretty\")\n\nlocations2$traits %&gt;% names()\n\n [1] \"dataset_id\"             \"taxon_name\"             \"observation_id\"        \n [4] \"trait_name\"             \"value\"                  \"unit\"                  \n [7] \"entity_type\"            \"value_type\"             \"basis_of_value\"        \n[10] \"replicates\"             \"basis_of_record\"        \"life_stage\"            \n[13] \"population_id\"          \"individual_id\"          \"repeat_measurements_id\"\n[16] \"temporal_context_id\"    \"source_id\"              \"location_id\"           \n[19] \"entity_context_id\"      \"plot_context_id\"        \"treatment_context_id\"  \n[22] \"collection_date\"        \"measurement_remarks\"    \"method_id\"             \n[25] \"method_context_id\"      \"original_name\"          \"location_name\"         \n[28] \"location_properties\"   \n\nlocations2$traits[1:10]\n\n# A tibble: 1,726,024 × 10\n   dataset_id taxon_name       observation_id trait_name value unit  entity_type\n   &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n 1 ABRS_1981  Acanthocarpus c… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n 2 ABRS_1981  Acanthocarpus c… 0001           seed_leng… 3     mm    species    \n 3 ABRS_1981  Acanthocarpus h… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n 4 ABRS_1981  Acanthocarpus p… 0003           leaf_comp… simp… &lt;NA&gt;  species    \n 5 ABRS_1981  Acanthocarpus p… 0004           leaf_comp… simp… &lt;NA&gt;  species    \n 6 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 4     mm    species    \n 7 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 5     mm    species    \n 8 ABRS_1981  Acanthocarpus r… 0005           leaf_comp… simp… &lt;NA&gt;  species    \n 9 ABRS_1981  Acanthocarpus r… 0006           leaf_comp… simp… &lt;NA&gt;  species    \n10 ABRS_1981  Acanthocarpus r… 0006           seed_leng… 2.5   mm    species    \n# ℹ 1,726,014 more rows\n# ℹ 3 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;, replicates &lt;chr&gt;\n\n# method where you add all location properties; this example showcases `format = \"single_column_json\"\nlocations3 &lt;- austraits %&gt;%\n  austraits::join_location_properties(vars = \"all\", format = \"single_column_json\")\n\nlocations3$traits %&gt;% names()\n\n [1] \"dataset_id\"             \"taxon_name\"             \"observation_id\"        \n [4] \"trait_name\"             \"value\"                  \"unit\"                  \n [7] \"entity_type\"            \"value_type\"             \"basis_of_value\"        \n[10] \"replicates\"             \"basis_of_record\"        \"life_stage\"            \n[13] \"population_id\"          \"individual_id\"          \"repeat_measurements_id\"\n[16] \"temporal_context_id\"    \"source_id\"              \"location_id\"           \n[19] \"entity_context_id\"      \"plot_context_id\"        \"treatment_context_id\"  \n[22] \"collection_date\"        \"measurement_remarks\"    \"method_id\"             \n[25] \"method_context_id\"      \"original_name\"          \"location_name\"         \n[28] \"location_properties\"   \n\nlocations3$traits[1:10]\n\n# A tibble: 1,726,024 × 10\n   dataset_id taxon_name       observation_id trait_name value unit  entity_type\n   &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n 1 ABRS_1981  Acanthocarpus c… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n 2 ABRS_1981  Acanthocarpus c… 0001           seed_leng… 3     mm    species    \n 3 ABRS_1981  Acanthocarpus h… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n 4 ABRS_1981  Acanthocarpus p… 0003           leaf_comp… simp… &lt;NA&gt;  species    \n 5 ABRS_1981  Acanthocarpus p… 0004           leaf_comp… simp… &lt;NA&gt;  species    \n 6 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 4     mm    species    \n 7 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 5     mm    species    \n 8 ABRS_1981  Acanthocarpus r… 0005           leaf_comp… simp… &lt;NA&gt;  species    \n 9 ABRS_1981  Acanthocarpus r… 0006           leaf_comp… simp… &lt;NA&gt;  species    \n10 ABRS_1981  Acanthocarpus r… 0006           seed_leng… 2.5   mm    species    \n# ℹ 1,726,014 more rows\n# ℹ 3 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;, replicates &lt;chr&gt;\n\n\n\n\nJoining contexts metadata\nThe context table documents additional context properties/ancillary data which may be useful for interpreting trait values. Context properties are divided into 5 categories: treatment context, plot context, entity context, temporal context, and method context.\n\n\n\n\n\n\n\ncontext category\ndescription\n\n\n\n\ntreatment context\nContext property that is an experimental manipulation, that might affect the trait values measured on an individual, population or species-level entity.\n\n\nplot context\nContext property that is a feature of a plot (subset of a location) that might affect the trait values measured on an individual, population or species-level entity.\n\n\nentity context\nContext property that is information about an organismal entity (individual, population or taxon) that does not comprise a trait-centered observation but might affect the trait values measured on the entity.\n\n\ntemporal context\nContext property that is a feature of a “point in time” that might affect the trait values measured on an individual, population or species-level entity.\n\n\nmethod context\nContext property that records specific information about a measurement method that is modified between measurements.\n\n\n\nThe austraits function join_context_properties joins context properties to the traits table. It has three arguments:\n\nvars, specifies the context properties, via complete or partial string matches, that should be added to the traits table; defaults to “all”\nformat offers three output formats:\n\n*   `many_columns` (each context property is added as a separate column)  \n*   `single_column_pretty` (all context properties compacted into a single column delimited in a way that is easy for humans to read; this is the default)\n*   `single_column_json` (all context properties compacted into a single column, using json formatting)\n\ninclude_description is a logical argument (TRUE/FALSE) that indicates where the context property value descriptions should be included or excluded when context data are joined; defaults to “TRUE”\n\nEach category of context property is added to a separate column for the compacted columns, retaining this important information about the different groupings of context properties. When format = \"many_columns\" is selected the context category is indicated in the column name.\nExamples of joining context properties to the traits table:\n\n# method to add context properties that you know exist from previous database exploration; this example showcases `format = \"many_columns\"\ncontexts1 &lt;- austraits %&gt;%\n  austraits::join_context_properties(\n    vars = c(\"sampling season\", \"plant sex\", \"leaf surface\", \"leaf age\", \"fire intensity\",\n             \"slope position\", \"fire season\", \"drought treatment\", \"temperature treatment\"), \n    format = \"many_columns\",\n    include_description = TRUE\n    )\n\ncontexts1$traits %&gt;% names()\n\n [1] \"dataset_id\"                              \n [2] \"taxon_name\"                              \n [3] \"observation_id\"                          \n [4] \"trait_name\"                              \n [5] \"value\"                                   \n [6] \"unit\"                                    \n [7] \"entity_type\"                             \n [8] \"value_type\"                              \n [9] \"basis_of_value\"                          \n[10] \"replicates\"                              \n[11] \"basis_of_record\"                         \n[12] \"life_stage\"                              \n[13] \"population_id\"                           \n[14] \"individual_id\"                           \n[15] \"repeat_measurements_id\"                  \n[16] \"temporal_context_id\"                     \n[17] \"source_id\"                               \n[18] \"location_id\"                             \n[19] \"entity_context_id\"                       \n[20] \"plot_context_id\"                         \n[21] \"treatment_context_id\"                    \n[22] \"collection_date\"                         \n[23] \"measurement_remarks\"                     \n[24] \"method_id\"                               \n[25] \"method_context_id\"                       \n[26] \"original_name\"                           \n[27] \"treatment_context: drought treatment\"    \n[28] \"treatment_context: temperature treatment\"\n[29] \"plot_context: fire intensity\"            \n[30] \"plot_context: slope position\"            \n[31] \"entity_context: plant sex\"               \n[32] \"temporal_context: sampling season\"       \n[33] \"temporal_context: fire season\"           \n[34] \"method_context: leaf age\"                \n[35] \"method_context: leaf surface\"            \n\ncontexts1$traits[1:10]\n\n# A tibble: 1,726,024 × 10\n   dataset_id taxon_name       observation_id trait_name value unit  entity_type\n   &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n 1 ABRS_1981  Acanthocarpus c… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n 2 ABRS_1981  Acanthocarpus c… 0001           seed_leng… 3     mm    species    \n 3 ABRS_1981  Acanthocarpus h… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n 4 ABRS_1981  Acanthocarpus p… 0003           leaf_comp… simp… &lt;NA&gt;  species    \n 5 ABRS_1981  Acanthocarpus p… 0004           leaf_comp… simp… &lt;NA&gt;  species    \n 6 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 4     mm    species    \n 7 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 5     mm    species    \n 8 ABRS_1981  Acanthocarpus r… 0005           leaf_comp… simp… &lt;NA&gt;  species    \n 9 ABRS_1981  Acanthocarpus r… 0006           leaf_comp… simp… &lt;NA&gt;  species    \n10 ABRS_1981  Acanthocarpus r… 0006           seed_leng… 2.5   mm    species    \n# ℹ 1,726,014 more rows\n# ℹ 3 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;, replicates &lt;chr&gt;\n\n# method where you first lookup context properties using the function `lookup_context_property`; this example showcases `format = \"single_column_pretty\"\nleaf_properties &lt;- lookup_context_property(database = austraits, term = \"leaf\")\n\ncontexts2 &lt;- austraits %&gt;%\n  austraits::join_context_properties(\n    vars = leaf_properties,\n    format = \"single_column_pretty\",\n    include_description = TRUE\n    )\n\ncontexts2$traits %&gt;% names()\n\n [1] \"dataset_id\"                   \"taxon_name\"                  \n [3] \"observation_id\"               \"trait_name\"                  \n [5] \"value\"                        \"unit\"                        \n [7] \"entity_type\"                  \"value_type\"                  \n [9] \"basis_of_value\"               \"replicates\"                  \n[11] \"basis_of_record\"              \"life_stage\"                  \n[13] \"population_id\"                \"individual_id\"               \n[15] \"repeat_measurements_id\"       \"temporal_context_id\"         \n[17] \"source_id\"                    \"location_id\"                 \n[19] \"entity_context_id\"            \"plot_context_id\"             \n[21] \"treatment_context_id\"         \"collection_date\"             \n[23] \"measurement_remarks\"          \"method_id\"                   \n[25] \"method_context_id\"            \"original_name\"               \n[27] \"treatment_context_properties\" \"plot_context_properties\"     \n[29] \"entity_context_properties\"    \"temporal_context_properties\" \n[31] \"method_context_properties\"   \n\ncontexts2$traits[1:10]\n\n# A tibble: 1,726,024 × 10\n   dataset_id taxon_name       observation_id trait_name value unit  entity_type\n   &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n 1 ABRS_1981  Acanthocarpus c… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n 2 ABRS_1981  Acanthocarpus c… 0001           seed_leng… 3     mm    species    \n 3 ABRS_1981  Acanthocarpus h… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n 4 ABRS_1981  Acanthocarpus p… 0003           leaf_comp… simp… &lt;NA&gt;  species    \n 5 ABRS_1981  Acanthocarpus p… 0004           leaf_comp… simp… &lt;NA&gt;  species    \n 6 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 4     mm    species    \n 7 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 5     mm    species    \n 8 ABRS_1981  Acanthocarpus r… 0005           leaf_comp… simp… &lt;NA&gt;  species    \n 9 ABRS_1981  Acanthocarpus r… 0006           leaf_comp… simp… &lt;NA&gt;  species    \n10 ABRS_1981  Acanthocarpus r… 0006           seed_leng… 2.5   mm    species    \n# ℹ 1,726,014 more rows\n# ℹ 3 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;, replicates &lt;chr&gt;\n\n# method where you add all context properties; this example showcases `format = \"single_column_json\"\ncontexts3 &lt;- austraits %&gt;%\n  austraits::join_context_properties(\n    vars = \"all\",\n    format = \"single_column_json\",\n    include_description = FALSE\n    )\n\ncontexts3$traits %&gt;% names()\n\n [1] \"dataset_id\"                   \"taxon_name\"                  \n [3] \"observation_id\"               \"trait_name\"                  \n [5] \"value\"                        \"unit\"                        \n [7] \"entity_type\"                  \"value_type\"                  \n [9] \"basis_of_value\"               \"replicates\"                  \n[11] \"basis_of_record\"              \"life_stage\"                  \n[13] \"population_id\"                \"individual_id\"               \n[15] \"repeat_measurements_id\"       \"temporal_context_id\"         \n[17] \"source_id\"                    \"location_id\"                 \n[19] \"entity_context_id\"            \"plot_context_id\"             \n[21] \"treatment_context_id\"         \"collection_date\"             \n[23] \"measurement_remarks\"          \"method_id\"                   \n[25] \"method_context_id\"            \"original_name\"               \n[27] \"treatment_context_properties\" \"plot_context_properties\"     \n[29] \"entity_context_properties\"    \"temporal_context_properties\" \n[31] \"method_context_properties\"   \n\ncontexts3$traits[1:10]\n\n# A tibble: 1,726,024 × 10\n   dataset_id taxon_name       observation_id trait_name value unit  entity_type\n   &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n 1 ABRS_1981  Acanthocarpus c… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n 2 ABRS_1981  Acanthocarpus c… 0001           seed_leng… 3     mm    species    \n 3 ABRS_1981  Acanthocarpus h… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n 4 ABRS_1981  Acanthocarpus p… 0003           leaf_comp… simp… &lt;NA&gt;  species    \n 5 ABRS_1981  Acanthocarpus p… 0004           leaf_comp… simp… &lt;NA&gt;  species    \n 6 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 4     mm    species    \n 7 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 5     mm    species    \n 8 ABRS_1981  Acanthocarpus r… 0005           leaf_comp… simp… &lt;NA&gt;  species    \n 9 ABRS_1981  Acanthocarpus r… 0006           leaf_comp… simp… &lt;NA&gt;  species    \n10 ABRS_1981  Acanthocarpus r… 0006           seed_leng… 2.5   mm    species    \n# ℹ 1,726,014 more rows\n# ℹ 3 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;, replicates &lt;chr&gt;\n\n\n\n\nJoining methods columns\nThe methods table documents a selection of metadata recorded about the entire dataset and methods used for individual trait measurements. There is a single row of data per dataset_id x trait_name x method_id combination. Method_id is used to distinguish between instances where a single trait is measured twice using two separate protocols and is separate to method_context_id, which documents specific components of a method that are modified between measurements.\nThe austraits function join_methods joins columns from the methods table to the traits table. It has one argument:\n\nvars which specifies which columns from the methods table are joined to the traits table; defaults to vars = c(\"all\")\n\nFirst, check the schema file embedded within AusTraits to see what information is documented in each column:\n\naustraits$schema$austraits$elements$methods$elements %&gt;% \n  austraits::convert_list_to_df1()\n\n# A tibble: 15 × 2\n   key                              value                                       \n   &lt;chr&gt;                            &lt;chr&gt;                                       \n 1 dataset_id                       Primary identifier for each study contribut…\n 2 trait_name                       Name of the trait sampled. Allowable values…\n 3 methods                          A textual description of the methods used t…\n 4 method_id                        A unique integer identifier to distinguish …\n 5 description                      A 1-2 sentence description of the purpose o…\n 6 sampling_strategy                A written description of how study location…\n 7 source_primary_key               Citation key for the primary source in `sou…\n 8 source_primary_citation          Citation for the primary source. This detai…\n 9 source_secondary_key             Citation key for the secondary source in `s…\n10 source_secondary_citation        Citations for the secondary source. This de…\n11 source_original_dataset_key      Citation key for the original dataset_id in…\n12 source_original_dataset_citation Citations for the original dataset_id in so…\n13 data_collectors                  The person (people) leading data collection…\n14 assistants                       Names of additional people who played a mor…\n15 dataset_curators                 Names of AusTraits team member(s) who conta…\n\n\nExamples using join_methods:\n\n# join methods column only, the default\ntraits_with_methods &lt;- \n  austraits %&gt;% austraits::join_methods()\n\ntraits_with_methods$traits %&gt;% names()\n\n [1] \"dataset_id\"             \"taxon_name\"             \"observation_id\"        \n [4] \"trait_name\"             \"value\"                  \"unit\"                  \n [7] \"entity_type\"            \"value_type\"             \"basis_of_value\"        \n[10] \"replicates\"             \"basis_of_record\"        \"life_stage\"            \n[13] \"population_id\"          \"individual_id\"          \"repeat_measurements_id\"\n[16] \"temporal_context_id\"    \"source_id\"              \"location_id\"           \n[19] \"entity_context_id\"      \"plot_context_id\"        \"treatment_context_id\"  \n[22] \"collection_date\"        \"measurement_remarks\"    \"method_id\"             \n[25] \"method_context_id\"      \"original_name\"          \"methods\"               \n\n# join all methods table columns\ntraits_with_methods &lt;- \n  austraits %&gt;% austraits::join_methods(vars = \"all\")\n\ntraits_with_methods$traits %&gt;% names()\n\n [1] \"dataset_id\"                       \"taxon_name\"                      \n [3] \"observation_id\"                   \"trait_name\"                      \n [5] \"value\"                            \"unit\"                            \n [7] \"entity_type\"                      \"value_type\"                      \n [9] \"basis_of_value\"                   \"replicates\"                      \n[11] \"basis_of_record\"                  \"life_stage\"                      \n[13] \"population_id\"                    \"individual_id\"                   \n[15] \"repeat_measurements_id\"           \"temporal_context_id\"             \n[17] \"source_id\"                        \"location_id\"                     \n[19] \"entity_context_id\"                \"plot_context_id\"                 \n[21] \"treatment_context_id\"             \"collection_date\"                 \n[23] \"measurement_remarks\"              \"method_id\"                       \n[25] \"method_context_id\"                \"original_name\"                   \n[27] \"methods\"                          \"description\"                     \n[29] \"sampling_strategy\"                \"source_primary_key\"              \n[31] \"source_primary_citation\"          \"source_secondary_key\"            \n[33] \"source_secondary_citation\"        \"source_original_dataset_key\"     \n[35] \"source_original_dataset_citation\" \"data_collectors\"                 \n[37] \"assistants\"                       \"dataset_curators\"                \n\n# join all specifically selected methods table columns\ntraits_with_methods &lt;- \n  austraits %&gt;% austraits::join_methods(vars = c(\"methods\", \"description\", \"source_secondary_key\"))\n\ntraits_with_methods$traits %&gt;% names()\n\n [1] \"dataset_id\"             \"taxon_name\"             \"observation_id\"        \n [4] \"trait_name\"             \"value\"                  \"unit\"                  \n [7] \"entity_type\"            \"value_type\"             \"basis_of_value\"        \n[10] \"replicates\"             \"basis_of_record\"        \"life_stage\"            \n[13] \"population_id\"          \"individual_id\"          \"repeat_measurements_id\"\n[16] \"temporal_context_id\"    \"source_id\"              \"location_id\"           \n[19] \"entity_context_id\"      \"plot_context_id\"        \"treatment_context_id\"  \n[22] \"collection_date\"        \"measurement_remarks\"    \"method_id\"             \n[25] \"method_context_id\"      \"original_name\"          \"methods\"               \n[28] \"description\"            \"source_secondary_key\"  \n\n\n\n\nJoining taxa\nThe taxa table documents a collection of names and identifiers for each taxon. Within AusTraits, names submitted as identifiers within a dataset might be resolved to a species, an infraspecific taxon, or sometimes just to a genus- or family-level name; the name’s resolution is recorded as the taxon_rank. The taxon_rank determines which information is filled in in the taxa table.\nThe {austraits} function join_taxa joins columns from the taxa table to the traits table. It has one argument:\n\nvars which specifies which columns from the taxa table are joined to the traits table; defaults to vars = c(\"family\", \"genus\", \"taxon_rank\", \"establishment_means\").\n\nFirst, check the schema file embedded within AusTraits to see what information is documented in each column:\n\naustraits$schema$austraits$elements$taxa$elements %&gt;% \n  austraits::convert_list_to_df1()\n\n# A tibble: 15 × 2\n   key                 value                                                    \n   &lt;chr&gt;               &lt;chr&gt;                                                    \n 1 taxon_name          Scientific name of the taxon on which traits were sample…\n 2 taxonomic_dataset   Name of the taxonomy (tree) that contains this concept. …\n 3 taxon_rank          The taxonomic rank of the most specific name in the scie…\n 4 trinomial           The infraspecific taxon name match for an original name.…\n 5 binomial            The species-level taxon name match for an original name.…\n 6 genus               Genus of the taxon without authorship.                   \n 7 family              Family of the taxon.                                     \n 8 taxon_distribution  Known distribution of the taxon, by Australian state.    \n 9 establishment_means Statement about whether an organism or organisms have be…\n10 taxonomic_status    The status of the use of the scientificName as a label f…\n11 taxon_id            An identifier for the set of taxon information (data ass…\n12 taxon_id_genus      An identifier for the set of taxon information (data ass…\n13 taxon_id_family     An identifier for the set of taxon information (data ass…\n14 scientific_name     The full scientific name, with authorship and date infor…\n15 scientific_name_id  An identifier for the set of taxon information (data ass…\n\n\nExamples using join_taxa:\n\n# join the default columns\ntraits_with_taxa &lt;- \n  austraits %&gt;% austraits::join_taxa()\n\ntraits_with_taxa$traits %&gt;% names()\n\n [1] \"dataset_id\"             \"taxon_name\"             \"observation_id\"        \n [4] \"trait_name\"             \"value\"                  \"unit\"                  \n [7] \"entity_type\"            \"value_type\"             \"basis_of_value\"        \n[10] \"replicates\"             \"basis_of_record\"        \"life_stage\"            \n[13] \"population_id\"          \"individual_id\"          \"repeat_measurements_id\"\n[16] \"temporal_context_id\"    \"source_id\"              \"location_id\"           \n[19] \"entity_context_id\"      \"plot_context_id\"        \"treatment_context_id\"  \n[22] \"collection_date\"        \"measurement_remarks\"    \"method_id\"             \n[25] \"method_context_id\"      \"original_name\"          \"family\"                \n[28] \"genus\"                  \"taxon_rank\"             \"establishment_means\"   \n\n# join all taxa table columns\ntraits_with_taxa &lt;- \n  austraits %&gt;% austraits::join_taxa(vars = \"all\")\n\ntraits_with_taxa$traits %&gt;% names()\n\n [1] \"dataset_id\"              \"taxon_name\"             \n [3] \"observation_id\"          \"trait_name\"             \n [5] \"value\"                   \"unit\"                   \n [7] \"entity_type\"             \"value_type\"             \n [9] \"basis_of_value\"          \"replicates\"             \n[11] \"basis_of_record\"         \"life_stage\"             \n[13] \"population_id\"           \"individual_id\"          \n[15] \"repeat_measurements_id\"  \"temporal_context_id\"    \n[17] \"source_id\"               \"location_id\"            \n[19] \"entity_context_id\"       \"plot_context_id\"        \n[21] \"treatment_context_id\"    \"collection_date\"        \n[23] \"measurement_remarks\"     \"method_id\"              \n[25] \"method_context_id\"       \"original_name\"          \n[27] \"taxon_rank\"              \"taxonomic_status\"       \n[29] \"taxonomic_dataset\"       \"taxon_name_alternatives\"\n[31] \"genus\"                   \"family\"                 \n[33] \"binomial\"                \"trinomial\"              \n[35] \"taxon_distribution\"      \"establishment_means\"    \n[37] \"scientific_name\"         \"taxon_id\"               \n[39] \"taxon_id_genus\"          \"taxon_id_family\"        \n[41] \"scientific_name_id\"     \n\n\n\n\nJoining taxonomic updates\nThe taxonomic updates table documents all taxonomic changes implemented in the construction of AusTraits, including both the correction of typos and the updating of outdated synonyms to the currently accepted name.\nThe {austraits} function join_taxonomic_updates joins columns from the taxonomic_updates table to the traits table. It has one argument:\n\nvars which specifies which columns from the taxonomic_updates table are joined to the traits table; defaults to vars = c(\"aligned_name\").\n\nFirst, check the schema file embedded within AusTraits to see what information is documented in each column:\n\naustraits$schema$austraits$elements$taxonomic_updates$elements %&gt;% \n  austraits::convert_list_to_df1()\n\n# A tibble: 7 × 2\n  key                           value                                           \n  &lt;chr&gt;                         &lt;chr&gt;                                           \n1 dataset_id                    Primary identifier for each study contributed t…\n2 original_name                 Name given to taxon in the original data suppli…\n3 aligned_name                  The taxon name without authorship after impleme…\n4 taxonomic_resolution          The rank of the most specific taxon name (or sc…\n5 taxon_name                    Scientific name of the taxon on which traits we…\n6 aligned_name_taxon_id         An identifier for the aligned name before it is…\n7 aligned_name_taxonomic_status The status of the use of the `aligned_name` as …\n\n\nExamples using join_taxonomic_updates:\n\n# join the default columns\ntraits_with_taxonomic_updates &lt;- \n  austraits %&gt;% austraits::join_taxonomic_updates()\n\ntraits_with_taxonomic_updates$traits %&gt;% names()\n\n [1] \"dataset_id\"             \"taxon_name\"             \"observation_id\"        \n [4] \"trait_name\"             \"value\"                  \"unit\"                  \n [7] \"entity_type\"            \"value_type\"             \"basis_of_value\"        \n[10] \"replicates\"             \"basis_of_record\"        \"life_stage\"            \n[13] \"population_id\"          \"individual_id\"          \"repeat_measurements_id\"\n[16] \"temporal_context_id\"    \"source_id\"              \"location_id\"           \n[19] \"entity_context_id\"      \"plot_context_id\"        \"treatment_context_id\"  \n[22] \"collection_date\"        \"measurement_remarks\"    \"method_id\"             \n[25] \"method_context_id\"      \"original_name\"          \"aligned_name\"          \n\n# join all methods columns\ntraits_with_taxonomic_updates &lt;- \n  austraits %&gt;% austraits::join_taxonomic_updates(vars = \"all\")\n\ntraits_with_taxonomic_updates$traits %&gt;% names()\n\n [1] \"dataset_id\"                    \"taxon_name\"                   \n [3] \"observation_id\"                \"trait_name\"                   \n [5] \"value\"                         \"unit\"                         \n [7] \"entity_type\"                   \"value_type\"                   \n [9] \"basis_of_value\"                \"replicates\"                   \n[11] \"basis_of_record\"               \"life_stage\"                   \n[13] \"population_id\"                 \"individual_id\"                \n[15] \"repeat_measurements_id\"        \"temporal_context_id\"          \n[17] \"source_id\"                     \"location_id\"                  \n[19] \"entity_context_id\"             \"plot_context_id\"              \n[21] \"treatment_context_id\"          \"collection_date\"              \n[23] \"measurement_remarks\"           \"method_id\"                    \n[25] \"method_context_id\"             \"original_name\"                \n[27] \"aligned_name\"                  \"taxonomic_resolution\"         \n[29] \"aligned_name_taxon_id\"         \"aligned_name_taxonomic_status\"\n\n\n\n\nJoining contributors\nThe contributors table documents all basic metadata about all dataset contributors, including their name, ORCID, and role for various datasets.\nThe {austraits} function join_contributors joins columns from the contributors table to the traits table. It has two arguments:\n\nvars which specifies which columns from the contributors table are joined to the traits table; defaults to `vars = c(“aligned_name”).\nformat offers two output formats:\n\n*   `single_column_pretty` (data in selected columns from `contributor` table compacted into a single column delimited in a way that is easy for humans to read; this is the default)\n*   `single_column_json` (data in selected columns from `contributor` table compacted into a single column, using json formatting)  \nFirst, check the schema file embedded within AusTraits to see what information is documented in each column:\n\naustraits$schema$austraits$elements$contributors$elements %&gt;% \n  austraits::convert_list_to_df1()\n\n# A tibble: 6 × 2\n  key             value                                                         \n  &lt;chr&gt;           &lt;chr&gt;                                                         \n1 dataset_id      Primary identifier for each study contributed to AusTraits; m…\n2 last_name       Last name of the data collector.                              \n3 given_name      Given names of the data collector.                            \n4 ORCID           ORCID of the data collector.                                  \n5 affiliation     Last known institution or affiliation.                        \n6 additional_role Additional roles of data collector, mostly contact person.    \n\n\nExamples using join_contributors:\n\n# join all columns (the default)\ntraits_with_contributors &lt;- \n  austraits %&gt;% austraits::join_contributors(format = \"single_column_json\")\n\ntraits_with_contributors$traits %&gt;% names()\n\n [1] \"dataset_id\"             \"taxon_name\"             \"observation_id\"        \n [4] \"trait_name\"             \"value\"                  \"unit\"                  \n [7] \"entity_type\"            \"value_type\"             \"basis_of_value\"        \n[10] \"replicates\"             \"basis_of_record\"        \"life_stage\"            \n[13] \"population_id\"          \"individual_id\"          \"repeat_measurements_id\"\n[16] \"temporal_context_id\"    \"source_id\"              \"location_id\"           \n[19] \"entity_context_id\"      \"plot_context_id\"        \"treatment_context_id\"  \n[22] \"collection_date\"        \"measurement_remarks\"    \"method_id\"             \n[25] \"method_context_id\"      \"original_name\"          \"data_contributors\"     \n\n# join select contributors columns\ntraits_with_contributors &lt;- \n  austraits %&gt;% austraits::join_contributors(\n                  vars = c(\"last_name\", \"first_name\", \"ORCID\"),\n                  format = \"single_column_pretty\")\n\ntraits_with_contributors$traits %&gt;% names()\n\n [1] \"dataset_id\"             \"taxon_name\"             \"observation_id\"        \n [4] \"trait_name\"             \"value\"                  \"unit\"                  \n [7] \"entity_type\"            \"value_type\"             \"basis_of_value\"        \n[10] \"replicates\"             \"basis_of_record\"        \"life_stage\"            \n[13] \"population_id\"          \"individual_id\"          \"repeat_measurements_id\"\n[16] \"temporal_context_id\"    \"source_id\"              \"location_id\"           \n[19] \"entity_context_id\"      \"plot_context_id\"        \"treatment_context_id\"  \n[22] \"collection_date\"        \"measurement_remarks\"    \"method_id\"             \n[25] \"method_context_id\"      \"original_name\"          \"data_contributors\"     \n\ntraits_with_contributors$traits\n\n# A tibble: 1,726,024 × 27\n   dataset_id taxon_name       observation_id trait_name value unit  entity_type\n   &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n 1 ABRS_1981  Acanthocarpus c… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n 2 ABRS_1981  Acanthocarpus c… 0001           seed_leng… 3     mm    species    \n 3 ABRS_1981  Acanthocarpus h… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n 4 ABRS_1981  Acanthocarpus p… 0003           leaf_comp… simp… &lt;NA&gt;  species    \n 5 ABRS_1981  Acanthocarpus p… 0004           leaf_comp… simp… &lt;NA&gt;  species    \n 6 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 4     mm    species    \n 7 ABRS_1981  Acanthocarpus p… 0004           seed_leng… 5     mm    species    \n 8 ABRS_1981  Acanthocarpus r… 0005           leaf_comp… simp… &lt;NA&gt;  species    \n 9 ABRS_1981  Acanthocarpus r… 0006           leaf_comp… simp… &lt;NA&gt;  species    \n10 ABRS_1981  Acanthocarpus r… 0006           seed_leng… 2.5   mm    species    \n# ℹ 1,726,014 more rows\n# ℹ 20 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;, …\n\n\n\n\nJoining all data\nIf you want to join data from all ancillary tables onto the traits table, effectively “flattening” the relational table into a flat table, it is simplest to use the {austraits} function flatten_database.\nflatten_database calls each of the join functions, selecting vars = \"all\" as the default for each function.\nIt has three arguments:\n\nvars, specifies the context properties, via complete or partial string matches, that should be added to the traits table; defaults to “all”\nformat offers three output formats that apply to the functions join_locations, join_contexts and join_contributors\n\n*   `many_columns` (each location or context property is added as a separate column)\n*   `single_column_pretty` (all location or context properties or all contributor columns compacted into a single column delimited in a way that is easy for humans to read; this is the default)\n*   `single_column_json` (all location or context properties or all contributor columns compacted into a single column, using json formatting)\n\ninclude_description is a logical argument (TRUE/FALSE) that indicates where the context property value descriptions should be included or excluded when context data are joined; defaults to “TRUE”; this argument is only used to parameterise join_contexts\n\nExamples using flatten_database:\n\n# using the defaults\nflat_database &lt;- austraits %&gt;% flatten_database()\n\nnames(flat_database)\n\n [1] \"dataset_id\"                       \"taxon_name\"                      \n [3] \"observation_id\"                   \"trait_name\"                      \n [5] \"value\"                            \"unit\"                            \n [7] \"entity_type\"                      \"value_type\"                      \n [9] \"basis_of_value\"                   \"replicates\"                      \n[11] \"basis_of_record\"                  \"life_stage\"                      \n[13] \"population_id\"                    \"individual_id\"                   \n[15] \"repeat_measurements_id\"           \"temporal_context_id\"             \n[17] \"source_id\"                        \"location_id\"                     \n[19] \"entity_context_id\"                \"plot_context_id\"                 \n[21] \"treatment_context_id\"             \"collection_date\"                 \n[23] \"measurement_remarks\"              \"method_id\"                       \n[25] \"method_context_id\"                \"original_name\"                   \n[27] \"location_name\"                    \"latitude (deg)\"                  \n[29] \"longitude (deg)\"                  \"location_properties\"             \n[31] \"treatment_context_properties\"     \"plot_context_properties\"         \n[33] \"entity_context_properties\"        \"temporal_context_properties\"     \n[35] \"method_context_properties\"        \"methods\"                         \n[37] \"description\"                      \"sampling_strategy\"               \n[39] \"source_primary_key\"               \"source_primary_citation\"         \n[41] \"source_secondary_key\"             \"source_secondary_citation\"       \n[43] \"source_original_dataset_key\"      \"source_original_dataset_citation\"\n[45] \"assistants\"                       \"dataset_curators\"                \n[47] \"data_contributors\"                \"taxon_rank\"                      \n[49] \"taxonomic_status\"                 \"taxonomic_dataset\"               \n[51] \"taxon_name_alternatives\"          \"genus\"                           \n[53] \"family\"                           \"binomial\"                        \n[55] \"trinomial\"                        \"taxon_distribution\"              \n[57] \"establishment_means\"              \"scientific_name\"                 \n[59] \"taxon_id\"                         \"taxon_id_genus\"                  \n[61] \"taxon_id_family\"                  \"scientific_name_id\"              \n[63] \"aligned_name\"                     \"taxonomic_resolution\"            \n[65] \"aligned_name_taxon_id\"            \"aligned_name_taxonomic_status\"   \n\n# specifying vars for each column\nflat_database &lt;- austraits %&gt;% flatten_database(\n  vars = list(\n    location = \"all\",\n    context = \"sampling_season\",\n    contributors = c(\"last_name\", \"first_name\", \"ORCID\"),\n    taxonomy = c(\"family\", \"establishment_means\"),\n    taxonomic_updates = \"aligned_name\",\n    methods = \"methods\"\n  )\n)\n\nnames(flat_database)\n\n [1] \"dataset_id\"                   \"taxon_name\"                  \n [3] \"observation_id\"               \"trait_name\"                  \n [5] \"value\"                        \"unit\"                        \n [7] \"entity_type\"                  \"value_type\"                  \n [9] \"basis_of_value\"               \"replicates\"                  \n[11] \"basis_of_record\"              \"life_stage\"                  \n[13] \"population_id\"                \"individual_id\"               \n[15] \"repeat_measurements_id\"       \"temporal_context_id\"         \n[17] \"source_id\"                    \"location_id\"                 \n[19] \"entity_context_id\"            \"plot_context_id\"             \n[21] \"treatment_context_id\"         \"collection_date\"             \n[23] \"measurement_remarks\"          \"method_id\"                   \n[25] \"method_context_id\"            \"original_name\"               \n[27] \"location_name\"                \"latitude (deg)\"              \n[29] \"longitude (deg)\"              \"location_properties\"         \n[31] \"treatment_context_properties\" \"plot_context_properties\"     \n[33] \"entity_context_properties\"    \"temporal_context_properties\" \n[35] \"method_context_properties\"    \"methods\"                     \n[37] \"data_contributors\"            \"family\"                      \n[39] \"establishment_means\"          \"aligned_name\"                \n\n\n\n\n\nCombining extract_ and join_ functions\nAs both the extract and join functions output a database with the original database structure they can be used sequentially to extract, then join exactly the data desired.\nFor instance:\n\nsubset2 &lt;- austraits %&gt;%\n  austraits::extract_data(table = \"traits\", col = \"basis_of_record\", col_value = \"field\") %&gt;%\n  austraits::extract_trait(trait_name = c(\"leaf_mass_per_area\", \"leaf_thickness\", \"leaf_length\", \"leaf_area\")) %&gt;%\n  austraits::extract_taxa(genus = \"Eucalyptus\") %&gt;%\n  austraits::join_location_coordinates() %&gt;%\n  austraits::join_taxa(vars = c(\"family\")) %&gt;%\n  austraits::join_context_properties(vars = \"all\", format = \"many_columns\")\n\nnames(subset2)\n\n [1] \"traits\"            \"locations\"         \"contexts\"         \n [4] \"methods\"           \"excluded_data\"     \"taxonomic_updates\"\n [7] \"taxa\"              \"contributors\"      \"sources\"          \n[10] \"definitions\"       \"schema\"            \"metadata\"         \n[13] \"build_info\"       \n\n\nHaving joined all context properties are separate columns, you may now look at the expanded traits table and decide that you only want data that was sampled during wet seasons, documented in the column temporal_context: sampling season\n\nunique(subset2$traits$`temporal_context: sampling season`)\n\n [1] NA                                                                                                            \n [2] \"summer favourable &lt;&lt;Measurements made during summer in a location where this is the favourable season.&gt;&gt;\"    \n [3] \"winter unfavourable &lt;&lt;Measurements made during winter in a location where this is the unfavourable season.&gt;&gt;\"\n [4] \"dry &lt;&lt;Measurements made during the dry season.&gt;&gt;\"                                                            \n [5] \"summer unfavourable &lt;&lt;Measurements made during summer in a location where this is the unfavourable season.&gt;&gt;\"\n [6] \"winter favourable &lt;&lt;Measurements made during winter in a location where this is the favourable season.&gt;&gt;\"    \n [7] \"October\"                                                                                                     \n [8] \"wet &lt;&lt;Measurements made during the wet season.&gt;&gt;\"                                                            \n [9] \"dry season &lt;&lt;Measurements made during the dry season.&gt;&gt;\"                                                     \n[10] \"wet season &lt;&lt;Measurements made during the wet season.&gt;&gt;\"                                                     \n[11] \"dry season (Sep 2010) &lt;&lt;Measurements made during the dry season (Sep 2010).&gt;&gt;\"                               \n[12] \"wet season (May 2011) &lt;&lt;Measurements made during the wet season (May 2011).&gt;&gt;\"                               \n\nsubset2 &lt;- subset2 %&gt;%\n  austraits::extract_data(table = \"traits\", col = \"temporal_context: sampling season\", col_value = \"wet\")\n\n\n\nBinding datasets\nFor some applications, you may wish to extract two different subsets of data, based on the values of different columns, then merge those extracted database subsets together, but still retain the original database structure.\nThis is possible with the function bind_databases.\nThis function binds each of the relational tables, removing any duplicate entries.\nFor instance, you might want all measurements where either the location_property or the context_property references the word “fire”:\n\nsubset_a &lt;- austraits %&gt;%\n  austraits::extract_data(table = \"locations\", col = \"location_property\", col_value = \"fire\")\n\nsubset_b &lt;- austraits %&gt;%\n  austraits::extract_data(table = \"contexts\", col = \"context_property\", col_value = \"fire\")\n\nsubset_ab &lt;- bind_databases(subset_a, subset_b)",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>AusTraits tutorial</span>"
    ]
  },
  {
    "objectID": "AusTraits_tutorial.html#summarising-data-trait-means-modes-etc.",
    "href": "AusTraits_tutorial.html#summarising-data-trait-means-modes-etc.",
    "title": "30  AusTraits tutorial",
    "section": "30.7 Summarising data: trait means, modes, etc.",
    "text": "30.7 Summarising data: trait means, modes, etc.\nThe function summarise_trait_means that was in older {austraits} versions was has been deprecated, as it is not appropriate for AusTraits versions &gt; 5.0 – that is all databases built using {traits.build}. A new version is in development and will be released in 2025. In the meantime, if you’ve sourced the file extra_functions.R, there are a few functions that allow you to summarise trait values.\n\nCategorical traits\nFor instance, categorical_summary indicates how many times a specific trait value is reported for a given taxa (across all datasets):\n\ncat_summary &lt;- categorical_summary(austraits, \"resprouting_capacity\")\n\ncat_summary\n\n# A tibble: 12,817 × 3\n   taxon_name                             trait_name           value_summary  \n   &lt;chr&gt;                                  &lt;chr&gt;                &lt;chr&gt;          \n 1 Abelmoschus ficulneus                  resprouting_capacity fire_killed (4)\n 2 Abelmoschus manihot                    resprouting_capacity fire_killed (3)\n 3 Abelmoschus moschatus                  resprouting_capacity resprouts (1)  \n 4 Abelmoschus moschatus subsp. tuberosus resprouting_capacity resprouts (3)  \n 5 Abrodictyum caudatum                   resprouting_capacity fire_killed (2)\n 6 Abrodictyum obscurum                   resprouting_capacity fire_killed (2)\n 7 Abrotanella forsteroides               resprouting_capacity resprouts (1)  \n 8 Abrotanella nivigena                   resprouting_capacity resprouts (1)  \n 9 Abrotanella sp. [White_2020]           resprouting_capacity resprouts (1)  \n10 Abrus precatorius                      resprouting_capacity resprouts (1)  \n# ℹ 12,807 more rows\n\n\nAlternatively, create a wider matrix with possible trait values as columns:\n\ncategorical_summary_wider &lt;- \n  categorical_summary_by_value(austraits, \"resprouting_capacity\") %&gt;%\n    tidyr::pivot_wider(names_from = value_tmp, values_from = replicates)\n\ncategorical_summary_wider\n\n# A tibble: 12,817 × 5\n   taxon_name               trait_name fire_killed resprouts partial_resprouting\n   &lt;chr&gt;                    &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;               &lt;dbl&gt;\n 1 Abelmoschus ficulneus    resprouti…           4        NA                  NA\n 2 Abelmoschus manihot      resprouti…           3        NA                  NA\n 3 Abelmoschus moschatus    resprouti…          NA         1                  NA\n 4 Abelmoschus moschatus s… resprouti…          NA         3                  NA\n 5 Abrodictyum caudatum     resprouti…           2        NA                  NA\n 6 Abrodictyum obscurum     resprouti…           2        NA                  NA\n 7 Abrotanella forsteroides resprouti…          NA         1                  NA\n 8 Abrotanella nivigena     resprouti…          NA         1                  NA\n 9 Abrotanella sp. [White_… resprouti…          NA         1                  NA\n10 Abrus precatorius        resprouti…          NA         1                  NA\n# ℹ 12,807 more rows\n\n\n\n\nNumeric traits\nOne of the problems with writing functions that summarise numeric traits is that they make statistical assumptions that are hidden within the function code and might not be appropriate for your data use case.\nThe datasets that comprise AusTraits were collected by different people, with a different number of replicates and different entity types reported. One dataset might include 20 measurements on individuals for a trait and another might have submitted a single population-level mean derived from 5 measurements.\nHow do you take the mean of these trait values?\nDo you want to include both data from experiments and plants growing under natural conditions? This information is recorded in the basis_of_record column.\nOne function we’re developing calculates weighted group means for field and experiment-sourced data, by first grouping values at the site level, then at the taxon level. For trait data sourced from floras where trait values are documented as a minimum and maximum value, the function takes the mean of these. The two subsets of data are then merged together.\n\nweighted &lt;- austraits_weighted_means(austraits, c(\"leaf_mass_per_area\", \n                                                  \"leaf_length\"))\n\nweighted\n\n# A tibble: 24,995 × 10\n   taxon_name       trait_name  mean   min   max median geom_mean all_replicates\n   &lt;chr&gt;            &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;\n 1 Abelia x grandi… leaf_leng…   35     20    50     NA      35                1\n 2 Abelmoschus fic… leaf_leng…  105     50   160     NA     105                1\n 3 Abelmoschus man… leaf_leng…  232.   150   380     NA     230.               2\n 4 Abelmoschus man… leaf_leng…  200    200   200     NA     200                1\n 5 Abelmoschus mos… leaf_leng…  103.    27   150     NA      97.6              3\n 6 Abelmoschus mos… leaf_leng…  150    150   150     NA     150                1\n 7 Abildgaardia ov… leaf_leng…  230     60   400     NA     230                1\n 8 Abrodictyum bra… leaf_leng…  143.    40   250     NA     137.               2\n 9 Abrodictyum cau… leaf_leng…  134.    35   200     NA     129.               4\n10 Abrodictyum obs… leaf_leng…  190     20   400     NA     161.               5\n# ℹ 24,985 more rows\n# ℹ 2 more variables: location_replicates &lt;dbl&gt;, flora_replicates &lt;dbl&gt;\n\n\nThis function may be sufficient for exploratory purposes. Alternatively, you can download the file with the function and edit the code to suit your purposes.",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>AusTraits tutorial</span>"
    ]
  },
  {
    "objectID": "AusTraits_tutorial.html#plotting_functions",
    "href": "AusTraits_tutorial.html#plotting_functions",
    "title": "30  AusTraits tutorial",
    "section": "30.8 Plotting data",
    "text": "30.8 Plotting data\n\nPlotting trait distributions\nAnother way to summarise AusTraits data by trait, and determine whether AusTraits offers sufficient data coverage for a trait of choice, is to plot the distribution of trait values in AusTraits.\nAs seen in A first look at data, the function austraits::plot_trait_distribution_beeswarm() plots trait data by dataset_id, genus, family or indeed any column in the traits table, such as life_stage or basis_of_record:\n\n# How does leaf N vary by dataset?\naustraits::plot_trait_distribution_beeswarm(austraits, \"leaf_N_per_dry_mass\", \n                                               y_axis_category = \"dataset_id\")\n\n\n\n\n\n\n\n# How does leaf N vary across Banksia species?\nBanksia_data &lt;- austraits %&gt;% extract_taxa(genus = \"Banksia\")\n\naustraits::plot_trait_distribution_beeswarm(Banksia_data, \"leaf_N_per_dry_mass\",\n                                               y_axis_category = \"taxon_name\")\n\n\n\n\n\n\n\n# Does leaf mass per area shift in Eucalyptus seedlings versus adults, which is captured in `life_stage`? What about amongst Eucalypts where information about the age of the leaves was recorded, captured as the context property \"leaf age\"?\n\nEuc_data &lt;- austraits %&gt;% extract_taxa(genus = \"Eucalyptus\") %&gt;%\n  austraits::join_context_properties(vars = \"leaf age\", format = \"many_columns\", include_description = FALSE)\n\naustraits::plot_trait_distribution_beeswarm(Euc_data, \"leaf_mass_per_area\", \n                                               y_axis_category = \"life_stage\")\n\n\n\n\n\n\n\naustraits::plot_trait_distribution_beeswarm(Euc_data, \"leaf_mass_per_area\", \n                                               y_axis_category = \"method_context: leaf age\")\n\n\n\n\n\n\n\n\n\n\nPlotting data distribution by location\nTo plot locations, begin by merging on the latitude & longitude data from austraits$locations using austraits::join_location_coordinates.\nThe plot_locations function plots the selected data, separating data into a series of plots based on the variable name selected. You can separate data based on the values of any column within the traits table – including basis_of_record, life_stage and value_type – or higher taxon categories (genus, family).\nFor instance, austraits::plot_locations(\"trait_name\") will output a separate plot for each trait_name within the selected data.\nA warning: austraits::plot_locations() WILL BE VERY SLOW if you request more than ~20 plots. For instance, do not attempt to generate plots for all traits simultaneously. Always first use extract/filter to just select a narrow range of traits, datasets, or taxa.\n\nPlot locations by trait, dataset, or other column\nSee where Eucalyptus data have been collected, divided by life_stage\n\nEuc_data &lt;- Euc_data %&gt;%\n  austraits::join_location_coordinates()\n\naustraits::plot_locations(database = Euc_data, feature = \"life_stage\")\n\n\n\n\n\n\n\n\nSee where Banksia leaf area data have been collected, divided by taxon_name\n\nBanksia_data &lt;- Banksia_data %&gt;%\n  austraits::join_location_coordinates() %&gt;%\n  austraits::extract_trait(trait_name = \"leaf_area\")\n\naustraits::plot_locations(database = Banksia_data, feature = \"taxon_name\")\n\n\n\n\n\n\n\n\nWhere were the various Westoby datasets collected?\n\nWestoby &lt;-\n  austraits %&gt;%\n     austraits::extract_dataset(dataset_id = \"Westoby\") %&gt;%\n     austraits::join_location_coordinates()\n\naustraits::plot_locations(database = Westoby, feature = \"dataset_id\")\n\n\n\n\n\n\n\n# Note that while the `dataset` is intended to be a relational database, this function also works with just the traits table, should you have separated it out of the relational structure.\n\n# Westoby_traits &lt;- Westoby$traits\n# austraits::plot_locations(dataset = Westoby_traits, feature = \"dataset_id\")\n\nWhere were data for Acacia aneura collected?\n\ndata &lt;-\n  austraits %&gt;%\n  austraits::extract_taxa(taxon_name = \"Acacia aneura\") %&gt;%\n  austraits::join_location_coordinates()\n\ndata$traits &lt;- data$traits %&gt;% \n  dplyr::filter(!is.na(`latitude (deg)`)) \n\naustraits::plot_locations(data, \"taxon_name\")     # actually 4 taxa, because of subspecies\n\n\n\n\n\n\n\naustraits::plot_locations(data, \"dataset_id\")     # 1 plot for each dataset_id\n\n\n\n\n\n\n\n\n\n\n\nMore complex workflows – some examples\n\nAn example looking at trait-climate gradients\nA simple workflow allows one to look at trait values across a climate gradient\n\n\nAn example incorporating ALA distribution data\nA recent tutorial posted by ALA shows how one can combine AusTraits trait data and ALA spatial occurrence data:\nhttps://labs.ala.org.au/posts/2023-08-28_alternatives-to-box-plots/post.html\nWe’ve adopted it here.",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>AusTraits tutorial</span>"
    ]
  },
  {
    "objectID": "AusTraits_tutorial.html#a-complexity-pivoting-datasets-pivotting_datasets",
    "href": "AusTraits_tutorial.html#a-complexity-pivoting-datasets-pivotting_datasets",
    "title": "30  AusTraits tutorial",
    "section": "30.9 A complexity: pivoting datasets {pivotting_datasets}",
    "text": "30.9 A complexity: pivoting datasets {pivotting_datasets}\nThe AusTraits tables are all in long format with an individual row for each trait measurement. This is the most compact way to store data and offers the flexibility of documenting diverse metadata for each trait measurement.\nHowever, for many research uses, it may be more useful to view data in a wide format, with the multiple traits that comprise a single observation displayed as consecutive columns.\nThe {austraits} function trait_pivot_wider allows AusTraits datasets to be pivoted from long to wide format.\nIt is recommended to only use this function on individual datasets – or perhaps a small selection of datasets – as each dataset includes a different collection of traits and pivoting wider otherwise creates a very “holey” dataset.\n\nFarrell_2017_values &lt;-\n  austraits %&gt;%\n    austraits::extract_dataset(dataset_id = \"Farrell_2017\")\n\nFarrell_2017_pivoted &lt;- \n  Farrell_2017_values$traits %&gt;%\n    austraits::trait_pivot_wider()\n\nFarrell_2017_pivoted\n\n# A tibble: 177 × 25\n   dataset_id   taxon_name observation_id entity_type basis_of_record life_stage\n   &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;          &lt;chr&gt;       &lt;chr&gt;           &lt;chr&gt;     \n 1 Farrell_2017 Arthropod… 001            individual  lab             adult     \n 2 Farrell_2017 Arthropod… 002            individual  lab             adult     \n 3 Farrell_2017 Arthropod… 003            individual  lab             adult     \n 4 Farrell_2017 Arthropod… 004            individual  lab             adult     \n 5 Farrell_2017 Arthropod… 005            individual  lab             adult     \n 6 Farrell_2017 Arthropod… 006            individual  lab             adult     \n 7 Farrell_2017 Arthropod… 007            individual  lab             adult     \n 8 Farrell_2017 Arthropod… 008            individual  lab             adult     \n 9 Farrell_2017 Arthropod… 009            individual  lab             adult     \n10 Farrell_2017 Chrysocep… 010            individual  lab             adult     \n# ℹ 167 more rows\n# ℹ 19 more variables: population_id &lt;chr&gt;, individual_id &lt;chr&gt;,\n#   repeat_measurements_id &lt;chr&gt;, temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;,\n#   location_id &lt;chr&gt;, entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;,\n#   treatment_context_id &lt;chr&gt;, collection_date &lt;chr&gt;, method_id &lt;chr&gt;,\n#   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;,\n#   bulk_modulus_of_elasticity &lt;chr&gt;, …\n\n\nThis example pivots “nicely” as all observations have entity_type = individual.\nCompare this first example to the dataset Edwards_2000 which includes individual-, population-, and species-level observations:\n\nEdwards_2000_values &lt;-\n  austraits %&gt;%\n    austraits::extract_dataset(dataset_id = \"Edwards_2000\")\n\nEdwards_2000_pivoted &lt;- \n  Edwards_2000_values$traits %&gt;%\n    austraits::trait_pivot_wider()\n\nEdwards_2000_pivoted\n\n# A tibble: 139 × 35\n   dataset_id   taxon_name observation_id entity_type basis_of_record life_stage\n   &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;          &lt;chr&gt;       &lt;chr&gt;           &lt;chr&gt;     \n 1 Edwards_2000 Acacia me… 001            individual  field           adult     \n 2 Edwards_2000 Acacia me… 002            individual  field           adult     \n 3 Edwards_2000 Acacia me… 003            individual  field           adult     \n 4 Edwards_2000 Acacia me… 004            individual  field           adult     \n 5 Edwards_2000 Acacia me… 005            individual  field           adult     \n 6 Edwards_2000 Acacia me… 006            population  field           adult     \n 7 Edwards_2000 Acacia me… 007            species     field           adult     \n 8 Edwards_2000 Acacia su… 008            individual  field           adult     \n 9 Edwards_2000 Acacia su… 009            individual  field           adult     \n10 Edwards_2000 Acacia su… 010            individual  field           adult     \n# ℹ 129 more rows\n# ℹ 29 more variables: population_id &lt;chr&gt;, individual_id &lt;chr&gt;,\n#   repeat_measurements_id &lt;chr&gt;, temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;,\n#   location_id &lt;chr&gt;, entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;,\n#   treatment_context_id &lt;chr&gt;, collection_date &lt;chr&gt;, method_id &lt;chr&gt;,\n#   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;, leaf_N_per_area &lt;chr&gt;,\n#   leaf_N_per_dry_mass &lt;chr&gt;, leaf_area &lt;chr&gt;, leaf_mass_per_area &lt;chr&gt;, …\n\n\nThe values at the individual, population and species level do not collapse together, because traits measured on different entity_types have separate observation_id’s.\nOne of the core identifiers assigned to data points is the observation_id. An observation is a collection of measurements made on a specific entity at a single point in time.\nObservation_id’s are, therefore, unique combinations of:\n\ndataset_id\nsource_id\nentity_type\ntaxon_name\npopulation_id (location_id, plot_context_id, treatment_context_id)\nindividual_id\nbasis_of_record\nentity_context_id\nlife_stage\ntemporal_context_id\ncollection_date\noriginal_name\n\nIf a single dataset includes traits that are attributed to different entity types, they are assigned separate observation_id’s. For instance, many datasets are comprised of individual-level physiological trait data and a column growth_form, documenting the growth form (i.e. tree, shrub, herb, etc.) of each species.\nWe’re developing a function, merge_entity_types that collapses the pivoted data into a more condensed table, but this loses some of the metadata. This function is currently in the R file extra_functions.R\n\nEdwards_2000_pivoted_merged &lt;-\n  merge_entity_types(\"Edwards_2000\")\n\n\nThis function will duplicate any “higher-entity” trait values (e.g. A single species-level value is filled in for all individuals or populations)\nMetadata fields, like entity_type or value_type, are only retained if their values are identical for all measurements\n\n\nWestoby_2014_pivoted_merged &lt;-\n  merge_entity_types(\"Westoby_2014\")",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>AusTraits tutorial</span>"
    ]
  },
  {
    "objectID": "AusTraits_tutorial.html#intepreting-trait-names-taxon-names",
    "href": "AusTraits_tutorial.html#intepreting-trait-names-taxon-names",
    "title": "30  AusTraits tutorial",
    "section": "30.10 Intepreting trait names, taxon names",
    "text": "30.10 Intepreting trait names, taxon names\n\nTrait dictionary\nThe {traits.build} pipeline requires a trait dictionary that documents 4 pieces of information about each trait:\n\ntrait name \ntrait type (categorical vs numeric) \nallowable trait values (for categorical traits) \nallowable trait range and units (for numeric traits) \n\nThe trait dictionary embedded within AusTraits also has:\n\ntrait labels \ntrait definitions \ndefinitions for all categorical trait values \n\nTogether these clarify each “trait concept”, which we define as: “a circumscribed set of trait measurements”. Much like a taxon concept delimits a collection of organisms, a trait concept delimits a collection of trait values pertaining to a distinct characteristic of a specific part of an organism (cell, tissue, organ, or whole organism).\nThe AusTraits Plant Dictionary (APD) offers detailed descriptions for all trait concepts included in AusTraits. With the APD, each trait is given a unique, resolvable identifier, allowing trait definitions to be reused and shared.\nThe trait dictionary also includes: \n\nkeywords \nplant structure measured \ncharacteristic measured \nreferences \nlinks to the same (or similar) trait concepts in other databases and dictionaries \n\n\n\nUnderstanding taxon names\nAusTraits uses the taxon names in the Australian Plant Census (APC) and the scientific names in the Australian Plant Names Index (APNI).\nThe R package {APCalign} is used to align and update taxon names submitted to AusTraits with those in the APC/APNI.\n{APCalign} can be installed directly from CRAN\n\n#install.packages(\"APCalign\")\n\nlibrary(APCalign) # Australian plant taxon alignment function, available on CRAN \n\nThere are two key components to the workflow: \n\naligning names \n\n\nsyntax is standardised, including for phrase names \nmost spelling mistakes are corrected \nnames that indicate the plant can only be identified to genus are reformatted to genus sp. [available notes; dataset_id] \n\nthey are linked to an APC-accepted genus but not to an APC-accepted binomial. \nthey include the dataset_id so people don’t mistakenly group all Eucalyptus sp. as a single “species” \n\n\n\nupdating names \n\n\nall aligned names that are in the APC, but that have a taxonomic status other than accepted, are updated to their currently accepted name. \n\nExamples: \nIdentical genus sp. inputs from disparate datasets are given unique “names”: \n\naustraits$traits %&gt;%\n  dplyr::filter(stringr::str_detect(original_name, \"Eucalyptus sp\\\\.$\")) %&gt;%\n  dplyr::distinct(dataset_id, taxon_name, original_name) %&gt;%\n  dplyr::filter(original_name != taxon_name) \n\n# A tibble: 4 × 3\n  dataset_id     taxon_name                      original_name \n  &lt;chr&gt;          &lt;chr&gt;                           &lt;chr&gt;         \n1 Clarke_2015    Eucalyptus sp. [Clarke_2015]    Eucalyptus sp.\n2 Nolan_2022     Eucalyptus sp. [Nolan_2022]     Eucalyptus sp.\n3 Soper_2014     Eucalyptus sp. [Soper_2014]     Eucalyptus sp.\n4 Zieminska_2015 Eucalyptus sp. [Zieminska_2015] Eucalyptus sp.\n\n\nOutdated names are updated: \n\naustraits$traits %&gt;%\n  dplyr::filter(stringr::str_detect(original_name, \"Dryandra\")) %&gt;%\n  dplyr::distinct(taxon_name, original_name) %&gt;%\n  dplyr::filter(original_name != taxon_name) %&gt;% dplyr::slice(1:15)\n\n# A tibble: 15 × 2\n   taxon_name                                 original_name                     \n   &lt;chr&gt;                                      &lt;chr&gt;                             \n 1 Banksia acanthopoda                        Dryandra acanthopoda              \n 2 Banksia anatona                            Dryandra anatona                  \n 3 Banksia arborea                            Dryandra arborea                  \n 4 Banksia arctotidis                         Dryandra arctotidis               \n 5 Banksia armata var. armata                 Dryandra armata var. armata       \n 6 Banksia armata var. ignicida               Dryandra armata var. ignicida     \n 7 Banksia armata                             Dryandra armata                   \n 8 Banksia aurantia                           Dryandra aurantia                 \n 9 Banksia biterax                            Dryandra baxteri                  \n10 Banksia bipinnatifida subsp. bipinnatifida Dryandra bipinnatifida subsp. bip…\n11 Banksia bipinnatifida subsp. multifida     Dryandra bipinnatifida subsp. mul…\n12 Banksia bipinnatifida                      Dryandra bipinnatifida            \n13 Banksia pellaeifolia                       Dryandra blechnifolia             \n14 Banksia borealis subsp. borealis           Dryandra borealis subsp. borealis \n15 Banksia borealis subsp. elatior            Dryandra borealis subsp. elatior  \n\n\nPhrase name syntax across datasets is aligned:\n\naustraits$traits %&gt;%\n  dplyr::filter(stringr::str_detect(taxon_name, \"Argyrodendron sp. Whyanbeel\")) %&gt;%\n  dplyr::distinct(taxon_name, original_name)\n\n# A tibble: 6 × 2\n  taxon_name                                       original_name                \n  &lt;chr&gt;                                            &lt;chr&gt;                        \n1 Argyrodendron sp. Whyanbeel (B.P.Hyland RFK1106) Argyrodendron (Whyanbeel)    \n2 Argyrodendron sp. Whyanbeel (B.P.Hyland RFK1106) Argyrodendron ssp. (Whyanbee…\n3 Argyrodendron sp. Whyanbeel (B.P.Hyland RFK1106) Argyrodendron Whyanbeel      \n4 Argyrodendron sp. Whyanbeel (B.P.Hyland RFK1106) Argyrodendron sp. (Whyanbeel…\n5 Argyrodendron sp. Whyanbeel (B.P.Hyland RFK1106) Argyrodendron sp. Whyanbeel …\n6 Argyrodendron sp. Whyanbeel (B.P.Hyland RFK1106) Argyrodendron sp. Whyanbeel …",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>AusTraits tutorial</span>"
    ]
  },
  {
    "objectID": "traits_and_climate_example.html",
    "href": "traits_and_climate_example.html",
    "title": "31  Analysis example: Using AusTraits for trait-climate analyses",
    "section": "",
    "text": "31.1 Introduction\nA more involved analysis is merging trait data with climatic parameters.\nPlease note the data summary and analysis presented here is similar to that in a manuscript currently in review, Towers et al, “Revisiting the role of mean annual precipitation in shaping functional trait distributions at a continental scale”, doi: 10.1101/2023.06.29.546983\nThe code presented here must be run offline on your machine, as the climate data files required are not hosted on the traits.build-book GitHub repository.\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(terra)\nlibrary(purrr)\nlibrary(ggplot2)\nThis example uses the most recent AusTraits release, version 6.0.0\nmost_recent &lt;- austraits::get_versions()[[\"doi\"]][1]\n\nmost_recent\n\n[1] \"10.5281/zenodo.11188867\"\n\naustraits &lt;- austraits::load_austraits(doi = most_recent)\n\nLoading data from 'data/austraits/austraits-6.0.0.rds'",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Analysis example: Using AusTraits for trait-climate analyses</span>"
    ]
  },
  {
    "objectID": "traits_and_climate_example.html#extract-data-from-austraits",
    "href": "traits_and_climate_example.html#extract-data-from-austraits",
    "title": "31  Analysis example: Using AusTraits for trait-climate analyses",
    "section": "31.2 Extract data from AusTraits",
    "text": "31.2 Extract data from AusTraits\nFor the analysis here, two subsets of AusTraits data are required.\nFirst, extracting data on woodiness. There are three traits for which AusTraits has near-complete taxon coverage. Woodiness & plant growth form are in Wenk_2022 and life history is in Wenk_2023_1:\n\nwoody_taxa &lt;-\n  austraits$traits %&gt;%\n  dplyr::filter(trait_name == \"woodiness_detailed\") %&gt;%\n  dplyr::filter(dataset_id == \"Wenk_2022\") %&gt;%\n  dplyr::select(taxon_name, value) %&gt;%\n  dplyr::mutate(woodiness = ifelse(stringr::str_detect(value, \"herb\"), \"herbaceous\", \"woody\")) %&gt;%\n  dplyr::select(-value) %&gt;%\n  dplyr::distinct(taxon_name, .keep_all = TRUE)\n\nSecond, extract the numeric trait data you want to analyse. Only field-collected data on adult plants with reported coordinates is used:\n\ntrait_data &lt;-\n  (austraits %&gt;% join_locations())$traits %&gt;%\n  rename(latitude = `latitude (deg)`, longitude = `longitude (deg)`) %&gt;%\n  dplyr::filter(!is.na(latitude)) %&gt;%\n  dplyr::filter(trait_name == \"leaf_mass_per_area\") %&gt;%\n  dplyr::filter(basis_of_record == \"field\") %&gt;%\n  dplyr::filter(life_stage == \"adult\") %&gt;%\n  dplyr::group_by(dataset_id, location_name, taxon_name) %&gt;%\n  dplyr::mutate(value = mean(as.numeric(value))) %&gt;%\n  dplyr::ungroup() %&gt;%\n  dplyr::mutate(\n    ID = row_number(),\n    latitude = as.numeric(latitude),\n    longitude = as.numeric(longitude)\n  ) %&gt;%\n  distinct(value, dataset_id, location_name, taxon_name, .keep_all = TRUE) %&gt;%\n  dplyr::filter(!is.na(latitude)) %&gt;%\n  dplyr::filter(!is.na(longitude)) %&gt;%\n  dplyr::left_join(woody_taxa, by = \"taxon_name\")",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Analysis example: Using AusTraits for trait-climate analyses</span>"
    ]
  },
  {
    "objectID": "traits_and_climate_example.html#download-and-open-spatial-climatic-data",
    "href": "traits_and_climate_example.html#download-and-open-spatial-climatic-data",
    "title": "31  Analysis example: Using AusTraits for trait-climate analyses",
    "section": "31.3 Download and open spatial climatic data",
    "text": "31.3 Download and open spatial climatic data\nDownload the climatic layers of interest from WorldClim:\nhttps://www.worldclim.org/data/worldclim21.html\nDownload a shapefile of Australia:\nhttps://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/digital-boundary-files\nLoad a target raster, to set the baseline Coordinate Reference System (CRS) and resolution:\n\ntarget_raster &lt;- terra::rast(\"export/wc2.1_2.5m_bio_12.tif\")\n\nSet the target CRS:\n\ntarget_crs &lt;- terra::crs(target_raster)\n\nLoad australia as a vector file to bound observations, using the target crs from above:\n\naustralia &lt;- terra::vect(\"export/AUS_2021_AUST_SHP_GDA2020/\", crs=target_crs)\n\nCrop the extent of the target raster with the vector file above and confirm the data are as expected:\n\nprecip_data_cropped &lt;- target_raster %&gt;%\n  terra::crop(australia)\n\nplot(precip_data_cropped)\n\nProject the AusTraits data into a spatial format and confirm the data plot as expected:\n\noccurrence_data_species_family_vect &lt;- terra::vect(trait_data,\n                                                   geom = c(\"longitude\", \"latitude\"),\n                                                   crs = terra::crs(precip_data_cropped))\n\nplot(occurrence_data_species_family_vect)\n\nUse the function terra::extract to extract climate variables for each AusTraits data point:\n\nextracted_tmp &lt;-\n  terra::extract(\n    x = precip_data_cropped,                   # climatic data\n    y = occurrence_data_species_family_vect,   # AusTraits trait data\n    method = \"simple\",\n    cells = TRUE, bind = TRUE, ID = FALSE, xy = TRUE)\n\nTurn extracted values into a dataframe and separate data for herbaceous versus woody taxa:\n\nextracted &lt;-\n  terra::values(extracted_tmp) %&gt;%\n    mutate(\n      value_herbs = ifelse(woodiness == \"herbaceous\", value, NA),\n      value_woody = ifelse(woodiness == \"woody\", value, NA)\n    )",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Analysis example: Using AusTraits for trait-climate analyses</span>"
    ]
  },
  {
    "objectID": "traits_and_climate_example.html#plot-your-data",
    "href": "traits_and_climate_example.html#plot-your-data",
    "title": "31  Analysis example: Using AusTraits for trait-climate analyses",
    "section": "31.4 Plot your data",
    "text": "31.4 Plot your data\n\nggplot() +\n  geom_point(\n    data = extracted,\n    aes(x = wc2.1_2.5m_bio_12,\n        y = value_herbs),\n        shape = 16,\n        alpha = 0.4,\n        color = \"darkseagreen3\"\n    ) +\n  geom_point(\n    data = extracted,\n    aes(x = wc2.1_2.5m_bio_12,\n        y = value_woody),\n    shape = 16,\n    alpha = 0.4,\n    color = \"coral\"\n  ) +\n  scale_x_continuous(\n    trans = \"log10\"\n  ) +\n  scale_y_continuous(\n    trans = \"log10\"\n  ) +\n  labs(\n    x = \"Annual precipitation (mm)\",\n    y = \"Leaf mass per area (g/m2)\")",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Analysis example: Using AusTraits for trait-climate analyses</span>"
    ]
  },
  {
    "objectID": "spatial_data_example.html",
    "href": "spatial_data_example.html",
    "title": "32  Analysis example: Using AusTraits with spatial data",
    "section": "",
    "text": "This tutorial is based on this great tutorial by Dax Kellie and Shandiya Balasubramaniam from the ALA team.\n\n# remotes::install_github(\"traitecoevo/austraits\")\nlibrary(tidyverse)\nlibrary(austraits)\n\nLoad austraits\n\nmost_recent &lt;- austraits::get_versions()[[\"doi\"]][1]\n\nmost_recent\n\n[1] \"10.5281/zenodo.11188867\"\n\naustraits &lt;- austraits::load_austraits(doi = most_recent)\n\nLoading data from 'data/austraits/austraits-6.0.0.rds'\n\n\nExtract leaf mass per area (LMA) data\n\n# You can use `lookup_trait()` to search for traits containing keywords\naustraits::lookup_trait(austraits, \"leaf_mass\")\n\n[1] \"leaf_mass_per_area\"           \"leaf_mass_fraction\"          \n[3] \"leaf_mass_to_stem_mass_ratio\"\n\n# Get trait data\nleaf_mass &lt;- austraits %&gt;%\n  austraits::extract_trait(\"leaf_mass_per_area\") %&gt;%\n  purrr::pluck(\"traits\") # Grab the traits table from the list of austraits tables\n\nFilter to six species in the dataset\n\nsample_names &lt;- c(\"Cryptocarya rigida\", \"Pteridium esculentum\",\n                  \"Eucalyptus baxteri\", \"Melaleuca armillaris\",\n                  \"Eucalyptus wandoo\", \"Eucalyptus piperita\")\n\nleaf_mass_sample &lt;- leaf_mass %&gt;% dplyr::filter(taxon_name %in% sample_names)\n\nPlot raincloud plot of LMA for the six species\n\n# install.packages(c(\"ggdist\", \"gghalves\", \"ggtext\"))\n# remotes::install_github(\"olihawkins/pilot\")\nlibrary(ggplot2)\nlibrary(ggdist)\nlibrary(gghalves)\nlibrary(ggtext)\nlibrary(pilot)\n\nggplot2::ggplot(\n  data = leaf_mass_sample,\n  aes(x = taxon_name %&gt;% stringr::str_wrap(10) %&gt;% reorder(value),\n      y = value,\n      colour = taxon_name,\n      fill = taxon_name)\n) +\n  ggdist::stat_halfeye(\n    adjust = .4,\n    width = .87,\n    colour = NA) +\n  gghalves::geom_half_point(\n    side = \"l\",\n    range_scale = .3,\n    alpha = .6,\n    size = 2.2) +\n  geom_boxplot(\n    aes(colour = taxon_name,\n        colour = after_scale(colorspace::darken(colour, .7))),\n    width = .12, # Adjust box width\n    fill = NA,\n    size = 1.1, # Size of box line\n    outlier.shape = NA # Remove outlier points\n  ) +\n  coord_flip() +\n  labs(\n    x = \"Species\",\n    y = \"Leaf mass per area (g/m&lt;sup&gt;2&lt;/sup&gt;)\") +\n  scale_y_continuous(\n    breaks = c(0, 100, 200, 300, 400),\n    labels = c(0, 100, 200, 300, 400),\n    limits = c(0, 400),\n    expand = c(0,0)) +\n  pilot::scale_color_pilot() +\n  pilot::scale_fill_pilot() +\n  pilot::theme_pilot(\n    grid = \"\",\n    axes = \"b\") +\n  theme(\n    legend.position = \"none\",\n    axis.title.x = ggtext::element_markdown(),\n    axis.text.y = element_text(face = \"italic\"))\n\nPlot the species distributions of these six species with ALA occurrence data (using galah)\n\n# install.packages(c(\"galah\", \"sf\", \"ozmaps\"))\nlibrary(galah)\nlibrary(sf)\nlibrary(ozmaps)\n\n# Configurate `galah` to use an email that has been registered with the ALA (https://auth.ala.org.au/userdetails/registration/createAccount)\n#galah_config(email = \"XXX@gmail.com\", verbose = FALSE)\n\n# Download data\n#plants &lt;- galah_call() %&gt;%\n#  galah_identify(sample_names) %&gt;%\n#  galah_apply_profile(ALA) %&gt;%\n#  atlas_occurrences()\nplants &lt;- readr::read_csv(\"data/plants.csv\")\n\n# Recategorise subspecies into species categories\nplants &lt;- plants %&gt;%\n  drop_na(decimalLatitude, decimalLatitude) %&gt;%\n  mutate(names = case_when(\n    str_detect(scientificName, \"Eucalyptus wandoo\") ~ \"Eucalyptus wandoo\",\n    str_detect(scientificName, \"Pentameris airoides\") ~ \"Pentameris airoides\",\n    str_detect(scientificName, \"Melaleuca armillaris\") ~ \"Melaleuca armillaris\",\n    str_detect(scientificName, \"Pteridium esculentum\") ~ \"Pteridium esculentum\",\n    .default = scientificName)\n  )\n\n# Join median LMAs for each species to `plants` tibble\nplants_lma &lt;- leaf_mass_sample %&gt;%\n  group_by(taxon_name) %&gt;%\n  summarise(median_lma = median(value) %&gt;% round(1)) %&gt;%\n  right_join(plants, by = join_by(taxon_name == scientificName)) %&gt;%\n  rename(scientificName = taxon_name) %&gt;%\n  drop_na(median_lma) # Remove NAs for unmatched subspecies\n\n# Australia map\naus &lt;- ozmaps::ozmap_country %&gt;%\n  st_transform(crs = st_crs(4326))\n\n# Map points\nggplot() +\n  geom_sf(\n    data = aus,\n    colour = \"grey60\",\n    fill = NA) +\n  geom_point(\n    data = plants_lma,\n    aes(x = decimalLongitude,\n        y = decimalLatitude,\n        colour = names),\n    shape = 16,\n    alpha = 0.4) +\n  pilot::scale_color_pilot() +\n  pilot::theme_pilot() +\n  coord_sf(\n    xlim = c(110, 155),\n    ylim = c(-45, -10)) +\n  facet_wrap(~ names, ncol = 3) +\n  geom_text(\n    data = plants_lma,\n    mapping = aes(x = 116, y = -11,\n                  label = glue::glue(\"LMA = {median_lma}\"),\n                  group = names),\n    colour = \"grey40\",\n    family = theme_get()$text$family, # use theme settings\n    size = 3.5,\n    lineheight = 0.92) +\n  theme(\n    legend.position = \"none\",\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    axis.text.x = element_blank(),\n    axis.text.y = element_blank(),\n    panel.border = element_rect(\n      linewidth = 1,\n      colour = \"grey90\",\n      fill = NA)\n  )",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Analysis example: Using AusTraits with spatial data</span>"
    ]
  },
  {
    "objectID": "austraits_package.html",
    "href": "austraits_package.html",
    "title": "33  The austraits package",
    "section": "",
    "text": "33.1 Getting started\nThe austraits package was initially designed to aid users in accessing data from AusTraits, a curated plant trait database for the Australian flora. This package contains several core functions to explore, wrangle and visualise data.\nIn 2024 the package was generalised to support all databases built using the traits.build workflow, new functions were added, and existing functions were re-worked. The structure of AusTraits evolved from its release in 2021 until present and the version 3.0 of the austraits package only supports AusTraits versions from 5.0 onwards. If you are working with AusTraits version 4.2.0 or earlier, you need to install an old version of austraits\nBelow, we include a tutorial to illustrate how to use these functions.\nNote the examples shown us a subset of AusTraits release 5.0.0, but the code can be run using any traits.build database.\naustraits is still under development and not yet on Cran. To install the current version from GitHub:\n#install.packages(\"remotes\")\n#remotes::install_github(\"traitecoevo/austraits\", dependencies = TRUE, upgrade = \"ask\")\n\n## Load the austraits package\nlibrary(austraits)",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>The `austraits` package</span>"
    ]
  },
  {
    "objectID": "austraits_package.html#getting-started",
    "href": "austraits_package.html#getting-started",
    "title": "33  The austraits package",
    "section": "",
    "text": "Loading AusTraits database\nload_austraits is the one austraits function that is specific to the AusTraits database. By default, load_austraits will download AusTraits to a specified path e.g. data/austraits and will reload it from this location in the future. You can set update = TRUE so the austrait versions are downloaded fresh from Zenodo. Note that load_austraits accepts a version number or the DOI of a particular version.\nIf you are new to using AusTraits we recommend you download the most recent release, while you may want to download an older version to reproduce a previous analysis.\n\naustraits &lt;- load_austraits(version = \"6.0.0\", path = \"data/austraits\")\n\nYou can check out the different versions of Austraits and their associated DOI by using:\n\nget_versions(path = \"data/austraits\")\n\nThe traits.build object is a very long list with various of elements. If you are not familiar with working with lists in R, we recommend having a quick look at this tutorial. To learn more about the structure of a traits.build database, check out the structure of the database.\n\naustraits",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>The `austraits` package</span>"
    ]
  },
  {
    "objectID": "austraits_package.html#descriptive-summaries-of-traits-and-taxa",
    "href": "austraits_package.html#descriptive-summaries-of-traits-and-taxa",
    "title": "33  The austraits package",
    "section": "33.2 Descriptive summaries of traits and taxa",
    "text": "33.2 Descriptive summaries of traits and taxa\nThe perfect way to begin exploring a traits.build database is to learn which traits are included and how much data exists for various traits and taxa.\nInterested in a specific trait? lookup_trait, lookup_location_property and lookup_context_property let you find terms based on exact and partial string matches.\n\nlookup_trait(database = austraits, term = \"leaf\") %&gt;% head()\n\n#&gt; [1] \"leaf_compoundness\"                   \"leaf_length\"                        \n#&gt; [3] \"leaf_phenology\"                      \"leaf_width\"                         \n#&gt; [5] \"leaf_delta13C\"                       \"leaf_water_use_efficiency_intrinsic\"\n\nlookup_location_property(database = austraits, term = \"temperature\") %&gt;% head()\n\n#&gt; [1] \"temperature, MAT (C)\"         \"temperature, max MAT (C)\"    \n#&gt; [3] \"temperature, min MAT (C)\"     \"temperature, summer mean (C)\"\n#&gt; [5] \"temperature, winter mean (C)\" \"temperature, monthly max (C)\"\n\nlookup_context_property(database = austraits, term = \"fire\") %&gt;% head()\n\n#&gt; [1] \"fire history\"   \"fire severity\"  \"fire intensity\" \"fire season\"\n\n\nAlternatively, have a look how much data a traits.build database has for specific traits or taxa. This function only summarises by trait_name, genus or family.\n\nsummarise_database(database = austraits, var = \"trait_name\") %&gt;% head()\n\n#&gt; # A tibble: 6 × 5\n#&gt;   trait_name                    n_records n_dataset n_taxa percent_total\n#&gt;   &lt;chr&gt;                             &lt;int&gt;     &lt;int&gt;  &lt;int&gt;         &lt;dbl&gt;\n#&gt; 1 atmospheric_CO2_concentration       217         1     17       0.00188\n#&gt; 2 bark_C_per_dry_mass                 159         1     17       0.00137\n#&gt; 3 bark_N_per_dry_mass                 159         1     17       0.00137\n#&gt; 4 bark_delta13C                       159         1     17       0.00137\n#&gt; 5 bark_delta15N                       159         1     17       0.00137\n#&gt; 6 bark_thickness                      198         2     17       0.00171\n\nsummarise_database(database = austraits, var =  \"family\") %&gt;% head()\n\n#&gt; # A tibble: 6 × 5\n#&gt;   family        n_records n_dataset n_taxa percent_total\n#&gt;   &lt;chr&gt;             &lt;int&gt;     &lt;int&gt;  &lt;int&gt;         &lt;dbl&gt;\n#&gt; 1 Acanthaceae         177         1     14    0.00153   \n#&gt; 2 Achariaceae          38         2      2    0.000328  \n#&gt; 3 Actinidiaceae        13         1      1    0.000112  \n#&gt; 4 Agapanthaceae         9         1      1    0.0000778 \n#&gt; 5 Akaniaceae           18         2      1    0.000156  \n#&gt; 6 Alismataceae          1         1      1    0.00000864\n\nsummarise_database(database = austraits, var =  \"genus\") %&gt;% head()\n\n#&gt; # A tibble: 6 × 5\n#&gt;   genus       n_records n_dataset n_taxa percent_total\n#&gt;   &lt;chr&gt;           &lt;int&gt;     &lt;int&gt;  &lt;int&gt;         &lt;dbl&gt;\n#&gt; 1 Abroma             13         1      1     0.000112 \n#&gt; 2 Abrophyllum        13         1      1     0.000112 \n#&gt; 3 Abrus               9         2      1     0.0000778\n#&gt; 4 Abutilon           91         1      7     0.000786 \n#&gt; 5 Acacia           4350        13    121     0.0376   \n#&gt; 6 Acalypha           65         1      5     0.000562\n\n\nAll traits.build databases include definitions for all traits. Check out the dictionary if you want to learn more about trait’s that have been output by a lookup_ or summarise_ query.\n\naustraits$definitions %&gt;% head()\n\n#&gt; $accessory_cost_fraction\n#&gt; $accessory_cost_fraction$label\n#&gt; [1] \"Seed accessory cost fraction\"\n#&gt; \n#&gt; $accessory_cost_fraction$description\n#&gt; [1] \"A reproductive shoot system [PO:0025082] biomass allocation [EnvThes:21360] trait which is one minus the ratio [PATO:0001470] of total plant seed [PO:0009010] dry [PATO:0001824] mass [PATO:0000125] to total plant reproductive shoot system tissue dry mass where reproductive tissues include all flower buds [PO:0000056], flowers [PO:0009046], fruits [PO:0009001], dispersal [EnvThes:21038] tissues, and seeds produced during the developmental process involved in reproduction [GO:0003006].;The fraction of total reproductive investment required to mature a seed that is invested in non-seed tissues. It is calculated as one minus, the ratio of total biomass investment in seeds to total biomass investment in all reproductive tissues, including flower buds, flowers, fruits, dispersal tissues, aborted seeds, and successfully matured seeds.\"\n#&gt; \n#&gt; $accessory_cost_fraction$type\n#&gt; [1] \"numeric\"\n#&gt; \n#&gt; $accessory_cost_fraction$units\n#&gt; [1] \"mg/mg\"\n#&gt; \n#&gt; $accessory_cost_fraction$allowed_values_min\n#&gt; [1] 0.01\n#&gt; \n#&gt; $accessory_cost_fraction$allowed_values_max\n#&gt; [1] 1\n#&gt; \n#&gt; $accessory_cost_fraction$entity_URI\n#&gt; [1] \"https://w3id.org/APD/traits/trait_0012221\"\n#&gt; \n#&gt; \n#&gt; $accessory_cost_mass\n#&gt; $accessory_cost_mass$label\n#&gt; [1] \"Seed accessory cost mass\"\n#&gt; \n#&gt; $accessory_cost_mass$description\n#&gt; [1] \"A reproductive shoot system [PO:0025082] biomass allocation [EnvThes:21360] trait which is the sum of the dry [PATO:0001824] mass [PATO:0000125] of all flower buds [PO:0000056], flowers [PO:0009046], fruits [PO:0009001], aborted seeds, and dispersal [EnvThes:21038] tissues produced during the developmental process involved in reproduction [GO:0003006], but excludes mature [PATO:0001701] seed [PO:0009010] dry mass.;The mass of seed accessory costs, which is the total biomass investment in all reproductive tissues, excluding biomass invested in successfully matured seeds; it includes all biomass invested in flower buds, flowers, fruits, dispersal tissues and aborted seeds.\"\n#&gt; \n#&gt; $accessory_cost_mass$type\n#&gt; [1] \"numeric\"\n#&gt; \n#&gt; $accessory_cost_mass$units\n#&gt; [1] \"mg\"\n#&gt; \n#&gt; $accessory_cost_mass$allowed_values_min\n#&gt; [1] 0.01\n#&gt; \n#&gt; $accessory_cost_mass$allowed_values_max\n#&gt; [1] 10000\n#&gt; \n#&gt; $accessory_cost_mass$entity_URI\n#&gt; [1] \"https://w3id.org/APD/traits/trait_0012222\"\n#&gt; \n#&gt; \n#&gt; $atmospheric_CO2_concentration\n#&gt; $atmospheric_CO2_concentration$label\n#&gt; [1] \"Ambient CO2 concentration (ca)\"\n#&gt; \n#&gt; $atmospheric_CO2_concentration$description\n#&gt; [1] \"The atmospheric carbon dioxide [ENVO:01000451] concentration [PATO:0000033].;Atmospheric CO2 concentration (external CO2 concentration); ca.\"\n#&gt; \n#&gt; $atmospheric_CO2_concentration$comments\n#&gt; [1] \"This is not a trait itself, but will often be used to calculate traits related to photosynthetic rates and therefore is recorded.\"\n#&gt; \n#&gt; $atmospheric_CO2_concentration$type\n#&gt; [1] \"numeric\"\n#&gt; \n#&gt; $atmospheric_CO2_concentration$units\n#&gt; [1] \"umol{CO2}/mol\"\n#&gt; \n#&gt; $atmospheric_CO2_concentration$allowed_values_min\n#&gt; [1] 50\n#&gt; \n#&gt; $atmospheric_CO2_concentration$allowed_values_max\n#&gt; [1] 2000\n#&gt; \n#&gt; $atmospheric_CO2_concentration$entity_URI\n#&gt; [1] \"https://w3id.org/APD/traits/trait_0020315\"\n#&gt; \n#&gt; \n#&gt; $bark_Al_per_dry_mass\n#&gt; $bark_Al_per_dry_mass$label\n#&gt; [1] \"Bark aluminium (Al) content per unit bark dry mass\"\n#&gt; \n#&gt; $bark_Al_per_dry_mass$description\n#&gt; [1] \"The ratio [PATO:0001470] of the mass [PATO:0000125] of aluminium [CHEBI:28984] in bark [PO:0004518] to bark dry mass.\"\n#&gt; \n#&gt; $bark_Al_per_dry_mass$type\n#&gt; [1] \"numeric\"\n#&gt; \n#&gt; $bark_Al_per_dry_mass$units\n#&gt; [1] \"mg/g\"\n#&gt; \n#&gt; $bark_Al_per_dry_mass$allowed_values_min\n#&gt; [1] 0.01\n#&gt; \n#&gt; $bark_Al_per_dry_mass$allowed_values_max\n#&gt; [1] 10\n#&gt; \n#&gt; $bark_Al_per_dry_mass$entity_URI\n#&gt; [1] \"https://w3id.org/APD/traits/trait_0000612\"\n#&gt; \n#&gt; \n#&gt; $bark_ash_per_dry_mass\n#&gt; $bark_ash_per_dry_mass$label\n#&gt; [1] \"Bark ash content per unit bark dry mass\"\n#&gt; \n#&gt; $bark_ash_per_dry_mass$description\n#&gt; [1] \"The ratio [PATO:0001470] of the mass [PATO:0000125] of bark [PO:0004518] ash [ENVO:02000090] remaining after a combustion process [ENVO:01000839] to the bark dry mass before the combustion process.\"\n#&gt; \n#&gt; $bark_ash_per_dry_mass$type\n#&gt; [1] \"numeric\"\n#&gt; \n#&gt; $bark_ash_per_dry_mass$units\n#&gt; [1] \"g/g\"\n#&gt; \n#&gt; $bark_ash_per_dry_mass$allowed_values_min\n#&gt; [1] 1e-04\n#&gt; \n#&gt; $bark_ash_per_dry_mass$allowed_values_max\n#&gt; [1] 1\n#&gt; \n#&gt; $bark_ash_per_dry_mass$entity_URI\n#&gt; [1] \"https://w3id.org/APD/traits/trait_0002824\"\n#&gt; \n#&gt; \n#&gt; $bark_B_per_dry_mass\n#&gt; $bark_B_per_dry_mass$label\n#&gt; [1] \"Bark boron (B) content per unit bark dry mass\"\n#&gt; \n#&gt; $bark_B_per_dry_mass$description\n#&gt; [1] \"The ratio [PATO:0001470] of the mass [PATO:0000125] of boron [CHEBI:27560] in bark [PO:0004518] to bark dry mass.\"\n#&gt; \n#&gt; $bark_B_per_dry_mass$type\n#&gt; [1] \"numeric\"\n#&gt; \n#&gt; $bark_B_per_dry_mass$units\n#&gt; [1] \"mg/g\"\n#&gt; \n#&gt; $bark_B_per_dry_mass$allowed_values_min\n#&gt; [1] 0.001\n#&gt; \n#&gt; $bark_B_per_dry_mass$allowed_values_max\n#&gt; [1] 1\n#&gt; \n#&gt; $bark_B_per_dry_mass$entity_URI\n#&gt; [1] \"https://w3id.org/APD/traits/trait_0000614\"\n\naustraits$definitions[[\"leaf_area\"]] %&gt;% convert_list_to_df1\n\n#&gt; # A tibble: 8 × 2\n#&gt;   key                value                                                      \n#&gt;   &lt;chr&gt;              &lt;chr&gt;                                                      \n#&gt; 1 label              Leaf area                                                  \n#&gt; 2 description        A leaf area trait [TO:0000540] which is the 2-D [PATO:0001…\n#&gt; 3 comments           This trait includes measurements of leaves and leaf analog…\n#&gt; 4 type               numeric                                                    \n#&gt; 5 units              mm2                                                        \n#&gt; 6 allowed_values_min 0.1                                                        \n#&gt; 7 allowed_values_max 1e+07                                                      \n#&gt; 8 entity_URI         https://w3id.org/APD/traits/trait_0011211",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>The `austraits` package</span>"
    ]
  },
  {
    "objectID": "austraits_package.html#extracting-data",
    "href": "austraits_package.html#extracting-data",
    "title": "33  The austraits package",
    "section": "33.3 Extracting data",
    "text": "33.3 Extracting data\nIn most cases, users would like to extract a subset of a traits.build database for their own research purposes.extract_dataset subsets by dataset(s), extract_traitsubsets by trait, and extract_taxa subsets by taxon_name, genus or family. In addition, the function extract_data extracts data based on a specified value(s) from any column of any table within a traits.build database.\nNote that the other tables and elements of the AusTraits data are extracted too, not just the main traits table, retaining the database’s original structure. See ?extract_data and ?extract_trait for more details.\n\nExtracting by study\nFiltering one particular study and assigning it to an object\n\nsubset_data &lt;- extract_dataset(database = austraits, dataset_id = \"Falster_2005_2\")\n\nsubset_data$traits %&gt;% head()\n\n#&gt; # A tibble: 6 × 26\n#&gt;   dataset_id     taxon_name    observation_id trait_name value unit  entity_type\n#&gt;   &lt;chr&gt;          &lt;chr&gt;         &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n#&gt; 1 Falster_2005_2 Acacia longi… 01             huber_val… 0.00… mm2{… population \n#&gt; 2 Falster_2005_2 Acacia longi… 01             huber_val… 0.00… mm2{… population \n#&gt; 3 Falster_2005_2 Acacia longi… 01             huber_val… 0.00… mm2{… population \n#&gt; 4 Falster_2005_2 Acacia longi… 01             huber_val… 0.00… mm2{… population \n#&gt; 5 Falster_2005_2 Acacia longi… 01             leaf_N_pe… 23.2  mg/g  population \n#&gt; 6 Falster_2005_2 Acacia longi… 01             leaf_area  1761  mm2   population \n#&gt; # ℹ 19 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#&gt; #   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#&gt; #   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#&gt; #   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#&gt; #   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#&gt; #   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;,\n#&gt; #   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;\n\n\nFiltering multiple studies by two different lead authors and assigning it to an object\n\nsubset_multi_studies &lt;- extract_dataset(database = austraits, \n                                        dataset_id = c(\"Thompson_2001\",\"Ilic_2000\"))\n \nsubset_multi_studies$traits %&gt;% distinct(dataset_id)\n\n#&gt; # A tibble: 0 × 1\n#&gt; # ℹ 1 variable: dataset_id &lt;chr&gt;\n\n\nFiltering multiple studies by same lead author (e.g. Falster) and assigning it to an object.\n\ndata_falster_studies &lt;- extract_dataset(austraits, \"Falster\")\n\ndata_falster_studies$traits %&gt;% distinct(dataset_id)\n\n#&gt; # A tibble: 3 × 1\n#&gt;   dataset_id    \n#&gt;   &lt;chr&gt;         \n#&gt; 1 Falster_2003  \n#&gt; 2 Falster_2005_1\n#&gt; 3 Falster_2005_2\n\n\n\n\nExtracting by taxonomic level\nFiltering\n\n# By family \nproteaceae &lt;- extract_taxa(austraits, family = \"Proteaceae\")\n# Checking that only taxa in Proteaceae have been extracted\nproteaceae$taxa$family %&gt;% unique()\n\n#&gt; [1] \"Proteaceae\"\n\n# By genus \nacacia &lt;- extract_taxa(austraits, genus = \"Acacia\")\n# Checking that only taxa in Acacia have been extracted\nacacia$traits$taxon_name %&gt;% unique() %&gt;% head()\n\n#&gt; [1] \"Acacia aneura\"         \"Acacia dealbata\"       \"Acacia dictyophleba\"  \n#&gt; [4] \"Acacia hemiteles\"      \"Acacia melanoxylon\"    \"Acacia parramattensis\"\n\n\n\n\nExtracting by trait\nFiltering one trait and assigning it to an object\n\ndata_wood_dens &lt;- extract_trait(austraits, \"wood_density\")\n\nhead(data_wood_dens$traits)\n\n#&gt; # A tibble: 6 × 26\n#&gt;   dataset_id  taxon_name       observation_id trait_name value unit  entity_type\n#&gt;   &lt;chr&gt;       &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n#&gt; 1 Apgaua_2017 Aglaia meridion… 001            wood_dens… 0.64… mg/m… individual \n#&gt; 2 Apgaua_2017 Aleurites rocki… 003            wood_dens… 0.50… mg/m… individual \n#&gt; 3 Apgaua_2017 Alphitonia petr… 005            wood_dens… 0.62… mg/m… individual \n#&gt; 4 Apgaua_2017 Alstonia schola… 007            wood_dens… 0.361 mg/m… individual \n#&gt; 5 Apgaua_2017 Amaracarpus nem… 009            wood_dens… 0.59… mg/m… individual \n#&gt; 6 Apgaua_2017 Antirhea tenuif… 013            wood_dens… 0.53… mg/m… individual \n#&gt; # ℹ 19 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#&gt; #   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#&gt; #   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#&gt; #   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#&gt; #   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#&gt; #   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;,\n#&gt; #   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;\n\n\nUsing extract_trait to extract data for all traits with ‘leaf’ in the trait name and assigning it to an object.\n\ndata_leaf &lt;- extract_trait(austraits, \"leaf\") \n\nunique(data_leaf$traits$trait_name)\n\n#&gt;  [1] \"leaf_compoundness\"                                                          \n#&gt;  [2] \"leaf_length\"                                                                \n#&gt;  [3] \"leaf_phenology\"                                                             \n#&gt;  [4] \"leaf_width\"                                                                 \n#&gt;  [5] \"leaf_delta13C\"                                                              \n#&gt;  [6] \"leaf_water_use_efficiency_intrinsic\"                                        \n#&gt;  [7] \"leaf_NP_ratio\"                                                              \n#&gt;  [8] \"leaf_N_per_area\"                                                            \n#&gt;  [9] \"leaf_N_per_dry_mass\"                                                        \n#&gt; [10] \"leaf_P_per_area\"                                                            \n#&gt; [11] \"leaf_P_per_dry_mass\"                                                        \n#&gt; [12] \"leaf_dark_respiration_per_area\"                                             \n#&gt; [13] \"leaf_dark_respiration_per_dry_mass\"                                         \n#&gt; [14] \"leaf_dry_matter_content\"                                                    \n#&gt; [15] \"leaf_intercellular_CO2_concentration_at_Amax\"                               \n#&gt; [16] \"leaf_intercellular_CO2_concentration_at_Asat\"                               \n#&gt; [17] \"leaf_intercellular_CO2_concentration_to_atmospheric_CO2_concentration_ratio\"\n#&gt; [18] \"leaf_mass_per_area\"                                                         \n#&gt; [19] \"leaf_photosynthetic_nitrogen_use_efficiency_saturated\"                      \n#&gt; [20] \"leaf_photosynthetic_phosphorus_use_efficiency_saturated\"                    \n#&gt; [21] \"leaf_photosynthetic_rate_per_area_maximum\"                                  \n#&gt; [22] \"leaf_photosynthetic_rate_per_area_saturated\"                                \n#&gt; [23] \"leaf_photosynthetic_rate_per_dry_mass_maximum\"                              \n#&gt; [24] \"leaf_photosynthetic_rate_per_dry_mass_saturated\"                            \n#&gt; [25] \"leaf_transpiration_per_area_at_Asat\"                                        \n#&gt; [26] \"leaf_water_use_efficiency_instantaneous\"                                    \n#&gt; [27] \"leaf_stomatal_conductance_per_area_at_Amax\"                                 \n#&gt; [28] \"leaf_stomatal_conductance_per_area_at_Asat\"                                 \n#&gt; [29] \"leaf_transpiration_per_area_at_Amax\"                                        \n#&gt; [30] \"leaf_dark_transpiration_per_area\"                                           \n#&gt; [31] \"leaf_CN_ratio\"                                                              \n#&gt; [32] \"leaf_C_per_dry_mass\"                                                        \n#&gt; [33] \"leaf_delta15N\"                                                              \n#&gt; [34] \"leaf_area\"                                                                  \n#&gt; [35] \"leaf_dry_mass\"                                                              \n#&gt; [36] \"leaf_fresh_mass\"                                                            \n#&gt; [37] \"leaf_thickness\"                                                             \n#&gt; [38] \"leaf_photosynthetic_rate_per_area_ambient\"                                  \n#&gt; [39] \"leaf_stomatal_conductance_per_area_ambient\"                                 \n#&gt; [40] \"leaf_transpiration_per_area_ambient\"                                        \n#&gt; [41] \"leaf_specific_hydraulic_conductivity\"                                       \n#&gt; [42] \"leaf_light_respiration_per_area\"                                            \n#&gt; [43] \"leaf_photosynthesis_Jmax_per_area\"                                          \n#&gt; [44] \"leaf_photosynthesis_Jmax_per_area_25C\"                                      \n#&gt; [45] \"leaf_photosynthesis_Vcmax_per_area\"                                         \n#&gt; [46] \"leaf_senesced_N_per_dry_mass\"                                               \n#&gt; [47] \"leaf_senesced_P_per_dry_mass\"                                               \n#&gt; [48] \"leaf_inclination_angle\"                                                     \n#&gt; [49] \"leaf_B_per_dry_mass\"                                                        \n#&gt; [50] \"leaf_Ca_per_dry_mass\"                                                       \n#&gt; [51] \"leaf_Cu_per_dry_mass\"                                                       \n#&gt; [52] \"leaf_Fe_per_dry_mass\"                                                       \n#&gt; [53] \"leaf_K_per_dry_mass\"                                                        \n#&gt; [54] \"leaf_Mg_per_dry_mass\"                                                       \n#&gt; [55] \"leaf_Mn_per_dry_mass\"                                                       \n#&gt; [56] \"leaf_Na_per_dry_mass\"                                                       \n#&gt; [57] \"leaf_S_per_dry_mass\"                                                        \n#&gt; [58] \"leaf_Zn_per_dry_mass\"                                                       \n#&gt; [59] \"leaf_lobation\"                                                              \n#&gt; [60] \"leaf_chlorophyll_per_area\"                                                  \n#&gt; [61] \"leaf_mass_to_stem_mass_ratio\"                                               \n#&gt; [62] \"leaf_chlorophyll_per_dry_mass\"                                              \n#&gt; [63] \"leaf_density\"                                                               \n#&gt; [64] \"leaf_water_content_per_dry_mass\"                                            \n#&gt; [65] \"leaf_water_content_per_fresh_mass\"                                          \n#&gt; [66] \"leaf_lifespan\"                                                              \n#&gt; [67] \"leaf_specific_hydraulic_conductance\"                                        \n#&gt; [68] \"leaf_vessel_density\"                                                        \n#&gt; [69] \"leaf_vessel_diameter\"                                                       \n#&gt; [70] \"leaf_Mo_per_dry_mass\"                                                       \n#&gt; [71] \"leaf_Al_per_dry_mass\"                                                       \n#&gt; [72] \"leaf_mass_fraction\"\n\n\nUsing extract_trait to extract data for all traits with ‘leaf_N’ or ‘leaf_P’ in the trait name and assigning it to an object.\n\ndata_vector_extraction &lt;- extract_trait(austraits, c(\"leaf_photosyn\", \"huber_value\")) \n\nunique(data_vector_extraction$traits$trait_name)\n\n#&gt;  [1] \"leaf_photosynthetic_nitrogen_use_efficiency_saturated\"  \n#&gt;  [2] \"leaf_photosynthetic_phosphorus_use_efficiency_saturated\"\n#&gt;  [3] \"leaf_photosynthetic_rate_per_area_maximum\"              \n#&gt;  [4] \"leaf_photosynthetic_rate_per_area_saturated\"            \n#&gt;  [5] \"leaf_photosynthetic_rate_per_dry_mass_maximum\"          \n#&gt;  [6] \"leaf_photosynthetic_rate_per_dry_mass_saturated\"        \n#&gt;  [7] \"huber_value\"                                            \n#&gt;  [8] \"leaf_photosynthetic_rate_per_area_ambient\"              \n#&gt;  [9] \"leaf_photosynthesis_Jmax_per_area\"                      \n#&gt; [10] \"leaf_photosynthesis_Jmax_per_area_25C\"                  \n#&gt; [11] \"leaf_photosynthesis_Vcmax_per_area\"\n\n\nThe function extract_data offers the flexibility of subsetting a database based on any combination of data table, column within the table, and column value.\nThe database tables you can subset on are: ‘traits’, ‘locations’, ‘contexts’, ‘methods’, ‘contributors’, ‘taxa’, and ‘taxonomic_updates’\n\nobservations_with_soil_data &lt;- extract_data(\n  database = austraits, \n  table = \"locations\",\n  col = \"location_property\",\n  col_value = \"soil\") \n\n# If you are unsure about column names, check with:\n\nnames(austraits$methods)\n\n#&gt;  [1] \"dataset_id\"                       \"trait_name\"                      \n#&gt;  [3] \"methods\"                          \"method_id\"                       \n#&gt;  [5] \"description\"                      \"sampling_strategy\"               \n#&gt;  [7] \"source_primary_key\"               \"source_primary_citation\"         \n#&gt;  [9] \"source_secondary_key\"             \"source_secondary_citation\"       \n#&gt; [11] \"source_original_dataset_key\"      \"source_original_dataset_citation\"\n#&gt; [13] \"data_collectors\"                  \"assistants\"                      \n#&gt; [15] \"dataset_curators\"\n\n\nAny of the extract functions can be linked together to output a more precise subset of data.\nFor instance, to return data on ‘leaf mass per area’ and ‘wood density’ for ‘adult’ plants of any species in the genus Acacia:\n\nAcacias_specific_traits &lt;- austraits %&gt;% \n  extract_taxa(genus = \"Acacia\") %&gt;%\n  extract_trait(trait_name = c(\"leaf_mass_per_area\", \"wood_density\")) %&gt;%\n  extract_data(table = \"traits\", col = \"life_stage\", col_value = \"adult\")",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>The `austraits` package</span>"
    ]
  },
  {
    "objectID": "austraits_package.html#join-data-from-other-tables-and-elements",
    "href": "austraits_package.html#join-data-from-other-tables-and-elements",
    "title": "33  The austraits package",
    "section": "33.4 Join data from other tables and elements",
    "text": "33.4 Join data from other tables and elements\nOnce users have extracted the data they want, they may want to merge the study metadata stored in various relational tables into the main traits dataframe for their analyses. For example, users may require additional taxonomic information for a phylogenetic analysis, location coordinates to plot data, or context properties to understand variation in trait values for a single taxon. This is where the join_ functions come in.\nThere are seven join_ functions in total, each designed to append specific information from other tables and elements in the austraitsthe ancillary data tables in a traits.build object. Their suffixes refer to the type of information that is joined, e.g. join_taxonomy appends taxonomic information to the traits dataframe. Each function lets you select which data columns you wish to add and the output format.\n\n# Join location coordinates\n(data_leaf %&gt;% join_location_coordinates)$traits %&gt;% head()\n\n#&gt; # A tibble: 6 × 29\n#&gt;   dataset_id taxon_name        observation_id trait_name value unit  entity_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;             &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n#&gt; 1 ABRS_1981  Acanthocarpus ca… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 2 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 3     mm    species    \n#&gt; 3 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 15    mm    species    \n#&gt; 4 ABRS_1981  Acanthocarpus hu… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 5 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 4     mm    species    \n#&gt; 6 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 12    mm    species    \n#&gt; # ℹ 22 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#&gt; #   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#&gt; #   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#&gt; #   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#&gt; #   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#&gt; #   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;,\n#&gt; #   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;, location_name &lt;chr&gt;, …\n\n# Join location properties using defaults\n(data_leaf %&gt;% join_location_properties)$traits %&gt;% head()\n\n#&gt; # A tibble: 6 × 28\n#&gt;   dataset_id taxon_name        observation_id trait_name value unit  entity_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;             &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n#&gt; 1 ABRS_1981  Acanthocarpus ca… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 2 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 3     mm    species    \n#&gt; 3 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 15    mm    species    \n#&gt; 4 ABRS_1981  Acanthocarpus hu… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 5 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 4     mm    species    \n#&gt; 6 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 12    mm    species    \n#&gt; # ℹ 21 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#&gt; #   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#&gt; #   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#&gt; #   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#&gt; #   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#&gt; #   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;,\n#&gt; #   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;, location_name &lt;chr&gt;, …\n\n# Join location properties, with each location property pertaining to soil added as a separate column.\ntemperature_properties &lt;- lookup_location_property(data_leaf, \"temperature\")\n(data_leaf %&gt;% join_location_properties(format = \"many_columns\", vars = temperature_properties))$traits %&gt;% head()\n\n#&gt; # A tibble: 6 × 32\n#&gt;   dataset_id taxon_name        observation_id trait_name value unit  entity_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;             &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n#&gt; 1 ABRS_1981  Acanthocarpus ca… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 2 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 3     mm    species    \n#&gt; 3 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 15    mm    species    \n#&gt; 4 ABRS_1981  Acanthocarpus hu… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 5 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 4     mm    species    \n#&gt; 6 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 12    mm    species    \n#&gt; # ℹ 25 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#&gt; #   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#&gt; #   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#&gt; #   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#&gt; #   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#&gt; #   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;,\n#&gt; #   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;, location_name &lt;chr&gt;, …\n\n# Join context properties using defaults\n(data_leaf %&gt;% join_context_properties)$traits %&gt;% head()\n\n#&gt; # A tibble: 6 × 31\n#&gt;   dataset_id taxon_name        observation_id trait_name value unit  entity_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;             &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n#&gt; 1 ABRS_1981  Acanthocarpus ca… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 2 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 3     mm    species    \n#&gt; 3 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 15    mm    species    \n#&gt; 4 ABRS_1981  Acanthocarpus hu… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 5 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 4     mm    species    \n#&gt; 6 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 12    mm    species    \n#&gt; # ℹ 24 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#&gt; #   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#&gt; #   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#&gt; #   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#&gt; #   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#&gt; #   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;,\n#&gt; #   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;, …\n\n# Join context properties, with each context property pertaining to fire added as a separate column.\nfire_properties &lt;- lookup_context_property(data_leaf, \"fire\")\n(austraits %&gt;% join_context_properties(format = \"many_columns\", vars = fire_properties, include_description = TRUE))$traits %&gt;% head()\n\n#&gt; # A tibble: 6 × 27\n#&gt;   dataset_id taxon_name        observation_id trait_name value unit  entity_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;             &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n#&gt; 1 ABRS_1981  Acanthocarpus ca… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 2 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 3     mm    species    \n#&gt; 3 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 15    mm    species    \n#&gt; 4 ABRS_1981  Acanthocarpus ca… 0001           seed_heig… 3     mm    species    \n#&gt; 5 ABRS_1981  Acanthocarpus ca… 0001           seed_leng… 3     mm    species    \n#&gt; 6 ABRS_1981  Acanthocarpus ca… 0001           seed_width 3     mm    species    \n#&gt; # ℹ 20 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#&gt; #   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#&gt; #   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#&gt; #   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#&gt; #   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#&gt; #   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;,\n#&gt; #   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;, …\n\n# Join methodological information using defaults\n(data_leaf %&gt;% join_methods)$traits %&gt;% head()\n\n#&gt; # A tibble: 6 × 27\n#&gt;   dataset_id taxon_name        observation_id trait_name value unit  entity_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;             &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n#&gt; 1 ABRS_1981  Acanthocarpus ca… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 2 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 3     mm    species    \n#&gt; 3 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 15    mm    species    \n#&gt; 4 ABRS_1981  Acanthocarpus hu… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 5 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 4     mm    species    \n#&gt; 6 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 12    mm    species    \n#&gt; # ℹ 20 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#&gt; #   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#&gt; #   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#&gt; #   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#&gt; #   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#&gt; #   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;,\n#&gt; #   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;, methods &lt;chr&gt;\n\n# Join taxonomic information using defaults\n(data_leaf %&gt;% join_taxa)$traits %&gt;% head()\n\n#&gt; # A tibble: 6 × 30\n#&gt;   dataset_id taxon_name        observation_id trait_name value unit  entity_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;             &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n#&gt; 1 ABRS_1981  Acanthocarpus ca… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 2 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 3     mm    species    \n#&gt; 3 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 15    mm    species    \n#&gt; 4 ABRS_1981  Acanthocarpus hu… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 5 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 4     mm    species    \n#&gt; 6 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 12    mm    species    \n#&gt; # ℹ 23 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#&gt; #   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#&gt; #   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#&gt; #   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#&gt; #   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#&gt; #   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;,\n#&gt; #   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, …\n\n# Join taxonomic updates information using defaults\n(data_leaf %&gt;% join_taxonomic_updates)$traits %&gt;% head()\n\n#&gt; # A tibble: 6 × 27\n#&gt;   dataset_id taxon_name        observation_id trait_name value unit  entity_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;             &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n#&gt; 1 ABRS_1981  Acanthocarpus ca… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 2 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 3     mm    species    \n#&gt; 3 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 15    mm    species    \n#&gt; 4 ABRS_1981  Acanthocarpus hu… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 5 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 4     mm    species    \n#&gt; 6 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 12    mm    species    \n#&gt; # ℹ 20 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#&gt; #   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#&gt; #   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#&gt; #   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#&gt; #   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#&gt; #   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;,\n#&gt; #   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;, aligned_name &lt;chr&gt;\n\n# Join contributors information using defaults\n(data_leaf %&gt;% join_contributors)$traits %&gt;% head()\n\n#&gt; # A tibble: 6 × 27\n#&gt;   dataset_id taxon_name        observation_id trait_name value unit  entity_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;             &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n#&gt; 1 ABRS_1981  Acanthocarpus ca… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 2 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 3     mm    species    \n#&gt; 3 ABRS_1981  Acanthocarpus ca… 0001           leaf_leng… 15    mm    species    \n#&gt; 4 ABRS_1981  Acanthocarpus hu… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 5 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 4     mm    species    \n#&gt; 6 ABRS_1981  Acanthocarpus hu… 0002           leaf_leng… 12    mm    species    \n#&gt; # ℹ 20 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#&gt; #   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#&gt; #   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#&gt; #   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#&gt; #   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#&gt; #   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;,\n#&gt; #   method_context_id &lt;chr&gt;, original_name &lt;chr&gt;, data_contributors &lt;chr&gt;\n\n\nAll data tables can be merged with flatten_database, which calls each of the join_ functions.\n\n# Flatten database using defaults\nall_joined &lt;- data_leaf %&gt;% flatten_database()\n\n# Flatten database also accepts a list of vectors to specify which columns to include for each table\ndata_leaf %&gt;% flatten_database(\n                format = \"single_column_json\",\n                vars = list(\n                  location = \"all\",\n                  context = \"all\",\n                  contributors = \"all\",\n                  taxonomy = c(\"family\"),\n                  taxonomic_updates = c(\"aligned_name\"),\n                  methods = c(\"methods\"))\n)\n\n#&gt; # A tibble: 70,471 × 39\n#&gt;    dataset_id taxon_name       observation_id trait_name value unit  entity_type\n#&gt;    &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n#&gt;  1 ABRS_1981  Acanthocarpus c… 0001           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt;  2 ABRS_1981  Acanthocarpus c… 0001           leaf_leng… 3     mm    species    \n#&gt;  3 ABRS_1981  Acanthocarpus c… 0001           leaf_leng… 15    mm    species    \n#&gt;  4 ABRS_1981  Acanthocarpus h… 0002           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt;  5 ABRS_1981  Acanthocarpus h… 0002           leaf_leng… 4     mm    species    \n#&gt;  6 ABRS_1981  Acanthocarpus h… 0002           leaf_leng… 12    mm    species    \n#&gt;  7 ABRS_1981  Acanthocarpus p… 0003           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt;  8 ABRS_1981  Acanthocarpus p… 0003           leaf_leng… 3     mm    species    \n#&gt;  9 ABRS_1981  Acanthocarpus p… 0004           leaf_comp… simp… &lt;NA&gt;  species    \n#&gt; 10 ABRS_1981  Acanthocarpus p… 0004           leaf_leng… 20    mm    species    \n#&gt; # ℹ 70,461 more rows\n#&gt; # ℹ 32 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#&gt; #   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#&gt; #   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#&gt; #   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#&gt; #   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#&gt; #   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;, …",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>The `austraits` package</span>"
    ]
  },
  {
    "objectID": "austraits_package.html#binding-extracted-databases",
    "href": "austraits_package.html#binding-extracted-databases",
    "title": "33  The austraits package",
    "section": "33.5 Binding extracted databases",
    "text": "33.5 Binding extracted databases\nThe function bind_databases allows you to bind together two subsetted databases you have created by filtering (extract_ functions) based on two critera.\n\nextracted_wood &lt;- austraits %&gt;% extract_trait(\"wood_density\")\nextracted_Rutaceae &lt;- austraits %&gt;% extract_taxa(family = \"Rutaceae\")\nmerged &lt;- bind_databases(extracted_wood, extracted_Rutaceae)",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>The `austraits` package</span>"
    ]
  },
  {
    "objectID": "austraits_package.html#visualising-data-by-site",
    "href": "austraits_package.html#visualising-data-by-site",
    "title": "33  The austraits package",
    "section": "33.6 Visualising data by site",
    "text": "33.6 Visualising data by site\nplot_locations graphically summarises where trait data were collected and how much data is available. The legend refers to the number of neighbouring points: the warmer the colour, the more data that are available for a particular location. This function only includes data that are geo-referenced. Users must first use join_location_coordinates to append latitude and longitude information into the trait dataframe before plotting\n\ndata_wood_dens &lt;- data_wood_dens %&gt;% join_location_coordinates()\nplot_locations(data_wood_dens$traits)",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>The `austraits` package</span>"
    ]
  },
  {
    "objectID": "austraits_package.html#visualising-data-distribution-and-variance",
    "href": "austraits_package.html#visualising-data-distribution-and-variance",
    "title": "33  The austraits package",
    "section": "33.7 Visualising data distribution and variance",
    "text": "33.7 Visualising data distribution and variance\nplot_trait_distribution_beeswarm creates histograms and beeswarm plots for continuous traits to help users visualise the data. Users can specify whether to create separate beeswarm plots based on any column in the traits table (e.g. dataset_id or life_stage) or at the level of genus or family.\n\naustraits %&gt;% plot_trait_distribution_beeswarm(\"wood_density\", \"family\")\n\n\n\n\n\n\n\naustraits %&gt;% plot_trait_distribution_beeswarm(\"wood_density\", \"dataset_id\")",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>The `austraits` package</span>"
    ]
  },
  {
    "objectID": "austraits_package.html#pivotting-from-long-to-wide-format",
    "href": "austraits_package.html#pivotting-from-long-to-wide-format",
    "title": "33  The austraits package",
    "section": "33.8 Pivotting from long to wide format",
    "text": "33.8 Pivotting from long to wide format\nThe table of traits in AusTraits comes in long format, where data for all trait information are denoted by two columns called trait_name and value. You can convert this to wide format, where each trait is in a separate column, using the function trait_pivot_wider. Note, that the informtion in the columns unit, replicates, measurement_remarks, and basis_of_value is lost when this function pivots.\n\ndata_wide_bound &lt;- data_falster_studies %&gt;% # Joining multiple obs with `--`\n  trait_pivot_wider()\n\nIf there are multiple measurements linked to the same observation_id, such as when both a minimum and maximum are recorded, this information is retained as separate rows when using trait_pivot_wider. Instead, you can use bind_trait_values first, which merges multiple entries for value, value_type, basis_of_value, and replicates into a single row, with values delimited by “–”.\n\nbound_values &lt;- (austraits %&gt;% extract_dataset(\"ABRS_1981\"))$traits %&gt;%\n  bind_trait_values()\n\nbounded_wider &lt;- bound_values %&gt;% trait_pivot_wider\n\nIf you would like to revert the bounded trait values, you have to use separate_trait_values. Note, this function does not always recreate the original table as the delimitor “–” is also used for value_type bin and range, which should not necessarily be split. This function is on the list to rework for future austraits versions.\n\nbound_values2 &lt;- (austraits %&gt;% \n                    extract_dataset(\"ABRS_1981\") %&gt;%\n                    extract_data(table = \"traits\", col = \"value_type\", col_value = c(\"minimum\", \"maximum\"))\n                  )$traits %&gt;%\n  bind_trait_values()\n\nbound_values2 %&gt;%\n  separate_trait_values(., austraits$definitions)\n\n#&gt; # A tibble: 2,587 × 26\n#&gt;    dataset_id taxon_name       observation_id trait_name value unit  entity_type\n#&gt;    &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      \n#&gt;  1 ABRS_1981  Acanthocarpus c… 0001           leaf_leng… 15    mm    species    \n#&gt;  2 ABRS_1981  Acanthocarpus c… 0001           leaf_leng… 3     mm    species    \n#&gt;  3 ABRS_1981  Acanthocarpus c… 0001           seed_heig… 3     mm    species    \n#&gt;  4 ABRS_1981  Acanthocarpus c… 0001           seed_leng… 3     mm    species    \n#&gt;  5 ABRS_1981  Acanthocarpus c… 0001           seed_width 3     mm    species    \n#&gt;  6 ABRS_1981  Acanthocarpus h… 0002           seed_leng… 4     mm    species    \n#&gt;  7 ABRS_1981  Acanthocarpus p… 0003           leaf_leng… 3     mm    species    \n#&gt;  8 ABRS_1981  Acanthocarpus r… 0006           seed_heig… 2.5   mm    species    \n#&gt;  9 ABRS_1981  Acanthocarpus r… 0006           seed_leng… 2.5   mm    species    \n#&gt; 10 ABRS_1981  Acanthocarpus r… 0006           seed_width 2.5   mm    species    \n#&gt; # ℹ 2,577 more rows\n#&gt; # ℹ 19 more variables: value_type &lt;chr&gt;, basis_of_value &lt;chr&gt;,\n#&gt; #   replicates &lt;chr&gt;, basis_of_record &lt;chr&gt;, life_stage &lt;chr&gt;,\n#&gt; #   population_id &lt;chr&gt;, individual_id &lt;chr&gt;, repeat_measurements_id &lt;chr&gt;,\n#&gt; #   temporal_context_id &lt;chr&gt;, source_id &lt;chr&gt;, location_id &lt;chr&gt;,\n#&gt; #   entity_context_id &lt;chr&gt;, plot_context_id &lt;chr&gt;, treatment_context_id &lt;chr&gt;,\n#&gt; #   collection_date &lt;chr&gt;, measurement_remarks &lt;chr&gt;, method_id &lt;chr&gt;, …",
    "crumbs": [
      "Using outputs of `traits.build`",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>The `austraits` package</span>"
    ]
  },
  {
    "objectID": "help.html",
    "href": "help.html",
    "title": "34  Getting help",
    "section": "",
    "text": "34.1 Before you post\nThis chapter explains how to ask for help. Questions can range from detailed troubleshooting to general advice. To ensure a constructive dialogue, please read this entire page before reaching out. Thank you for respecting the time and effort it takes to provide one-on-one support.\nLinks to",
    "crumbs": [
      "Getting help",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Getting help</span>"
    ]
  },
  {
    "objectID": "help.html#before-you-post",
    "href": "help.html#before-you-post",
    "title": "34  Getting help",
    "section": "",
    "text": "Code of conduct\nPlease note that the traits.build project adheres to a Contributor Code of Conduct, as specified in austraits.build. By contributing to this project you agree to abide by its terms.\n\n\nSearch existing issues\nPlease check if your question already has an answer. You can search the GitHub Repositories:\n\ntraits.build-book\ntraits.build\naustraits.build\n\n\n\nTry troubleshooting\nFor specific errors or other issues, please read this chapter’s section on troubleshooting. Please try to work through the steps yourself before posting a question.",
    "crumbs": [
      "Getting help",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Getting help</span>"
    ]
  },
  {
    "objectID": "help.html#troubleshooting",
    "href": "help.html#troubleshooting",
    "title": "34  Getting help",
    "section": "34.2 Troubleshooting",
    "text": "34.2 Troubleshooting\nIt is okay to reach out if you are struggling to solve a specific problem in a specific project: an error message, a part of the code you are not sure how to write, or any experience with traits.build that is incorrect, unwelcome, unexpected, or confusing. However, please follow the guidelines below and take an active role in the troubleshooting process.\n\nUpdate your R packages\nIf the error is a bug in traits.build or austraits, it is possible the bug has already been fixed in a newer version. Before posting, please try again with the latest CRAN release of traits.build (or austraits), then again with the GitHub development version if needed. Please see http://traitecoevo.github.io/traits.build/#installation for installation instructions.\n\n\nAttribute the error\nThe traits.build package itself is often not usually the cause of problems that arise in traits.build pipelines. Most issues come from the user-defined R code, or data files that the pipeline calls, as well as other R packages on your system. So before you post a question, please attempt to troubleshoot and figure out if traits.build is actually the source of the trouble, or if the error comes from another package or your own code. The tips in the adding datasets or common data issues chapters may help. If the culprit turns out to be a non-traits.build issue, then please ask your question in a non-traits.build forum and write the question accordingly.\n\n\nWrite a reprex\nTo set up the discussion for success, please provide the complete context of the problem, including a reprex. The purpose of a reprex, or reproducible example1, is to eliminate the knowledge gaps, misunderstandings, and hidden assumptions where bugs hide. A reprex is a sample of complete, self-contained, runnable code that fully emulates and reproduces the problem. The code should look clean and readable, be as short and concise as possible, run in as few seconds as possible, and contain only the details most relevant to troubleshooting. You can embed the code inline in your question, or you can upload it to a public repository and post the link. Regardless, please expect that anyone trying to help will read all the code and run the enclosed _targets.R file on their own private computer. This process is hands-on and empirical, so please make it as quick and easy as possible for the people who volunteer their valuable time and energy to answer questions.\nThe following posts explain how to write a good reprex.\n\nhttps://stackoverflow.com/help/minimal-reproducible-example\nhttps://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example\nhttps://reprex.tidyverse.org/\nhttps://www.tidyverse.org/blog/2017/12/workflow-vs-script/",
    "crumbs": [
      "Getting help",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Getting help</span>"
    ]
  },
  {
    "objectID": "help.html#sec-contact",
    "href": "help.html#sec-contact",
    "title": "34  Getting help",
    "section": "34.3 Contact",
    "text": "34.3 Contact\nThere are many ways to reach out.\n\nMaintainer\nTo contact the maintainer directly, please post to the relevant public GitHub Discussions page of the package.2 Examples:\n\ntraits.build: https://github.com/ropensci/targets/discussions\naustraits: https://github.com/ropensci/tarchetypes/discussions\n\nGitHub makes it easy to search for and link to public discussions. Not only does this help users solve their own problems, it also helps the maintainer avoid repetition. So please use discussions instead of private emails, instant messages, or mentions on social media.",
    "crumbs": [
      "Getting help",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Getting help</span>"
    ]
  },
  {
    "objectID": "help.html#acknowledgements-and-copyright",
    "href": "help.html#acknowledgements-and-copyright",
    "title": "34  Getting help",
    "section": "34.4 Acknowledgements and copyright",
    "text": "34.4 Acknowledgements and copyright\nThis page was adapted from a corresponding file for the targets package, with text by Will Landau. The original file is available at https://github.com/ropensci-books/targets/blob/main/help.qmd. Text adapted from that page is under copy right specified in that package https://github.com/ropensci-books/targets/blob/main/LICENSE.md.",
    "crumbs": [
      "Getting help",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Getting help</span>"
    ]
  },
  {
    "objectID": "help.html#footnotes",
    "href": "help.html#footnotes",
    "title": "34  Getting help",
    "section": "",
    "text": "Also known as a minimal reproducible example or minimal working example.↩︎\nYou may need to create a free GitHub account, but the process is straightforward.↩︎",
    "crumbs": [
      "Getting help",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Getting help</span>"
    ]
  },
  {
    "objectID": "csv.html",
    "href": "csv.html",
    "title": "Appendix A — CSV files",
    "section": "",
    "text": "A comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas. This is a comma format for storing tables of data in a simple text file. You can edit it in Excel or in a text editor. For more, see here.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>CSV files</span>"
    ]
  },
  {
    "objectID": "yaml.html",
    "href": "yaml.html",
    "title": "Appendix B — Yaml files",
    "section": "",
    "text": "The yml file extension (pronounced “YAML”) is a type structured data file, that is both human and machine readable. You can edit it in any text editor, or also in Rstudio. Generally, yml is used in situations where a table is not suitable because of variable lengths and or nested structures. It has the advantage over a spreadsheet in that the nested “headers” can have variable numbers of categories. The data under each of the hierarchical headings are easily extracted by R.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Yaml files</span>"
    ]
  }
]